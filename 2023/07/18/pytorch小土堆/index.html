<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>pytorch小土堆 | Larkkkkkkk</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="学习链接12345678910111213141.哔哩哔哩视频https:&#x2F;&#x2F;www.bilibili.com&#x2F;video&#x2F;BV1hE411t7RN?p&#x3D;18&amp;spm_id_from&#x3D;pageDriver&amp;vd_source&#x3D;f2ebbaf7e4283edae08088dbbbaff2992.pytorch官网h">
<meta property="og:type" content="article">
<meta property="og:title" content="pytorch小土堆">
<meta property="og:url" content="https://larkkkkkkk.github.io/2023/07/18/pytorch%E5%B0%8F%E5%9C%9F%E5%A0%86/index.html">
<meta property="og:site_name" content="Larkkkkkkk">
<meta property="og:description" content="学习链接12345678910111213141.哔哩哔哩视频https:&#x2F;&#x2F;www.bilibili.com&#x2F;video&#x2F;BV1hE411t7RN?p&#x3D;18&amp;spm_id_from&#x3D;pageDriver&amp;vd_source&#x3D;f2ebbaf7e4283edae08088dbbbaff2992.pytorch官网h">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://larkkkkkkk.github.io/2023/07/18/pytorch%E5%B0%8F%E5%9C%9F%E5%A0%86/1.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2023/07/18/pytorch%E5%B0%8F%E5%9C%9F%E5%A0%86/2.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2023/07/18/pytorch%E5%B0%8F%E5%9C%9F%E5%A0%86/3.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2023/07/18/pytorch%E5%B0%8F%E5%9C%9F%E5%A0%86/4.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2023/07/18/pytorch%E5%B0%8F%E5%9C%9F%E5%A0%86/5.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2023/07/18/pytorch%E5%B0%8F%E5%9C%9F%E5%A0%86/6.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2023/07/18/pytorch%E5%B0%8F%E5%9C%9F%E5%A0%86/8.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2023/07/18/pytorch%E5%B0%8F%E5%9C%9F%E5%A0%86/7.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2023/07/18/pytorch%E5%B0%8F%E5%9C%9F%E5%A0%86/9.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2023/07/18/pytorch%E5%B0%8F%E5%9C%9F%E5%A0%86/10.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2023/07/18/pytorch%E5%B0%8F%E5%9C%9F%E5%A0%86/11.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2023/07/18/pytorch%E5%B0%8F%E5%9C%9F%E5%A0%86/12.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2023/07/18/pytorch%E5%B0%8F%E5%9C%9F%E5%A0%86/13.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2023/07/18/pytorch%E5%B0%8F%E5%9C%9F%E5%A0%86/15.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2023/07/18/pytorch%E5%B0%8F%E5%9C%9F%E5%A0%86/14.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2023/07/18/pytorch%E5%B0%8F%E5%9C%9F%E5%A0%86/16.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2023/07/18/pytorch%E5%B0%8F%E5%9C%9F%E5%A0%86/17.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2023/07/18/pytorch%E5%B0%8F%E5%9C%9F%E5%A0%86/20.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2023/07/18/pytorch%E5%B0%8F%E5%9C%9F%E5%A0%86/18.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2023/07/18/pytorch%E5%B0%8F%E5%9C%9F%E5%A0%86/19.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2023/07/18/pytorch%E5%B0%8F%E5%9C%9F%E5%A0%86/D:%5Cblog%5CLarkkkkkkk%5Csource_posts%5Cpytorch%E5%B0%8F%E5%9C%9F%E5%A0%86%5C21.png">
<meta property="article:published_time" content="2023-07-18T09:20:31.000Z">
<meta property="article:modified_time" content="2023-10-21T13:47:08.603Z">
<meta property="article:author" content="Larkkkkkkk">
<meta property="article:tag" content="python">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://larkkkkkkk.github.io/2023/07/18/pytorch%E5%B0%8F%E5%9C%9F%E5%A0%86/1.png">
  
    <link rel="alternative" href="/atom.xml" title="Larkkkkkkk" type="application/atom+xml">
  
  
    <link rel="icon" href="/http://oayoilchh.bkt.clouddn.com/2016/07/27/18:05:26%20">
  
  
      
<link rel="stylesheet" href="//cdn.bootcss.com/animate.css/3.5.0/animate.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  <link rel="stylesheet" href="/font-awesome/css/font-awesome.min.css">
  <link rel="apple-touch-icon" href="/apple-touch-icon.png">
  
  
      <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  
  <!-- 加载特效 -->
    <script src="/js/pace.js"></script>
    <link href="/css/pace/pace-theme-flash.css" rel="stylesheet" />
  <script>
      var yiliaConfig = {
          rootUrl: '/',
          fancybox: true,
          animate: true,
          isHome: false,
          isPost: true,
          isArchive: false,
          isTag: false,
          isCategory: false,
          open_in_new: false
      }
  </script>
<meta name="generator" content="Hexo 4.2.1"></head>
<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
    <header id="header" class="inner">
        <script src="http://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js"></script>
        <a href="/" class="profilepic">
            
            <img lazy-src="img/head.jpg" class="js-avatar">
            
        </a>
        <hgroup>
          <h1 class="header-author"><a href="/">Larkkkkkkk</a></h1>
        </hgroup>
        
        
            <form>
                <input type="text" class="st-default-search-input search" id="local-search-input" placeholder="搜索一下" autocomplete="off">
            </form>
            <div id="local-search-result"></div>
        
        
            <script type="text/javascript">
                (function() {
                    'use strict';
                    function getMatchData(keyword, data) {
                        var matchData = [];
                        for(var i =0;i<data.length;i++){
                            if(data[i].title.toLowerCase().indexOf(keyword)>=0) 
                                matchData.push(data[i])
                        }
                        return matchData;
                    }
                    var $input = $('#local-search-input');
                    var $resultContent = $('#local-search-result');
                    $input.keyup(function(){
                        $.ajax({
                            url: '/search.json',
                            dataType: "json",
                            success: function( json ) {
                                var str='<ul class=\"search-result-list\">';                
                                var keyword = $input.val().trim().toLowerCase();
                                $resultContent.innerHTML = "";
                                if ($input.val().trim().length <= 0) {
                                    $resultContent.empty();
                                    $('#switch-area').show();
                                    return;
                                }
                                var results = getMatchData(keyword, json);
                                if(results.length === 0){
                                    $resultContent.empty();
                                    $('#switch-area').show();
                                    return;
                                } 
                                for(var i =0; i<results.length; i++){
                                    str += "<li><a href='"+ results[i].url +"' class='search-result-title'>"+ results[i].title +"</a></li>";
                                }
                                str += "</ul>";
                                $resultContent.empty();
                                $resultContent.append(str);
                                $('#switch-area').hide();
                            }
                        });
                    });
                })();
            </script>
        
        
            <div id="switch-btn" class="switch-btn">
                <div class="icon">
                    <div class="icon-ctn">
                        <div class="icon-wrap icon-house" data-idx="0">
                            <div class="birdhouse"></div>
                            <div class="birdhouse_holes"></div>
                        </div>
                        <div class="icon-wrap icon-ribbon hide" data-idx="1">
                            <div class="ribbon"></div>
                        </div>
                        
                        <div class="icon-wrap icon-link hide" data-idx="2">
                            <div class="loopback_l"></div>
                            <div class="loopback_r"></div>
                        </div>
                        
                        
                        <div class="icon-wrap icon-me hide" data-idx="3">
                            <div class="user"></div>
                            <div class="shoulder"></div>
                        </div>
                        
                    </div>
                </div>
                <div class="tips-box hide">
                    <div class="tips-arrow"></div>
                    <ul class="tips-inner">
                        <li>菜单</li>
                        <li>标签</li>
                        
                        <li>友情链接</li>
                        
                        
                        <li>关于我</li>
                        
                    </ul>
                </div>
            </div>
        
        <div id="switch-area" class="switch-area">
            <div class="switch-wrap">
                <section class="switch-part switch-part1">
                    <nav class="header-menu">
                        <ul>
                        
                            <li><a  href="https://github.com/Larkkkkkkk" target="_blank" rel="noopener">博客首页</a></li>
                        
                            <li><a  href="/archives">文章归档</a></li>
                        
                            <li><a  href="/CTFStudy">学习导航</a></li>
                        
                            <li><a  href="/PWNABLE">PWNABLE</a></li>
                        
                            <li><a  href="/resume">个人简历</a></li>
                        
                        </ul>
                    </nav>
                    <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fl mail"  target="_blank" href="http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&email=U2JgZ2ZlY2VmamATIiJ9MDw_" title="mail">mail</a>
                            
                                <a class="fl github"  target="_blank" href="https://github.com/Larkkkkkkk" title="github">github</a>
                            
                                <a class="fl zhihu"  target="_blank" href="https://www.zhihu.com/people/plain-3-78/activities" title="zhihu">zhihu</a>
                            
                                <a class="fl weibo"  target="_blank" href="https://weibo.com/5304208276/profile?topnav=1&wvr=6" title="weibo">weibo</a>
                            
                                <a class="fl rss"  target="_blank" href="/atom.xml" title="rss">rss</a>
                            
                        </ul>
                    </nav>
                </section>
                
                <section class="switch-part switch-part2">
                    <div class="widget tagcloud" id="js-tagcloud">
                        <a href="/tags/Ajax/" style="font-size: 12px;">Ajax</a> <a href="/tags/Cookie%E5%92%8CSession/" style="font-size: 14px;">Cookie和Session</a> <a href="/tags/DBUtils/" style="font-size: 11px;">DBUtils</a> <a href="/tags/Docker/" style="font-size: 10px;">Docker</a> <a href="/tags/EL%E8%A1%A8%E8%BE%BE%E5%BC%8F/" style="font-size: 10px;">EL表达式</a> <a href="/tags/Filter/" style="font-size: 11px;">Filter</a> <a href="/tags/HTTP/" style="font-size: 10px;">HTTP</a> <a href="/tags/HTTPServletReauest%E5%92%8CHTTPServletResponse/" style="font-size: 10px;">HTTPServletReauest和HTTPServletResponse</a> <a href="/tags/IDEA%E5%AE%89%E8%A3%85%E5%92%8C%E7%A0%B4%E8%A7%A3/" style="font-size: 10px;">IDEA安装和破解</a> <a href="/tags/JAVA/" style="font-size: 16px;">JAVA</a> <a href="/tags/JAVA-Lambda%E8%A1%A8%E8%BE%BE%E5%BC%8F/" style="font-size: 10px;">JAVA-Lambda表达式</a> <a href="/tags/JAVA-Set%E9%9B%86%E5%90%88/" style="font-size: 10px;">JAVA-Set集合</a> <a href="/tags/JAVA-%E5%8F%8D%E5%B0%84/" style="font-size: 10px;">JAVA-反射</a> <a href="/tags/JAVA-%E5%A4%9A%E7%BA%BF%E7%A8%8B/" style="font-size: 12px;">JAVA-多线程</a> <a href="/tags/JAVA-%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/" style="font-size: 10px;">JAVA-正则表达式</a> <a href="/tags/JAVA-%E6%B3%9B%E5%9E%8B/" style="font-size: 10px;">JAVA-泛型</a> <a href="/tags/JAVA-%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/" style="font-size: 12px;">JAVA-网络编程</a> <a href="/tags/JAVA-%E9%9B%86%E5%90%88/" style="font-size: 12px;">JAVA-集合</a> <a href="/tags/JAVA%E7%BB%83%E4%B9%A0/" style="font-size: 11px;">JAVA练习</a> <a href="/tags/JAVA%E7%BB%83%E4%B9%A0-%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/" style="font-size: 10px;">JAVA练习-动态规划</a> <a href="/tags/JQuery/" style="font-size: 13px;">JQuery</a> <a href="/tags/JSP/" style="font-size: 10px;">JSP</a> <a href="/tags/JVM/" style="font-size: 10px;">JVM</a> <a href="/tags/LeetCode/" style="font-size: 18px;">LeetCode</a> <a href="/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/tags/Listener/" style="font-size: 10px;">Listener</a> <a href="/tags/Mybatis/" style="font-size: 19px;">Mybatis</a> <a href="/tags/Mysql/" style="font-size: 10px;">Mysql</a> <a href="/tags/Mysql%E6%95%B0%E6%8D%AE%E5%BA%93%E5%92%8CJDBC/" style="font-size: 15px;">Mysql数据库和JDBC</a> <a href="/tags/Redis/" style="font-size: 11px;">Redis</a> <a href="/tags/Servlet/" style="font-size: 11px;">Servlet</a> <a href="/tags/Spring/" style="font-size: 17px;">Spring</a> <a href="/tags/SpringBoot/" style="font-size: 10px;">SpringBoot</a> <a href="/tags/SpringMVC/" style="font-size: 15px;">SpringMVC</a> <a href="/tags/Tomcat/" style="font-size: 10px;">Tomcat</a> <a href="/tags/Web%E5%89%8D%E7%AB%AF%E7%9F%A5%E8%AF%86%E7%82%B9/" style="font-size: 20px;">Web前端知识点</a> <a href="/tags/XML/" style="font-size: 11px;">XML</a> <a href="/tags/django/" style="font-size: 10px;">django</a> <a href="/tags/flask%E6%A1%86%E6%9E%B6/" style="font-size: 10px;">flask框架</a> <a href="/tags/git/" style="font-size: 10px;">git</a> <a href="/tags/jsp%E6%A0%87%E5%87%86%E6%A0%87%E7%AD%BE%E5%BA%93/" style="font-size: 10px;">jsp标准标签库</a> <a href="/tags/maven/" style="font-size: 10px;">maven</a> <a href="/tags/picture/" style="font-size: 10px;">picture</a> <a href="/tags/python/" style="font-size: 12px;">python</a> <a href="/tags/pytorch/" style="font-size: 10px;">pytorch</a> <a href="/tags/ssm%E6%A1%86%E6%9E%B6%E6%A8%A1%E6%9D%BF/" style="font-size: 10px;">ssm框架模板</a> <a href="/tags/webserver%E7%BC%96%E7%A8%8B/" style="font-size: 10px;">webserver编程</a> <a href="/tags/%E4%BA%8B%E5%8A%A1/" style="font-size: 10px;">事务</a> <a href="/tags/%E4%BA%AC%E4%B8%9C/" style="font-size: 11px;">京东</a> <a href="/tags/%E5%90%8E%E7%BC%80%E6%A0%91/" style="font-size: 10px;">后缀树</a> <a href="/tags/%E5%93%88%E5%B8%8C%E8%A1%A8/" style="font-size: 10px;">哈希表</a> <a href="/tags/%E5%9B%BE/" style="font-size: 10px;">图</a> <a href="/tags/%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%88%86%E6%9E%90/" style="font-size: 10px;">复杂度分析</a> <a href="/tags/%E5%AD%A6%E7%94%9F%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/" style="font-size: 10px;">学生管理系统</a> <a href="/tags/%E5%AD%A6%E7%94%9F%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F2-0/" style="font-size: 12px;">学生管理系统2.0</a> <a href="/tags/%E6%8B%BC%E5%A4%9A%E5%A4%9A/" style="font-size: 10px;">拼多多</a> <a href="/tags/%E6%8E%92%E5%BA%8F/" style="font-size: 10px;">排序</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/" style="font-size: 10px;">数据分析</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0/" style="font-size: 10px;">数据库连接池</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%A8%80%E7%96%8F%E6%95%B0%E7%BB%84/" style="font-size: 10px;">数据结构-稀疏数组</a> <a href="/tags/%E6%96%87%E5%AD%97%E7%AF%87-%E8%AE%B0%E5%BD%95/" style="font-size: 10px;">文字篇-记录</a> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="font-size: 12px;">机器学习</a> <a href="/tags/%E6%A0%88/" style="font-size: 10px;">栈</a> <a href="/tags/%E6%A0%91/" style="font-size: 12px;">树</a> <a href="/tags/%E6%B3%A8%E8%A7%A3/" style="font-size: 10px;">注解</a> <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" style="font-size: 14px;">深度学习</a> <a href="/tags/%E7%88%AC%E8%99%AB/" style="font-size: 11px;">爬虫</a> <a href="/tags/%E7%94%9F%E7%89%A9%E4%BF%A1%E6%81%AF%E5%AD%A6/" style="font-size: 10px;">生物信息学</a> <a href="/tags/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/" style="font-size: 12px;">知识图谱</a> <a href="/tags/%E7%A0%94%E7%A9%B6%E7%94%9F%E5%88%9D%E8%AF%95/" style="font-size: 12px;">研究生初试</a> <a href="/tags/%E7%A7%8B%E6%8B%9B/" style="font-size: 10px;">秋招</a> <a href="/tags/%E7%AE%97%E6%B3%95-%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/" style="font-size: 10px;">算法-动态规划</a> <a href="/tags/%E7%AE%97%E6%B3%95-%E5%9B%9E%E6%BA%AF%E6%B3%95/" style="font-size: 10px;">算法-回溯法</a> <a href="/tags/%E7%AE%97%E6%B3%95-%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95/" style="font-size: 10px;">算法-贪心算法</a> <a href="/tags/%E8%80%83%E7%A0%94/" style="font-size: 10px;">考研</a> <a href="/tags/%E8%93%9D%E6%A1%A5%E6%9D%AF/" style="font-size: 13px;">蓝桥杯</a> <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E8%AF%BE%E8%AE%BE-%E8%BD%AF%E4%BB%B6%E4%B8%93%E4%B8%9A%E9%A2%98%E7%9B%AE/" style="font-size: 10px;">计算机网络课设(软件专业题目)</a> <a href="/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/" style="font-size: 12px;">设计模式</a> <a href="/tags/%E8%BD%AF%E4%BB%B6%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/" style="font-size: 10px;">软件体系结构</a> <a href="/tags/%E9%80%92%E5%BD%92/" style="font-size: 10px;">递归</a> <a href="/tags/%E9%87%8D%E6%96%B0%E9%83%A8%E7%BD%B2/" style="font-size: 10px;">重新部署</a> <a href="/tags/%E9%93%BE%E8%A1%A8/" style="font-size: 10px;">链表</a> <a href="/tags/%E9%98%9F%E5%88%97/" style="font-size: 10px;">队列</a> <a href="/tags/%E9%9D%A2%E8%AF%95/" style="font-size: 10px;">面试</a> <a href="/tags/%E9%A1%B5%E9%9D%A2%EF%BC%88H5-CSS%EF%BC%89/" style="font-size: 10px;">页面（H5+CSS）</a> <a href="/tags/%E9%A1%B9%E7%9B%AE%E4%B8%8A%E4%BC%A0/" style="font-size: 10px;">项目上传</a>
                    </div>
                </section>
                
                
                <section class="switch-part switch-part3">
                    <div id="js-friends">
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://ring3.xyz/">Yllen</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://mxny.org/">麦香浓郁</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://whereisk0shl.top/">K0sh1</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://www.ycjcl.cc/">信鑫</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://bystudent.com/">ByStundet表哥</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="https://www.jarviswang.me/">汪神_Jarvis</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://sh3ll.me/">Chu</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="https://www.hackfun.org/">4ido10n</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://www.cnblogs.com/iamstudy">L3m0n</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://o0xmuhe.me/">muhe</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://blog.nuptzj.cn/">_画船听雨</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://www.virzz.com/index.html">Virink</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://www.sqlsec.com/">国光</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://www.bodkin.ren/">老锥</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://www.cizel.cn/">C1zel</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://1phan.cc">1phan</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="https://www.liuil.top/">liuil</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://www.cnblogs.com/Ox9A82/">Ox9A82</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://burnegg.com/">burnegg</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="https://jwrsec.cn/">jwr-sec</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://sudalover.cn/">苏打</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://blog.binklac.com">VeroFess</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://www.bendawang.site/">bendawang</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://weeklyalgo.codes/">hook</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://www.flier.net.cn/">Flier&#39;blog</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://www.mutepig.club">mutepig</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="https://blog.iret.xyz/list.aspx">Silver</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://simp1e.leanote.com/">Simple</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://processor.pub/">Processor</a>
                    
                    </div>
                </section>
                
                
                
                <section class="switch-part switch-part4">
                
                    <div id="js-aboutme">一只淹死在二进制海洋里的二进制狗!</div>
                </section>
                
            </div>
        </div>
    </header>
</div>

    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
      <div class="overlay">
          <div class="slider-trigger"></div>
          <h1 class="header-author js-mobile-header hide"><a href="/" title="Me">Larkkkkkkk</a></h1>
      </div>
    <div class="intrude-less">
        <header id="header" class="inner">
            <a href="/" class="profilepic">
                
                    <img lazy-src="/img/head.jpg" class="js-avatar">
                
            </a>
            <hgroup>
              <h1 class="header-author"><a href="/" title="Me">Larkkkkkkk</a></h1>
            </hgroup>
            
            <nav class="header-menu">
                <ul>
                
                    <li><a href="https://github.com/Larkkkkkkk" target="_blank" rel="noopener">博客首页</a></li>
                
                    <li><a href="/archives">文章归档</a></li>
                
                    <li><a href="/CTFStudy">学习导航</a></li>
                
                    <li><a href="/PWNABLE">PWNABLE</a></li>
                
                    <li><a href="/resume">个人简历</a></li>
                
                <div class="clearfix"></div>
                </ul>
            </nav>
            <nav class="header-nav">
                <div class="social">
                    
                        <a class="mail" target="_blank" href="http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&email=U2JgZ2ZlY2VmamATIiJ9MDw_" title="mail">mail</a>
                    
                        <a class="github" target="_blank" href="https://github.com/Larkkkkkkk" title="github">github</a>
                    
                        <a class="zhihu" target="_blank" href="https://www.zhihu.com/people/plain-3-78/activities" title="zhihu">zhihu</a>
                    
                        <a class="weibo" target="_blank" href="https://weibo.com/5304208276/profile?topnav=1&wvr=6" title="weibo">weibo</a>
                    
                        <a class="rss" target="_blank" href="/atom.xml" title="rss">rss</a>
                    
                </div>
            </nav>
        </header>                
    </div>
</nav>
      <div class="body-wrap"><article id="post-pytorch小土堆" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2023/07/18/pytorch%E5%B0%8F%E5%9C%9F%E5%A0%86/" class="article-date">
      <time datetime="2023-07-18T09:20:31.000Z" itemprop="datePublished">2023-07-18</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      pytorch小土堆
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        

        
    <div class="article-tag tagcloud">
        <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/python/" rel="tag">python</a></li></ul>
    </div>

        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h1 id="学习链接"><a href="#学习链接" class="headerlink" title="学习链接"></a>学习链接</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">1.哔哩哔哩视频</span><br><span class="line">https:&#x2F;&#x2F;www.bilibili.com&#x2F;video&#x2F;BV1hE411t7RN?p&#x3D;18&amp;spm_id_from&#x3D;pageDriver&amp;vd_source&#x3D;f2ebbaf7e4283edae08088dbbbaff299</span><br><span class="line"></span><br><span class="line">2.pytorch官网</span><br><span class="line">https:&#x2F;&#x2F;pytorch.org&#x2F;docs&#x2F;stable&#x2F;generated&#x2F;torch.nn.functional.conv2d.html#torch.nn.functional.conv2d</span><br><span class="line"></span><br><span class="line">3.小土堆的资料链接</span><br><span class="line">土堆B站视频课件：https:&#x2F;&#x2F;pan.baidu.com&#x2F;wap&#x2F;init?surl&#x3D;moZb_eKmVCcRHS49IPKHQw#&#x2F; 提取码：t3st</span><br><span class="line"></span><br><span class="line">4.我自己电脑是tuduipytorch2环境(python3.8)</span><br><span class="line"></span><br><span class="line">5.配置pytorch用的链接里面的11.3版本</span><br><span class="line">https:&#x2F;&#x2F;blog.csdn.net&#x2F;weixin_45334223&#x2F;article&#x2F;details&#x2F;128772572?ops_request_misc&#x3D;%257B%2522request%255Fid%2522%253A%2522168974940216800227485583%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id&#x3D;168974940216800227485583&amp;biz_id&#x3D;0&amp;utm_medium&#x3D;distribute.pc_search_result.none-task-blog-2~blog~top_positive~default-2-128772572-null-null.268^v1^control&amp;utm_term&#x3D;%E5%AE%89%E8%A3%85pytorch&amp;spm&#x3D;1018.2226.3001.4450</span><br></pre></td></tr></table></figure>

<h1 id="p16神经网络的基本骨架-nn-Module"><a href="#p16神经网络的基本骨架-nn-Module" class="headerlink" title="p16神经网络的基本骨架(nn.Module)"></a>p16神经网络的基本骨架(nn.Module)</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">import torch</span><br><span class="line">from torch import nn</span><br><span class="line"></span><br><span class="line">class Tudui(nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super().__init__()  #重写父类</span><br><span class="line"></span><br><span class="line">    def forward(self, input):</span><br><span class="line">        output &#x3D; input + 1  #计数</span><br><span class="line">        return output</span><br><span class="line"></span><br><span class="line">tudui &#x3D; Tudui()</span><br><span class="line">x &#x3D; torch.tensor(1.0)</span><br><span class="line">output &#x3D; tudui(x)</span><br><span class="line">print(output)</span><br></pre></td></tr></table></figure>

<p><img src="/2023/07/18/pytorch%E5%B0%8F%E5%9C%9F%E5%A0%86/1.png" alt></p>
<hr>
<h1 id="p17卷积操作"><a href="#p17卷积操作" class="headerlink" title="p17卷积操作"></a>p17卷积操作</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">import torch</span><br><span class="line">import torch.nn.functional as F</span><br><span class="line"></span><br><span class="line">#输入图像 5*5</span><br><span class="line">input&#x3D;torch.tensor([[1,2,0,3,1],</span><br><span class="line">                    [0,1,2,3,1],</span><br><span class="line">                    [1,2,1,0,0],</span><br><span class="line">                    [5,2,3,1,1],</span><br><span class="line">                    [2,1,0,1,1]])</span><br><span class="line">#卷积核 3*3</span><br><span class="line">kernel&#x3D;torch.tensor([1,2,1],</span><br><span class="line">                    [0,1,0],</span><br><span class="line">                    [2,1,0])</span><br><span class="line"></span><br><span class="line">#将输入图像更改为1个数据1个通道  高度5宽度5      input要求为(minibatch,in_channels,iH,iW)</span><br><span class="line">input&#x3D;torch.reshape(input,(1,1,5,5))</span><br><span class="line">kernel&#x3D;kernel.reshape(input,(1,1,3,3))</span><br><span class="line"></span><br><span class="line">print(input.shape)</span><br><span class="line">print(kernel.shape)</span><br><span class="line"></span><br><span class="line">#步长为1 就是每次移动一位</span><br><span class="line">output&#x3D;F.conv2d(input,kernel,stride&#x3D;1)</span><br><span class="line">print(output)</span><br><span class="line"></span><br><span class="line">output2&#x3D;F.conv2d(input,kernel,stride&#x3D;2)</span><br><span class="line">print(output2)</span><br><span class="line"></span><br><span class="line">#填充为1</span><br><span class="line">output3&#x3D;F.conv2d(input,kernel,stride&#x3D;1,padding&#x3D;1)</span><br><span class="line">print(output3)</span><br></pre></td></tr></table></figure>

<p><img src="/2023/07/18/pytorch%E5%B0%8F%E5%9C%9F%E5%A0%86/2.png" alt></p>
<hr>
<h1 id="p18卷积层"><a href="#p18卷积层" class="headerlink" title="p18卷积层"></a>p18卷积层</h1><p><strong>动画</strong><br><a href="https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md" target="_blank" rel="noopener" title="卷积层参数的影响">https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">import torch</span><br><span class="line">import torchvision</span><br><span class="line">from torch.nn import Conv2d</span><br><span class="line">from torch.utils.data import DataLoader</span><br><span class="line">from torch import nn</span><br><span class="line">dataset&#x3D;torchvision.datasets.CIFAR10(&quot;..&#x2F;data&quot;,train&#x3D;False,transform&#x3D;torchvision.transforms.ToTensor(),download&#x3D;True)</span><br><span class="line">dataloader&#x3D;DataLoader(dataset,batch_size&#x3D;64)</span><br><span class="line"></span><br><span class="line">class Tudui(nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(Tudui,self).__init__()  #重写父类</span><br><span class="line">        self.conv1&#x3D;Conv2d(in_channels&#x3D;3,out_channels&#x3D;6,kernel_size&#x3D;3,stride&#x3D;1,padding&#x3D;0)  #设置一个卷积层</span><br><span class="line"></span><br><span class="line">    def forward(self,x):</span><br><span class="line">        x&#x3D;self.conv1(x)</span><br><span class="line">        return x</span><br><span class="line"></span><br><span class="line">tudui&#x3D;Tudui()</span><br><span class="line">print(tudui)  #conv1:conv2d(3,6,kernel_size&#x3D;(3,3),stride&#x3D;(1,1))</span><br><span class="line"></span><br><span class="line">for data in dataloader:</span><br><span class="line">    imgs,target&#x3D;data</span><br><span class="line">    output&#x3D;tudui(imgs) #把数据集的照片放进去</span><br><span class="line">    #图片开始的格式</span><br><span class="line">    print(imgs.shape) #【64,4,32，32】</span><br><span class="line">    #图片最终的格式</span><br><span class="line">    print(output.shape)#【64,3,30，30】</span><br></pre></td></tr></table></figure>

<p><img src="/2023/07/18/pytorch%E5%B0%8F%E5%9C%9F%E5%A0%86/3.png" alt></p>
<hr>
<h1 id="p19最大池化层"><a href="#p19最大池化层" class="headerlink" title="p19最大池化层"></a>p19最大池化层</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">import torch</span><br><span class="line">from torch import nn</span><br><span class="line">from torch.nn import MaxPool2d</span><br><span class="line"></span><br><span class="line">#输入图像 5*5</span><br><span class="line">input&#x3D;torch.tensor([[1,2,0,3,1],</span><br><span class="line">                    [0,1,2,3,1],</span><br><span class="line">                    [1,2,1,0,0],</span><br><span class="line">                    [5,2,3,1,1],</span><br><span class="line">                    [2,1,0,1,1]],dtype&#x3D;torch.float32)</span><br><span class="line"></span><br><span class="line">input &#x3D; torch.reshape(input, (-1, 1, 5, 5))  #-1就是根据其他设置，自动计算</span><br><span class="line">print(input)</span><br><span class="line">print(input.shape)</span><br><span class="line"></span><br><span class="line">class Tudui(nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(Tudui,self).__init__()  #重写父类</span><br><span class="line">        #池化层就是减少参数 让模型更简略更小</span><br><span class="line">        self.maxpool1&#x3D;MaxPool2d(kernel_size&#x3D;3,ceil_mode&#x3D;True)   #设置一个池化层 ceil_mode&#x3D;True能够保证不够池化核大小的时候可以出结果</span><br><span class="line"></span><br><span class="line">    def forward(self,input):</span><br><span class="line">        output&#x3D;self.maxpool1(input)</span><br><span class="line">        return output</span><br><span class="line"></span><br><span class="line">tudui&#x3D;Tudui()</span><br><span class="line">output&#x3D;tudui(input)</span><br><span class="line">print(output)</span><br></pre></td></tr></table></figure>

<p><img src="/2023/07/18/pytorch%E5%B0%8F%E5%9C%9F%E5%A0%86/4.png" alt></p>
<hr>
<h1 id="p20非线性激活"><a href="#p20非线性激活" class="headerlink" title="p20非线性激活"></a>p20非线性激活</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">#主要介绍relu和sigmoid</span><br><span class="line">import torch</span><br><span class="line">from torch import nn</span><br><span class="line">from torch.nn import ReLU, Sigmoid</span><br><span class="line"></span><br><span class="line">input&#x3D;torch.tensor([[1,-0.5],</span><br><span class="line">                    [-1,3]])</span><br><span class="line"></span><br><span class="line">input&#x3D;torch.reshape(input,(-1,1,2,2))</span><br><span class="line">print(input)</span><br><span class="line">class Tudui(nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(Tudui, self).__init__()</span><br><span class="line">        self.relu1 &#x3D; ReLU()</span><br><span class="line">        self.sigmoid1 &#x3D; Sigmoid()</span><br><span class="line"></span><br><span class="line">    def forward(self, input):</span><br><span class="line">        output &#x3D; self.relu1(input)</span><br><span class="line">        #output &#x3D; self.sigmoid1(input)</span><br><span class="line">        return output</span><br><span class="line"></span><br><span class="line">tudui &#x3D; Tudui()</span><br><span class="line">output&#x3D;tudui(input)</span><br><span class="line">print(output)</span><br></pre></td></tr></table></figure>

<p><img src="/2023/07/18/pytorch%E5%B0%8F%E5%9C%9F%E5%A0%86/5.png" alt></p>
<hr>
<h1 id="p21线性层和其它层介绍"><a href="#p21线性层和其它层介绍" class="headerlink" title="p21线性层和其它层介绍"></a>p21线性层和其它层介绍</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">import torch</span><br><span class="line">import torchvision</span><br><span class="line">from torch import nn</span><br><span class="line">from torch.nn import Linear</span><br><span class="line">from torch.utils.data import DataLoader</span><br><span class="line"></span><br><span class="line">dataset &#x3D; torchvision.datasets.CIFAR10(&quot;..&#x2F;data&quot;, train&#x3D;False, transform&#x3D;torchvision.transforms.ToTensor(),</span><br><span class="line">                                       download&#x3D;True)</span><br><span class="line"></span><br><span class="line">dataloader &#x3D; DataLoader(dataset, batch_size&#x3D;64)</span><br><span class="line"></span><br><span class="line">class Tudui(nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(Tudui, self).__init__()</span><br><span class="line">        self.linear1 &#x3D; Linear(196608, 10)  #输入 输出</span><br><span class="line"></span><br><span class="line">    def forward(self, input):</span><br><span class="line">        output &#x3D; self.linear1(input) #经过线性层</span><br><span class="line">        return output</span><br><span class="line"></span><br><span class="line">tudui &#x3D; Tudui()</span><br><span class="line"></span><br><span class="line">for data in dataloader:</span><br><span class="line">    imgs, targets &#x3D; data</span><br><span class="line">    print(imgs.shape)</span><br><span class="line">    output &#x3D; torch.flatten(imgs)  #展开成一行</span><br><span class="line">    print(output.shape)</span><br><span class="line">    output &#x3D; tudui(output)</span><br><span class="line">    print(output.shape)</span><br></pre></td></tr></table></figure>

<p><img src="/2023/07/18/pytorch%E5%B0%8F%E5%9C%9F%E5%A0%86/6.png" alt></p>
<hr>
<h1 id="p22实战和sequential的使用"><a href="#p22实战和sequential的使用" class="headerlink" title="p22实战和sequential的使用"></a>p22实战和sequential的使用</h1><p><strong>要参考的模型图:</strong></p>
<p><img src="/2023/07/18/pytorch%E5%B0%8F%E5%9C%9F%E5%A0%86/8.png" alt></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">import torch</span><br><span class="line">from torch import nn</span><br><span class="line">from torch.nn import Conv2d, MaxPool2d, Flatten, Linear, Sequential</span><br><span class="line">#from torch.utils.tensorboard import SummaryWriter</span><br><span class="line"></span><br><span class="line">class Tudui(nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(Tudui, self).__init__()</span><br><span class="line">        #直接做成一个系列</span><br><span class="line">        self.model1 &#x3D; Sequential(</span><br><span class="line">            Conv2d(in_channels&#x3D;3, out_channels&#x3D;32,kernel_size&#x3D;5, padding&#x3D;2),  #padding&#x3D;2是根据输入输出的HW公式推出来   输入3个通道 输出维度32池化核5*5</span><br><span class="line">            MaxPool2d(2),  #默认池化层的stride步长&#x3D;池化核维度</span><br><span class="line">            Conv2d(in_channels&#x3D;32, out_channels&#x3D;32,kernel_size&#x3D;5, padding&#x3D;2), #padding&#x3D;2是根据输入输出的HW公式推出来   输入32个通道 输出维度32 池化核5*5</span><br><span class="line">            MaxPool2d(2),  #默认池化层的stride步长&#x3D;池化核维度</span><br><span class="line">            Conv2d(in_channels&#x3D;32, out_channels&#x3D;64,kernel_size&#x3D;5, padding&#x3D;2), #padding&#x3D;2是根据输入输出的HW公式推出来   输入32个通道 输出维度64 池化核5*5</span><br><span class="line">            MaxPool2d(2),  #默认池化层的stride步长&#x3D;池化核维度</span><br><span class="line">            Flatten(),  #展开</span><br><span class="line">            Linear(1024, 64),  #展开之后64*4*4&#x3D;1024个 一共有64个</span><br><span class="line">            Linear(64, 10)  #展开之后64个 一共10个</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        x &#x3D; self.model1(x)</span><br><span class="line">        return x</span><br><span class="line"></span><br><span class="line">@初始化看看</span><br><span class="line">tudui &#x3D; Tudui()</span><br><span class="line">print(tudui)</span><br><span class="line"></span><br><span class="line">#假设有一个</span><br><span class="line">input &#x3D; torch.ones((64, 3, 32, 32)) #相当于64张图 每张图有3个通道 32*32的</span><br><span class="line">output &#x3D; tudui(input)</span><br><span class="line">print(output.shape)</span><br><span class="line"></span><br><span class="line">#可视化</span><br><span class="line">#writer &#x3D; SummaryWriter(&quot;..&#x2F;logs_seq&quot;)</span><br><span class="line">#writer.add_graph(tudui, input)</span><br><span class="line">#writer.close()</span><br></pre></td></tr></table></figure>

<p><img src="/2023/07/18/pytorch%E5%B0%8F%E5%9C%9F%E5%A0%86/7.png" alt></p>
<hr>
<h1 id="p23损失函数-误差-和反向传播-计算误差提供可以优化的点"><a href="#p23损失函数-误差-和反向传播-计算误差提供可以优化的点" class="headerlink" title="p23损失函数(误差)和反向传播(计算误差提供可以优化的点)"></a>p23损失函数(误差)和反向传播(计算误差提供可以优化的点)</h1><h2 id="两种损失函数和交叉熵"><a href="#两种损失函数和交叉熵" class="headerlink" title="两种损失函数和交叉熵"></a>两种损失函数和交叉熵</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">import torch</span><br><span class="line">from torch.nn import L1Loss</span><br><span class="line">from torch import nn</span><br><span class="line"></span><br><span class="line">#输入和目标</span><br><span class="line">inputs &#x3D; torch.tensor([1, 2, 3], dtype&#x3D;torch.float32)</span><br><span class="line">targets &#x3D; torch.tensor([1, 2, 5], dtype&#x3D;torch.float32)</span><br><span class="line">#规定想要的输入和目标的结果</span><br><span class="line">inputs &#x3D; torch.reshape(inputs, (1, 1, 1, 3))  #1个样本 通道为1 宽度为1*3</span><br><span class="line">targets &#x3D; torch.reshape(targets, (1, 1, 1, 3))</span><br><span class="line"></span><br><span class="line">loss&#x3D;L1Loss()</span><br><span class="line">result&#x3D;loss(inputs,targets) #tensor(0.6667)</span><br><span class="line">print(result) #[(1-1)+(2-2)+(5-3)]&#x2F;3</span><br><span class="line"></span><br><span class="line">loss2&#x3D;nn.MSELoss()</span><br><span class="line">result2&#x3D;loss2(inputs,targets) #tensor(1.3333)</span><br><span class="line">print(result2) #[(1-1)+(2-2)+(5-3)^2]&#x2F;3</span><br><span class="line"></span><br><span class="line">#交叉熵</span><br><span class="line">#使用在分类问题时候,有很多个类别</span><br><span class="line">x&#x3D;torch.tensor([0.1, 0.2, 0.3])</span><br><span class="line">y&#x3D;torch.tensor([1])</span><br><span class="line">x&#x3D;torch.reshape(x,(1, 3))  #3类</span><br><span class="line">loss_cross&#x3D;nn.CrossEntropyLoss()</span><br><span class="line">result3&#x3D;loss_cross(x,y) #tensor(1.1019)</span><br><span class="line">print(result3)</span><br></pre></td></tr></table></figure>

<p><img src="/2023/07/18/pytorch%E5%B0%8F%E5%9C%9F%E5%A0%86/9.png" alt></p>
<h2 id="带网络的"><a href="#带网络的" class="headerlink" title="带网络的"></a>带网络的</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">import torchvision</span><br><span class="line">from torch import nn</span><br><span class="line">from torch.nn import Sequential, Conv2d, MaxPool2d, Flatten, Linear</span><br><span class="line">from torch.utils.data import DataLoader</span><br><span class="line"></span><br><span class="line">#数据集</span><br><span class="line">dataset &#x3D; torchvision.datasets.CIFAR10(&quot;..&#x2F;data&quot;, train&#x3D;False, transform&#x3D;torchvision.transforms.ToTensor(),</span><br><span class="line">                                       download&#x3D;True)</span><br><span class="line"></span><br><span class="line">dataloader &#x3D; DataLoader(dataset, batch_size&#x3D;1)</span><br><span class="line"></span><br><span class="line">class Tudui(nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(Tudui, self).__init__()</span><br><span class="line">        #直接做成一个系列</span><br><span class="line">        self.model1 &#x3D; Sequential(</span><br><span class="line">            Conv2d(in_channels&#x3D;3, out_channels&#x3D;32,kernel_size&#x3D;5, padding&#x3D;2),  #padding&#x3D;2是根据输入输出的HW公式推出来   输入3个通道 输出维度32池化核5*5</span><br><span class="line">            MaxPool2d(2),  #默认池化层的stride步长&#x3D;池化核维度</span><br><span class="line">            Conv2d(in_channels&#x3D;32, out_channels&#x3D;32,kernel_size&#x3D;5, padding&#x3D;2), #padding&#x3D;2是根据输入输出的HW公式推出来   输入32个通道 输出维度32 池化核5*5</span><br><span class="line">            MaxPool2d(2),  #默认池化层的stride步长&#x3D;池化核维度</span><br><span class="line">            Conv2d(in_channels&#x3D;32, out_channels&#x3D;64,kernel_size&#x3D;5, padding&#x3D;2), #padding&#x3D;2是根据输入输出的HW公式推出来   输入32个通道 输出维度64 池化核5*5</span><br><span class="line">            MaxPool2d(2),  #默认池化层的stride步长&#x3D;池化核维度</span><br><span class="line">            Flatten(),  #展开</span><br><span class="line">            Linear(1024, 64),  #展开之后64*4*4&#x3D;1024个 一共有64个</span><br><span class="line">            Linear(64, 10)  #展开之后64个 一共10个</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        x &#x3D; self.model1(x)</span><br><span class="line">        return x</span><br><span class="line"></span><br><span class="line">#交叉熵</span><br><span class="line">loss &#x3D; nn.CrossEntropyLoss()</span><br><span class="line">tudui &#x3D; Tudui()</span><br><span class="line">for data in dataloader:</span><br><span class="line">    imgs, targets &#x3D; data</span><br><span class="line">    outputs &#x3D; tudui(imgs)</span><br><span class="line">    result_loss &#x3D; loss(outputs, targets)</span><br><span class="line">    print(result_loss)</span><br><span class="line">    print(&quot;ok&quot;)</span><br></pre></td></tr></table></figure>

<p><img src="/2023/07/18/pytorch%E5%B0%8F%E5%9C%9F%E5%A0%86/10.png" alt></p>
<hr>
<h1 id="p24优化器-让loss变小"><a href="#p24优化器-让loss变小" class="headerlink" title="p24优化器(让loss变小)"></a>p24优化器(让loss变小)</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">import torch.optim</span><br><span class="line">import torchvision</span><br><span class="line">from torch import nn</span><br><span class="line">from torch.nn import Sequential, Conv2d, MaxPool2d, Flatten, Linear</span><br><span class="line">from torch.utils.data import DataLoader</span><br><span class="line"></span><br><span class="line">#数据集</span><br><span class="line">dataset &#x3D; torchvision.datasets.CIFAR10(&quot;..&#x2F;data&quot;, train&#x3D;False, transform&#x3D;torchvision.transforms.ToTensor(),</span><br><span class="line">                                       download&#x3D;True)</span><br><span class="line"></span><br><span class="line">dataloader &#x3D; DataLoader(dataset, batch_size&#x3D;1)</span><br><span class="line"></span><br><span class="line">class Tudui(nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(Tudui, self).__init__()</span><br><span class="line">        #直接做成一个系列</span><br><span class="line">        self.model1 &#x3D; Sequential(</span><br><span class="line">            Conv2d(in_channels&#x3D;3, out_channels&#x3D;32,kernel_size&#x3D;5, padding&#x3D;2),  #padding&#x3D;2是根据输入输出的HW公式推出来   输入3个通道 输出维度32池化核5*5</span><br><span class="line">            MaxPool2d(2),  #默认池化层的stride步长&#x3D;池化核维度</span><br><span class="line">            Conv2d(in_channels&#x3D;32, out_channels&#x3D;32,kernel_size&#x3D;5, padding&#x3D;2), #padding&#x3D;2是根据输入输出的HW公式推出来   输入32个通道 输出维度32 池化核5*5</span><br><span class="line">            MaxPool2d(2),  #默认池化层的stride步长&#x3D;池化核维度</span><br><span class="line">            Conv2d(in_channels&#x3D;32, out_channels&#x3D;64,kernel_size&#x3D;5, padding&#x3D;2), #padding&#x3D;2是根据输入输出的HW公式推出来   输入32个通道 输出维度64 池化核5*5</span><br><span class="line">            MaxPool2d(2),  #默认池化层的stride步长&#x3D;池化核维度</span><br><span class="line">            Flatten(),  #展开</span><br><span class="line">            Linear(1024, 64),  #展开之后64*4*4&#x3D;1024个 一共有64个</span><br><span class="line">            Linear(64, 10)  #展开之后64个 一共10个</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        x &#x3D; self.model1(x)</span><br><span class="line">        return x</span><br><span class="line"></span><br><span class="line">#交叉熵</span><br><span class="line">loss &#x3D; nn.CrossEntropyLoss()</span><br><span class="line">tudui &#x3D; Tudui()</span><br><span class="line"></span><br><span class="line">#设置优化器</span><br><span class="line">optim&#x3D;torch.optim.SGD(tudui.parameters(),lr&#x3D;0.01) #入门设置两个参数 模型参数和学习速率</span><br><span class="line"></span><br><span class="line">for epoch in range(20):  #套循环</span><br><span class="line">    wucha&#x3D;0.0</span><br><span class="line">    for data in dataloader:</span><br><span class="line">        imgs, targets &#x3D; data</span><br><span class="line">        outputs &#x3D; tudui(imgs)</span><br><span class="line">        result_loss &#x3D; loss(outputs, targets)</span><br><span class="line">        </span><br><span class="line">		#增加优化器的部分</span><br><span class="line">        optim.zero_grad() #每次循环梯度清0</span><br><span class="line">        result_loss.backward()  #获取每个data计算grad</span><br><span class="line">        optim.step()  #进行优化  --&gt;最终将loss差距变小</span><br><span class="line">        #计算每一轮误差优化多少</span><br><span class="line">        wucha&#x3D;wucha+result_loss</span><br><span class="line"></span><br><span class="line">    print(result_loss)</span><br></pre></td></tr></table></figure>

<p><img src="/2023/07/18/pytorch%E5%B0%8F%E5%9C%9F%E5%A0%86/11.png" alt></p>
<hr>
<h1 id="p25现有模型"><a href="#p25现有模型" class="headerlink" title="p25现有模型"></a>p25现有模型</h1><h2 id="使用和修改"><a href="#使用和修改" class="headerlink" title="使用和修改"></a>使用和修改</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">import torchvision</span><br><span class="line">from torch import nn</span><br><span class="line"></span><br><span class="line">vgg16_false &#x3D; torchvision.models.vgg16(pretrained&#x3D;False)  #会下载到c盘 我的到C:\Users\larkkkkkkk\.cache\torch\hub\checkpoints</span><br><span class="line">vgg16_true &#x3D; torchvision.models.vgg16(pretrained&#x3D;True)</span><br><span class="line"></span><br><span class="line">print(vgg16_true)</span><br><span class="line"></span><br><span class="line">train_data &#x3D; torchvision.datasets.CIFAR10(&#39;.&#x2F;data&#39;, train&#x3D;True, transform&#x3D;torchvision.transforms.ToTensor(),</span><br><span class="line">                                          download&#x3D;True)</span><br><span class="line"></span><br><span class="line">#修改点！！！</span><br><span class="line"># (6): Linear(in_features&#x3D;4096, out_features&#x3D;1000, bias&#x3D;True)</span><br><span class="line"></span><br><span class="line">#要么加一层线性层输出10</span><br><span class="line">vgg16_true.add_module(&#39;add_Linear&#39;,nn.Linear(1000,10))     #在原来的classifier外面加</span><br><span class="line">#vgg16_true.classifier.add_module(&#39;add_Linear&#39;,nn.Linear(1000,10))  #在原来的classifier里面加</span><br><span class="line">print(vgg16_true)</span><br><span class="line"></span><br><span class="line">#要么将输出层改为10</span><br><span class="line">vgg16_false.classifier[6]&#x3D;nn.Linear(4096,10)</span><br><span class="line">print(vgg16_false)</span><br></pre></td></tr></table></figure>

<p><img src="/2023/07/18/pytorch%E5%B0%8F%E5%9C%9F%E5%A0%86/12.png" alt></p>
<h2 id="p26保存"><a href="#p26保存" class="headerlink" title="p26保存"></a>p26保存</h2><h3 id="保存方法1-模型结构-模型参数"><a href="#保存方法1-模型结构-模型参数" class="headerlink" title="保存方法1(模型结构+模型参数)"></a>保存方法1(模型结构+模型参数)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">import torch</span><br><span class="line">import torchvision</span><br><span class="line"></span><br><span class="line">vgg16&#x3D; torchvision.models.vgg16(pretrained&#x3D;False)  #会下载到c盘 我的到C:\Users\larkkkkkkk\.cache\torch\hub\checkpoints</span><br><span class="line"></span><br><span class="line">#保存</span><br><span class="line">torch.save(vgg16,&quot;vgg16_method1.pth&quot;)  #模型结构+模型参数</span><br></pre></td></tr></table></figure>

<p><img src="/2023/07/18/pytorch%E5%B0%8F%E5%9C%9F%E5%A0%86/13.png" alt></p>
<h3 id="保存方法2-模型参数"><a href="#保存方法2-模型参数" class="headerlink" title="保存方法2(模型参数)"></a>保存方法2(模型参数)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">import torch</span><br><span class="line">import torchvision</span><br><span class="line"></span><br><span class="line">vgg16&#x3D; torchvision.models.vgg16(pretrained&#x3D;False)  #会下载到c盘 我的到C:\Users\larkkkkkkk\.cache\torch\hub\checkpoints</span><br><span class="line"></span><br><span class="line">#保存</span><br><span class="line">torch.save(vgg16.state_dict(),&quot;vgg16_method2.pth&quot;) #模型参数  是字典形式!!!!</span><br></pre></td></tr></table></figure>

<p><img src="/2023/07/18/pytorch%E5%B0%8F%E5%9C%9F%E5%A0%86/15.png" alt></p>
<h2 id="p26读取"><a href="#p26读取" class="headerlink" title="p26读取"></a>p26读取</h2><h3 id="读取方法1-load"><a href="#读取方法1-load" class="headerlink" title="读取方法1(load)"></a>读取方法1(load)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">import torch</span><br><span class="line">import torchvision</span><br><span class="line">##读取方式1</span><br><span class="line">model&#x3D;torch.load(&quot;vgg16_method1.pth&quot;)</span><br><span class="line">print(model)</span><br></pre></td></tr></table></figure>

<p><img src="/2023/07/18/pytorch%E5%B0%8F%E5%9C%9F%E5%A0%86/14.png" alt></p>
<h3 id="读取方法2-考虑字典形式"><a href="#读取方法2-考虑字典形式" class="headerlink" title="读取方法2(考虑字典形式)"></a>读取方法2(考虑字典形式)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">import torch</span><br><span class="line">import torchvision</span><br><span class="line"></span><br><span class="line">#读取方式2</span><br><span class="line">vgg16&#x3D;torchvision.models.vgg16(pretrained&#x3D;False)</span><br><span class="line">vgg16.load_state_dict(torch.load(&quot;vgg16_method2.pth&quot;))</span><br><span class="line">print(vgg16)</span><br><span class="line">print(&quot;-----------------------------------------------------------------&quot;)</span><br><span class="line">#如果不使用加载dict 那么输出就是字典形式</span><br><span class="line">model2&#x3D;torch.load(&quot;vgg16_method2.pth&quot;)</span><br><span class="line">print(model2)</span><br></pre></td></tr></table></figure>

<p><img src="/2023/07/18/pytorch%E5%B0%8F%E5%9C%9F%E5%A0%86/16.png" alt></p>
<hr>
<h1 id="p27完整模型训练套路"><a href="#p27完整模型训练套路" class="headerlink" title="p27完整模型训练套路"></a>p27完整模型训练套路</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">import torchvision</span><br><span class="line">from torch.utils.tensorboard import SummaryWriter</span><br><span class="line">from model import *  # 引入model.py里的模型</span><br><span class="line">from torch import nn</span><br><span class="line">from torch.utils.data import DataLoader</span><br><span class="line"></span><br><span class="line"># 1.数据集</span><br><span class="line">##1.1准备数据集</span><br><span class="line">train_data &#x3D; torchvision.datasets.CIFAR10(root&#x3D;&quot;..&#x2F;data&quot;, train&#x3D;True, transform&#x3D;torchvision.transforms.ToTensor(),</span><br><span class="line">                                          download&#x3D;True)</span><br><span class="line">test_data &#x3D; torchvision.datasets.CIFAR10(root&#x3D;&quot;..&#x2F;data&quot;, train&#x3D;False, transform&#x3D;torchvision.transforms.ToTensor(),</span><br><span class="line">                                         download&#x3D;True)</span><br><span class="line">##1.2查看数据集内容</span><br><span class="line">train_data_size &#x3D; len(train_data)</span><br><span class="line">test_data_size &#x3D; len(test_data)</span><br><span class="line">print(&quot;训练集长度:&quot;, train_data_size)  # 训练集长度: 50000</span><br><span class="line">print(&quot;测试集长度:&quot;, test_data_size)  # 测试集长度: 10000</span><br><span class="line">##1.3加载数据集</span><br><span class="line">train_dataloader &#x3D; DataLoader(train_data, batch_size&#x3D;64)</span><br><span class="line">test_dataloader &#x3D; DataLoader(test_data, batch_size&#x3D;64)</span><br><span class="line"></span><br><span class="line"># 2.创建网络模型</span><br><span class="line">tudui &#x3D; Tudui()  # 引用model.py文件下的模型</span><br><span class="line">##2.1损失函数</span><br><span class="line">loss_fn &#x3D; nn.CrossEntropyLoss()</span><br><span class="line">##2.2优化器(反向传播时候用)</span><br><span class="line">optimizer &#x3D; torch.optim.SGD(tudui.parameters(), lr&#x3D;0.01)</span><br><span class="line"></span><br><span class="line"># 3.训练网络</span><br><span class="line">##3.1记录训练的次数</span><br><span class="line">total_train_step &#x3D; 0</span><br><span class="line">##3.2记录测试的次数</span><br><span class="line">total_test_step &#x3D; 0</span><br><span class="line">##3.3训练的轮数</span><br><span class="line">epoch &#x3D; 10</span><br><span class="line"></span><br><span class="line"># 添加tensorboard</span><br><span class="line">writer &#x3D; SummaryWriter(&quot;.&#x2F;logs_train&quot;)</span><br><span class="line"></span><br><span class="line">for i in range(epoch):</span><br><span class="line">    print(&quot;-------第 &#123;&#125; 轮训练开始-------&quot;.format(i + 1))</span><br><span class="line">    # 训练</span><br><span class="line">    tudui.train()  #有些特殊层需要调用(一般写上去也没事)</span><br><span class="line">    for data in train_dataloader:</span><br><span class="line">        imgs, targets &#x3D; data  # 图片和标签</span><br><span class="line">        outputs &#x3D; tudui(imgs)</span><br><span class="line">        loss &#x3D; loss_fn(outputs, targets)</span><br><span class="line"></span><br><span class="line">        # 优化器</span><br><span class="line">        optimizer.zero_grad()  # 每一轮梯度清0</span><br><span class="line">        loss.backward()  # 反向传播 计算出要优化的值</span><br><span class="line">        optimizer.step()  # 优化器优化</span><br><span class="line"></span><br><span class="line">        total_train_step &#x3D; total_train_step + 1</span><br><span class="line">        if total_train_step % 100 &#x3D;&#x3D; 0:</span><br><span class="line">            print(&quot;训练次数：&#123;&#125;, Loss: &#123;&#125;&quot;.format(total_train_step, loss.item()))</span><br><span class="line">            writer.add_scalar(&quot;train_loss&quot;, loss.item(), total_train_step)</span><br><span class="line"></span><br><span class="line">    # 测试</span><br><span class="line">    tudui.eval()  #有些特殊层需要调用(一般写上去也没事)</span><br><span class="line">    total_test_loss &#x3D; 0  #整体loss</span><br><span class="line">    total_accuracy &#x3D; 0  #整体准确率</span><br><span class="line">    with torch.no_grad():  #在训练之后没有梯度了才可以进循环</span><br><span class="line">        for data in test_dataloader:</span><br><span class="line">            imgs, targets &#x3D; data  # 图片和标签</span><br><span class="line">            outputs &#x3D; tudui(imgs)</span><br><span class="line">            # 一部分数据的损失</span><br><span class="line">            loss &#x3D; loss_fn(outputs, targets)</span><br><span class="line">            total_test_loss &#x3D; total_test_loss + loss.item()  # 每次损失增加</span><br><span class="line">            accuracy &#x3D; (outputs.argmax(1) &#x3D;&#x3D; targets).sum()  #整体准确率 用argmax可以判断[False,True].sum()&#x3D;1</span><br><span class="line">            total_accuracy &#x3D; total_accuracy + accuracy</span><br><span class="line"></span><br><span class="line">    print(&quot;整体测试集上的Loss: &#123;&#125;&quot;.format(total_test_loss))</span><br><span class="line">    print(&quot;整体测试集上的正确率: &#123;&#125;&quot;.format(total_accuracy &#x2F; test_data_size))</span><br><span class="line">    writer.add_scalar(&quot;test_loss&quot;, total_test_loss, total_test_step)</span><br><span class="line">    writer.add_scalar(&quot;test_accuracy&quot;, total_accuracy &#x2F; test_data_size, total_test_step)</span><br><span class="line">    total_test_step &#x3D; total_test_step + 1</span><br><span class="line"></span><br><span class="line">    torch.save(tudui, &quot;tudui_&#123;&#125;.pth&quot;.format(i))</span><br><span class="line">    print(&quot;模型已保存&quot;)</span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>

<p><img src="/2023/07/18/pytorch%E5%B0%8F%E5%9C%9F%E5%A0%86/17.png" alt></p>
<hr>
<h1 id="p30利用GPU训练"><a href="#p30利用GPU训练" class="headerlink" title="p30利用GPU训练"></a>p30利用GPU训练</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> </span><br><span class="line">在上一轮的代码中添加gpu训练</span><br></pre></td></tr></table></figure>

<p><strong>两者的区别和加入的位置:</strong></p>
<p><img src="/2023/07/18/pytorch%E5%B0%8F%E5%9C%9F%E5%A0%86/20.png" alt></p>
<h2 id="cuda"><a href="#cuda" class="headerlink" title=".cuda()"></a>.cuda()</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">import torchvision</span><br><span class="line">from torch.utils.tensorboard import SummaryWriter</span><br><span class="line">from model import *  # 引入model.py里的模型</span><br><span class="line">from torch import nn</span><br><span class="line">from torch.utils.data import DataLoader</span><br><span class="line"></span><br><span class="line"># 1.数据集</span><br><span class="line">##1.1准备数据集</span><br><span class="line">train_data &#x3D; torchvision.datasets.CIFAR10(root&#x3D;&quot;..&#x2F;data&quot;, train&#x3D;True, transform&#x3D;torchvision.transforms.ToTensor(),</span><br><span class="line">                                          download&#x3D;True)</span><br><span class="line">test_data &#x3D; torchvision.datasets.CIFAR10(root&#x3D;&quot;..&#x2F;data&quot;, train&#x3D;False, transform&#x3D;torchvision.transforms.ToTensor(),</span><br><span class="line">                                         download&#x3D;True)</span><br><span class="line">##1.2查看数据集内容</span><br><span class="line">train_data_size &#x3D; len(train_data)</span><br><span class="line">test_data_size &#x3D; len(test_data)</span><br><span class="line">print(&quot;训练集长度:&quot;, train_data_size)  # 训练集长度: 50000</span><br><span class="line">print(&quot;测试集长度:&quot;, test_data_size)  # 测试集长度: 10000</span><br><span class="line">##1.3加载数据集</span><br><span class="line">train_dataloader &#x3D; DataLoader(train_data, batch_size&#x3D;64)</span><br><span class="line">test_dataloader &#x3D; DataLoader(test_data, batch_size&#x3D;64)</span><br><span class="line"></span><br><span class="line"># 2.创建网络模型</span><br><span class="line">##2.1搭建神经网络</span><br><span class="line">class Tudui(nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(Tudui, self).__init__()</span><br><span class="line">        self.model &#x3D; nn.Sequential(</span><br><span class="line">            nn.Conv2d(3, 32, 5, 1, 2),</span><br><span class="line">            nn.MaxPool2d(2),</span><br><span class="line">            nn.Conv2d(32, 32, 5, 1, 2),</span><br><span class="line">            nn.MaxPool2d(2),</span><br><span class="line">            nn.Conv2d(32, 64, 5, 1, 2),</span><br><span class="line">            nn.MaxPool2d(2),</span><br><span class="line">            nn.Flatten(),</span><br><span class="line">            nn.Linear(64 * 4 * 4, 64),</span><br><span class="line">            nn.Linear(64, 10)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        x &#x3D; self.model(x)</span><br><span class="line">        return x</span><br><span class="line"></span><br><span class="line">tudui &#x3D; Tudui()  # 引用model.py文件下的模型</span><br><span class="line">tudui&#x3D;tudui.cuda()</span><br><span class="line"></span><br><span class="line">##2.2损失函数</span><br><span class="line">loss_fn &#x3D; nn.CrossEntropyLoss()</span><br><span class="line">loss_fn&#x3D;loss_fn.cuda()</span><br><span class="line"></span><br><span class="line">##2.3优化器(反向传播时候用)</span><br><span class="line">optimizer &#x3D; torch.optim.SGD(tudui.parameters(), lr&#x3D;0.01)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 3.训练网络</span><br><span class="line">##3.1记录训练的次数</span><br><span class="line">total_train_step &#x3D; 0</span><br><span class="line">##3.2记录测试的次数</span><br><span class="line">total_test_step &#x3D; 0</span><br><span class="line">##3.3训练的轮数</span><br><span class="line">epoch &#x3D; 10</span><br><span class="line"></span><br><span class="line"># 添加tensorboard</span><br><span class="line">writer &#x3D; SummaryWriter(&quot;.&#x2F;logs_train&quot;)</span><br><span class="line"></span><br><span class="line">for i in range(epoch):</span><br><span class="line">    print(&quot;-------第 &#123;&#125; 轮训练开始-------&quot;.format(i + 1))</span><br><span class="line">    # 训练</span><br><span class="line">    tudui.train()  #有些特殊层需要调用(一般写上去也没事)</span><br><span class="line">    for data in train_dataloader:</span><br><span class="line">        imgs, targets &#x3D; data  # 图片和标签</span><br><span class="line">        imgs&#x3D;imgs.cuda()</span><br><span class="line">        targets&#x3D;targets.cuda()</span><br><span class="line">        outputs &#x3D; tudui(imgs)</span><br><span class="line">        loss &#x3D; loss_fn(outputs, targets)</span><br><span class="line"></span><br><span class="line">        # 优化器</span><br><span class="line">        optimizer.zero_grad()  # 每一轮梯度清0</span><br><span class="line">        loss.backward()  # 反向传播 计算出要优化的值</span><br><span class="line">        optimizer.step()  # 优化器优化</span><br><span class="line"></span><br><span class="line">        total_train_step &#x3D; total_train_step + 1</span><br><span class="line">        if total_train_step % 100 &#x3D;&#x3D; 0:</span><br><span class="line">            print(&quot;训练次数：&#123;&#125;, Loss: &#123;&#125;&quot;.format(total_train_step, loss.item()))</span><br><span class="line">            writer.add_scalar(&quot;train_loss&quot;, loss.item(), total_train_step)</span><br><span class="line"></span><br><span class="line">    # 测试</span><br><span class="line">    tudui.eval()  #有些特殊层需要调用(一般写上去也没事)</span><br><span class="line">    total_test_loss &#x3D; 0  #整体loss</span><br><span class="line">    total_accuracy &#x3D; 0  #整体准确率</span><br><span class="line">    with torch.no_grad():</span><br><span class="line">        for data in test_dataloader:</span><br><span class="line">            imgs, targets &#x3D; data  # 图片和标签</span><br><span class="line">            imgs &#x3D; imgs.cuda()</span><br><span class="line">            targets &#x3D; targets.cuda()</span><br><span class="line">            outputs &#x3D; tudui(imgs)</span><br><span class="line">            # 一部分数据的损失</span><br><span class="line">            loss &#x3D; loss_fn(outputs, targets)</span><br><span class="line">            total_test_loss &#x3D; total_test_loss + loss.item()  # 每次损失增加</span><br><span class="line">            accuracy &#x3D; (outputs.argmax(1) &#x3D;&#x3D; targets).sum()  #整体准确率 用argmax可以判断[False,True].sum()&#x3D;1</span><br><span class="line">            total_accuracy &#x3D; total_accuracy + accuracy</span><br><span class="line"></span><br><span class="line">    print(&quot;整体测试集上的Loss: &#123;&#125;&quot;.format(total_test_loss))</span><br><span class="line">    print(&quot;整体测试集上的正确率: &#123;&#125;&quot;.format(total_accuracy &#x2F; test_data_size))</span><br><span class="line">    writer.add_scalar(&quot;test_loss&quot;, total_test_loss, total_test_step)</span><br><span class="line">    writer.add_scalar(&quot;test_accuracy&quot;, total_accuracy &#x2F; test_data_size, total_test_step)</span><br><span class="line">    total_test_step &#x3D; total_test_step + 1</span><br><span class="line"></span><br><span class="line">    torch.save(tudui, &quot;tudui_&#123;&#125;.pth&quot;.format(i))</span><br><span class="line">    print(&quot;模型已保存&quot;)</span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>

<p><strong>更改位置:</strong></p>
<p><img src="/2023/07/18/pytorch%E5%B0%8F%E5%9C%9F%E5%A0%86/18.png" alt></p>
<h2 id="torch-device-“cuda-0”"><a href="#torch-device-“cuda-0”" class="headerlink" title=".torch.device(“cuda:0”)"></a>.torch.device(“cuda:0”)</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">import torchvision</span><br><span class="line">from torch.utils.tensorboard import SummaryWriter</span><br><span class="line">from model import *  # 引入model.py里的模型</span><br><span class="line">from torch import nn</span><br><span class="line">from torch.utils.data import DataLoader</span><br><span class="line"></span><br><span class="line">#设置GPU</span><br><span class="line">device&#x3D;torch.device(&quot;cuda:0&quot;) #要考虑有几张卡</span><br><span class="line"></span><br><span class="line"># 1.数据集</span><br><span class="line">##1.1准备数据集</span><br><span class="line">train_data &#x3D; torchvision.datasets.CIFAR10(root&#x3D;&quot;..&#x2F;data&quot;, train&#x3D;True, transform&#x3D;torchvision.transforms.ToTensor(),</span><br><span class="line">                                          download&#x3D;True)</span><br><span class="line">test_data &#x3D; torchvision.datasets.CIFAR10(root&#x3D;&quot;..&#x2F;data&quot;, train&#x3D;False, transform&#x3D;torchvision.transforms.ToTensor(),</span><br><span class="line">                                         download&#x3D;True)</span><br><span class="line">##1.2查看数据集内容</span><br><span class="line">train_data_size &#x3D; len(train_data)</span><br><span class="line">test_data_size &#x3D; len(test_data)</span><br><span class="line">print(&quot;训练集长度:&quot;, train_data_size)  # 训练集长度: 50000</span><br><span class="line">print(&quot;测试集长度:&quot;, test_data_size)  # 测试集长度: 10000</span><br><span class="line">##1.3加载数据集</span><br><span class="line">train_dataloader &#x3D; DataLoader(train_data, batch_size&#x3D;64)</span><br><span class="line">test_dataloader &#x3D; DataLoader(test_data, batch_size&#x3D;64)</span><br><span class="line"></span><br><span class="line"># 2.创建网络模型</span><br><span class="line">##2.1搭建神经网络</span><br><span class="line">class Tudui(nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(Tudui, self).__init__()</span><br><span class="line">        self.model &#x3D; nn.Sequential(</span><br><span class="line">            nn.Conv2d(3, 32, 5, 1, 2),</span><br><span class="line">            nn.MaxPool2d(2),</span><br><span class="line">            nn.Conv2d(32, 32, 5, 1, 2),</span><br><span class="line">            nn.MaxPool2d(2),</span><br><span class="line">            nn.Conv2d(32, 64, 5, 1, 2),</span><br><span class="line">            nn.MaxPool2d(2),</span><br><span class="line">            nn.Flatten(),</span><br><span class="line">            nn.Linear(64 * 4 * 4, 64),</span><br><span class="line">            nn.Linear(64, 10)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        x &#x3D; self.model(x)</span><br><span class="line">        return x</span><br><span class="line"></span><br><span class="line">tudui &#x3D; Tudui()  # 引用model.py文件下的模型</span><br><span class="line">#tudui&#x3D;tudui.cuda()</span><br><span class="line">tudui&#x3D;tudui.to(device)</span><br><span class="line"></span><br><span class="line">##2.2损失函数</span><br><span class="line">loss_fn &#x3D; nn.CrossEntropyLoss()</span><br><span class="line">#loss_fn&#x3D;loss_fn.cuda()</span><br><span class="line">loss_fn&#x3D;loss_fn.to(device)</span><br><span class="line"></span><br><span class="line">##2.3优化器(反向传播时候用)</span><br><span class="line">optimizer &#x3D; torch.optim.SGD(tudui.parameters(), lr&#x3D;0.01)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 3.训练网络</span><br><span class="line">##3.1记录训练的次数</span><br><span class="line">total_train_step &#x3D; 0</span><br><span class="line">##3.2记录测试的次数</span><br><span class="line">total_test_step &#x3D; 0</span><br><span class="line">##3.3训练的轮数</span><br><span class="line">epoch &#x3D; 10</span><br><span class="line"></span><br><span class="line"># 添加tensorboard</span><br><span class="line">writer &#x3D; SummaryWriter(&quot;.&#x2F;logs_train&quot;)</span><br><span class="line"></span><br><span class="line">for i in range(epoch):</span><br><span class="line">    print(&quot;-------第 &#123;&#125; 轮训练开始-------&quot;.format(i + 1))</span><br><span class="line">    # 训练</span><br><span class="line">    tudui.train()  #有些特殊层需要调用(一般写上去也没事)</span><br><span class="line">    for data in train_dataloader:</span><br><span class="line">        imgs, targets &#x3D; data  # 图片和标签</span><br><span class="line">        #imgs&#x3D;imgs.cuda()</span><br><span class="line">        #targets&#x3D;targets.cuda()</span><br><span class="line">        imgs&#x3D;imgs.to(device)</span><br><span class="line">        targets&#x3D;targets.to(device)</span><br><span class="line">        outputs &#x3D; tudui(imgs)</span><br><span class="line">        loss &#x3D; loss_fn(outputs, targets)</span><br><span class="line"></span><br><span class="line">        # 优化器</span><br><span class="line">        optimizer.zero_grad()  # 每一轮梯度清0</span><br><span class="line">        loss.backward()  # 反向传播 计算出要优化的值</span><br><span class="line">        optimizer.step()  # 优化器优化</span><br><span class="line"></span><br><span class="line">        total_train_step &#x3D; total_train_step + 1</span><br><span class="line">        if total_train_step % 100 &#x3D;&#x3D; 0:</span><br><span class="line">            print(&quot;训练次数：&#123;&#125;, Loss: &#123;&#125;&quot;.format(total_train_step, loss.item()))</span><br><span class="line">            writer.add_scalar(&quot;train_loss&quot;, loss.item(), total_train_step)</span><br><span class="line"></span><br><span class="line">    # 测试</span><br><span class="line">    tudui.eval()  #有些特殊层需要调用(一般写上去也没事)</span><br><span class="line">    total_test_loss &#x3D; 0  #整体loss</span><br><span class="line">    total_accuracy &#x3D; 0  #整体准确率</span><br><span class="line">    with torch.no_grad():</span><br><span class="line">        for data in test_dataloader:</span><br><span class="line">            imgs, targets &#x3D; data  # 图片和标签</span><br><span class="line">            # imgs&#x3D;imgs.cuda()</span><br><span class="line">            # targets&#x3D;targets.cuda()</span><br><span class="line">            imgs &#x3D; imgs.to(device)</span><br><span class="line">            targets &#x3D; targets.to(device)</span><br><span class="line">            outputs &#x3D; tudui(imgs)</span><br><span class="line">            # 一部分数据的损失</span><br><span class="line">            loss &#x3D; loss_fn(outputs, targets)</span><br><span class="line">            total_test_loss &#x3D; total_test_loss + loss.item()  # 每次损失增加</span><br><span class="line">            accuracy &#x3D; (outputs.argmax(1) &#x3D;&#x3D; targets).sum()  #整体准确率 用argmax可以判断[False,True].sum()&#x3D;1</span><br><span class="line">            total_accuracy &#x3D; total_accuracy + accuracy</span><br><span class="line"></span><br><span class="line">    print(&quot;整体测试集上的Loss: &#123;&#125;&quot;.format(total_test_loss))</span><br><span class="line">    print(&quot;整体测试集上的正确率: &#123;&#125;&quot;.format(total_accuracy &#x2F; test_data_size))</span><br><span class="line">    writer.add_scalar(&quot;test_loss&quot;, total_test_loss, total_test_step)</span><br><span class="line">    writer.add_scalar(&quot;test_accuracy&quot;, total_accuracy &#x2F; test_data_size, total_test_step)</span><br><span class="line">    total_test_step &#x3D; total_test_step + 1</span><br><span class="line"></span><br><span class="line">    torch.save(tudui, &quot;tudui_&#123;&#125;.pth&quot;.format(i))</span><br><span class="line">    print(&quot;模型已保存&quot;)</span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>

<p><strong>更改位置:</strong></p>
<p><img src="/2023/07/18/pytorch%E5%B0%8F%E5%9C%9F%E5%A0%86/19.png" alt></p>
<hr>
<h1 id="p32完整模型验证套路"><a href="#p32完整模型验证套路" class="headerlink" title="p32完整模型验证套路"></a>p32完整模型验证套路</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">import torchvision</span><br><span class="line">from PIL import Image</span><br><span class="line">from torch import nn</span><br><span class="line"></span><br><span class="line">#读取图片</span><br><span class="line">image_path &#x3D; &quot;.&#x2F;imgs&#x2F;dog.png&quot;</span><br><span class="line">image &#x3D; Image.open(image_path)</span><br><span class="line">print(image)   #&lt;PIL.PngImagePlugin.PngImageFile image mode&#x3D;RGB size&#x3D;1053x825 at 0x26FB60DF880&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#png格式是四个通道，除了RGB以外还有一个透明度通道</span><br><span class="line">image&#x3D;image.convert(&#39;RGB&#39;)#保留其颜色通道</span><br><span class="line"></span><br><span class="line">transform &#x3D; torchvision.transforms.Compose([torchvision.transforms.Resize((32, 32)),  #网络输入是32*32维</span><br><span class="line">                                            torchvision.transforms.ToTensor()])</span><br><span class="line">image&#x3D;transform(image)</span><br><span class="line">print(image.shape)  #torch.Size([3, 32, 32])</span><br><span class="line"></span><br><span class="line">#模型</span><br><span class="line">class Tudui(nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(Tudui, self).__init__()</span><br><span class="line">        self.model &#x3D; nn.Sequential(</span><br><span class="line">            nn.Conv2d(3, 32, 5, 1, 2),</span><br><span class="line">            nn.MaxPool2d(2),</span><br><span class="line">            nn.Conv2d(32, 32, 5, 1, 2),</span><br><span class="line">            nn.MaxPool2d(2),</span><br><span class="line">            nn.Conv2d(32, 64, 5, 1, 2),</span><br><span class="line">            nn.MaxPool2d(2),</span><br><span class="line">            nn.Flatten(),</span><br><span class="line">            nn.Linear(64*4*4, 64),</span><br><span class="line">            nn.Linear(64, 10)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        x &#x3D; self.model(x)</span><br><span class="line">        return x</span><br><span class="line"></span><br><span class="line">model &#x3D; torch.load(&quot;tudui_29_gpu.pth&quot;, map_location&#x3D;torch.device(&#39;cpu&#39;))</span><br><span class="line">#print(model)</span><br><span class="line"></span><br><span class="line">#开始验证</span><br><span class="line">#输入时候记得设置batch_size</span><br><span class="line">image &#x3D; torch.reshape(image, (1, 3, 32, 32))</span><br><span class="line">model.eval()  #有些特殊层需要</span><br><span class="line"></span><br><span class="line">with torch.no_grad():</span><br><span class="line">    output &#x3D; model(image)</span><br><span class="line">print(&quot;预测结果是:&quot;,output)</span><br><span class="line"></span><br><span class="line">print(&quot;最大的可能是:&quot;,output.argmax(1))</span><br></pre></td></tr></table></figure>

<p><img src="/2023/07/18/pytorch%E5%B0%8F%E5%9C%9F%E5%A0%86/D:%5Cblog%5CLarkkkkkkk%5Csource_posts%5Cpytorch%E5%B0%8F%E5%9C%9F%E5%A0%86%5C21.png" alt></p>
<hr>

      
      
        <div class="page-reward">
          <p><a href="javascript:void(0)" onclick="dashangToggle()" class="dashang">赏</a></p>
          <div class="hide_box"></div>
          <div class="shang_box">
            <a class="shang_close" href="javascript:void(0)" onclick="dashangToggle()">×</a>
            <div class="shang_tit">
              <p>纯属好玩</p>
            </div>
            <div class="shang_payimg">
              <img src="/img/alipayimg.jpg" alt="扫码支持" title="扫一扫" />
            </div>
              <div class="pay_explain">扫码打赏，你说多少就多少</div>
            <div class="shang_payselect">
              
                <div class="pay_item checked" data-id="alipay">
                  <span class="radiobox"></span>
                  <span class="pay_logo"><img src="/img/alipay.png" alt="支付宝" /></span>
                </div>
              
              
                <div class="pay_item" data-id="wechat">
                  <span class="radiobox"></span>
                  <span class="pay_logo"><img src="/img/weixin.png" alt="微信" /></span>
                </div>
              
            </div>
            <div class="shang_info">
              <p>打开<span id="shang_pay_txt">支付宝</span>扫一扫，即可进行扫码打赏哦</p>
            </div>
          </div>
        </div>
        <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/zepto/1.2.0/zepto.min.js"></script>
        <script type="text/javascript">
          $(".pay_item").click(function(){
            $(this).addClass('checked').siblings('.pay_item').removeClass('checked');
            var dataid=$(this).attr('data-id');
            $(".shang_payimg img").attr("src","/img/"+dataid+"img.jpg");
            $("#shang_pay_txt").text(dataid=="alipay"?"支付宝":"微信");
          });
          function dashangToggle(){
            
            $(".hide_box").fadeToggle();
            $(".shang_box").fadeToggle();
          }
        </script>
      
    </div>
    
  </div>
  
    
    <div class="copyright">
        <p><span>本文标题:</span><a href="/2023/07/18/pytorch%E5%B0%8F%E5%9C%9F%E5%A0%86/">pytorch小土堆</a></p>
        <p><span>文章作者:</span><a href="/" title="访问 Larkkkkkkk 的个人博客">Larkkkkkkk</a></p>
        <p><span>发布时间:</span>2023年07月18日 - 17时20分</p>
        <p><span>最后更新:</span>2023年10月21日 - 21时47分</p>
        <p>
            <span>原始链接:</span><a class="post-url" href="/2023/07/18/pytorch%E5%B0%8F%E5%9C%9F%E5%A0%86/" title="pytorch小土堆">https://larkkkkkkk.github.io/2023/07/18/pytorch%E5%B0%8F%E5%9C%9F%E5%A0%86/</a>
            <span class="copy-path" data-clipboard-text="原文: https://larkkkkkkk.github.io/2023/07/18/pytorch%E5%B0%8F%E5%9C%9F%E5%A0%86/　　作者: Larkkkkkkk" title="点击复制文章链接"><i class="fa fa-clipboard"></i></span>
            <script src="/js/clipboard.min.js"></script>
            <script> var clipboard = new Clipboard('.copy-path'); </script>
        </p>
        <p>
            <span>许可协议:</span><i class="fa fa-creative-commons"></i> <a rel="license noopener" href="http://creativecommons.org/licenses/by-nc-sa/3.0/cn/" target="_blank" title="中国大陆 (CC BY-NC-SA 3.0 CN)" target = "_blank">"署名-非商用-相同方式共享 3.0"</a> 转载请保留原文链接及作者。
        </p>
    </div>



<nav id="article-nav">
  
    <a href="/2023/09/19/%E5%B0%9A%E7%A1%85%E8%B0%B7java/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption"><</strong>
      <div class="article-nav-title">
        
          尚硅谷JAVA基础
        
      </div>
    </a>
  
  
    <a href="/2023/06/04/python%E6%89%93%E5%8C%85/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">python打包</div>
      <strong class="article-nav-caption">></strong>
    </a>
  
</nav>

  
</article>

    <div id="toc" class="toc-article">
    <strong class="toc-title">文章目录</strong>
    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#学习链接"><span class="toc-number">1.</span> <span class="toc-text">学习链接</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#p16神经网络的基本骨架-nn-Module"><span class="toc-number">2.</span> <span class="toc-text">p16神经网络的基本骨架(nn.Module)</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#p17卷积操作"><span class="toc-number">3.</span> <span class="toc-text">p17卷积操作</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#p18卷积层"><span class="toc-number">4.</span> <span class="toc-text">p18卷积层</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#p19最大池化层"><span class="toc-number">5.</span> <span class="toc-text">p19最大池化层</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#p20非线性激活"><span class="toc-number">6.</span> <span class="toc-text">p20非线性激活</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#p21线性层和其它层介绍"><span class="toc-number">7.</span> <span class="toc-text">p21线性层和其它层介绍</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#p22实战和sequential的使用"><span class="toc-number">8.</span> <span class="toc-text">p22实战和sequential的使用</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#p23损失函数-误差-和反向传播-计算误差提供可以优化的点"><span class="toc-number">9.</span> <span class="toc-text">p23损失函数(误差)和反向传播(计算误差提供可以优化的点)</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#两种损失函数和交叉熵"><span class="toc-number">9.1.</span> <span class="toc-text">两种损失函数和交叉熵</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#带网络的"><span class="toc-number">9.2.</span> <span class="toc-text">带网络的</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#p24优化器-让loss变小"><span class="toc-number">10.</span> <span class="toc-text">p24优化器(让loss变小)</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#p25现有模型"><span class="toc-number">11.</span> <span class="toc-text">p25现有模型</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#使用和修改"><span class="toc-number">11.1.</span> <span class="toc-text">使用和修改</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#p26保存"><span class="toc-number">11.2.</span> <span class="toc-text">p26保存</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#保存方法1-模型结构-模型参数"><span class="toc-number">11.2.1.</span> <span class="toc-text">保存方法1(模型结构+模型参数)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#保存方法2-模型参数"><span class="toc-number">11.2.2.</span> <span class="toc-text">保存方法2(模型参数)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#p26读取"><span class="toc-number">11.3.</span> <span class="toc-text">p26读取</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#读取方法1-load"><span class="toc-number">11.3.1.</span> <span class="toc-text">读取方法1(load)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#读取方法2-考虑字典形式"><span class="toc-number">11.3.2.</span> <span class="toc-text">读取方法2(考虑字典形式)</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#p27完整模型训练套路"><span class="toc-number">12.</span> <span class="toc-text">p27完整模型训练套路</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#p30利用GPU训练"><span class="toc-number">13.</span> <span class="toc-text">p30利用GPU训练</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#cuda"><span class="toc-number">13.1.</span> <span class="toc-text">.cuda()</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#torch-device-“cuda-0”"><span class="toc-number">13.2.</span> <span class="toc-text">.torch.device(“cuda:0”)</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#p32完整模型验证套路"><span class="toc-number">14.</span> <span class="toc-text">p32完整模型验证套路</span></a></li></ol>
</div>
<input type="button" id="tocButton" value="隐藏目录"  title="点击按钮隐藏或者显示文章目录">


<script src="https://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js"></script>

<script>
    var valueHide = "隐藏目录";
    var valueShow = "显示目录";

    if ($(".left-col").is(":hidden")) {
        $("#tocButton").attr("value", valueShow);
    }
    $("#tocButton").click(function() {
        if ($("#toc").is(":hidden")) {
            $("#tocButton").attr("value", valueHide);
            $("#toc").slideDown(320);
        }
        else {
            $("#tocButton").attr("value", valueShow);
            $("#toc").slideUp(350);
        }
    })
    if ($(".toc").length < 1) {
        $("#toc, #tocButton").hide();
    }
</script>





<div class="bdsharebuttonbox">
	<a href="#" class="fx fa-weibo bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a>
	<a href="#" class="fx fa-weixin bds_weixin" data-cmd="weixin" title="分享到微信"></a>
	<a href="#" class="fx fa-qq bds_sqq" data-cmd="sqq" title="分享到QQ好友"></a>
	<a href="#" class="fx fa-facebook-official bds_fbook" data-cmd="fbook" title="分享到Facebook"></a>
	<a href="#" class="fx fa-twitter bds_twi" data-cmd="twi" title="分享到Twitter"></a>
	<a href="#" class="fx fa-linkedin bds_linkedin" data-cmd="linkedin" title="分享到linkedin"></a>
	<a href="#" class="fx fa-files-o bds_copy" data-cmd="copy" title="分享到复制网址"></a>
</div>
<script>window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"2","bdSize":"24"},"share":{}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];</script>




    
        <section id="comments">
  <div id="disqus_thread"></div>
    <script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'swing'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" target="_blank" rel="noopener">comments powered by Disqus.</a></noscript>
</section>
    



    <div class="scroll" id="post-nav-button">
        
            <a href="/2023/09/19/%E5%B0%9A%E7%A1%85%E8%B0%B7java/" title="上一篇: 尚硅谷JAVA基础">
                <i class="fa fa-angle-left"></i>
            </a>
        
        <a title="文章列表"><i class="fa fa-bars"></i><i class="fa fa-times"></i></a>
        
            <a href="/2023/06/04/python%E6%89%93%E5%8C%85/" title="下一篇: python打包">
                <i class="fa fa-angle-right"></i>
            </a>
        
    </div>
    <ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2023/10/28/JAVA-%E6%B3%9B%E5%9E%8B/">JAVA-泛型</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/10/24/JAVA-%E9%9B%86%E5%90%88%E6%A1%86%E6%9E%B6/">JAVA-集合框架</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/10/21/picgo/">picgo</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/10/20/%E4%BB%A3%E7%A0%81%E9%9A%8F%E6%83%B3%E5%BD%95-JAVA/">代码随想录</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/10/20/JAVA-%E5%B8%B8%E7%94%A8%E7%B1%BB%E5%92%8C%E5%9F%BA%E7%A1%80API/">JAVA-常用类和基础API</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/10/20/JAVA-%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/">JAVA-异常处理</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/10/20/JAVA-%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/">JAVA-面向对象</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/10/20/JAVA-%E5%9F%BA%E7%A1%80%E7%AF%87/">JAVA-基础篇</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/09/19/%E5%B0%9A%E7%A1%85%E8%B0%B7java/">尚硅谷JAVA基础</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/07/18/pytorch%E5%B0%8F%E5%9C%9F%E5%A0%86/">pytorch小土堆</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/06/04/python%E6%89%93%E5%8C%85/">python打包</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/25/pytorch/">pytorch</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/23/django/">django</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/22/flask%E6%8E%A5%E5%8F%A3/">flask接口</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/22/Docker/">Docker</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/22/JQ%E5%AE%9E%E7%8E%B0%E8%A1%A8%E5%8D%95%E6%A0%A1%E9%AA%8C/style/">JQ实现表单校验/style</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/22/JQ%E5%AE%9E%E7%8E%B0%E8%A1%A8%E5%8D%95%E6%A0%A1%E9%AA%8C/jquery-1.11.0/">JQ实现表单校验/jquery-1.11.0</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/22/JQ%E5%AE%9E%E7%8E%B0%E8%80%81%E9%BB%84%E5%8E%86/style/">JQ实现老黄历/style</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/22/JQ%E5%AE%9E%E7%8E%B0%E8%80%81%E9%BB%84%E5%8E%86/laohuangli/">JQ实现老黄历/laohuangli</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/22/JQ%E5%AE%9E%E7%8E%B0%E8%80%81%E9%BB%84%E5%8E%86/jquery-1.11.0/">JQ实现老黄历/jquery-1.11.0</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/22/JQ%E5%AE%9E%E7%8E%B0%E8%80%81%E9%BB%84%E5%8E%86/data/">JQ实现老黄历/data</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/22/JQuery%E9%80%89%E6%8B%A9%E5%99%A8/style/">JQuery选择器/style</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/22/JQuery%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/jquery-1.11.3.min/">JQuery基本用法/jquery-1.11.3.min</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/22/JQuery/jquery-1.11.0/">JQuery/jquery-1.11.0</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/22/Bootstrap/bootstrap-3.3.5-dist/js/npm/">Bootstrap/bootstrap-3.3.5-dist/js/npm</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/22/Bootstrap/bootstrap-3.3.5-dist/js/bootstrap.min/">Bootstrap/bootstrap-3.3.5-dist/js/bootstrap.min</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/22/Bootstrap/bootstrap-3.3.5-dist/js/bootstrap/">Bootstrap/bootstrap-3.3.5-dist/js/bootstrap</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/22/Bootstrap/bootstrap-3.3.5-dist/css/bootstrap.min/">Bootstrap/bootstrap-3.3.5-dist/css/bootstrap.min</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/22/Bootstrap/bootstrap-3.3.5-dist/css/bootstrap/">Bootstrap/bootstrap-3.3.5-dist/css/bootstrap</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/22/Bootstrap/bootstrap-3.3.5-dist/css/bootstrap-theme.min/">Bootstrap/bootstrap-3.3.5-dist/css/bootstrap-theme.min</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/22/Bootstrap/bootstrap-3.3.5-dist/css/bootstrap-theme/">Bootstrap/bootstrap-3.3.5-dist/css/bootstrap-theme</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/22/Larkkkkkkk/">Larkkkkkkk</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/04/17/py2neo/">py2neo</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/04/17/neo4j/">neo4j</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/04/16/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/">知识图谱</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/11/22/%E5%90%8E%E7%BC%80%E6%A0%91/">后缀树</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/11/11/%E7%94%9F%E7%89%A9%E4%BF%A1%E6%81%AF%E5%AD%A6/">生物信息学</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/11/02/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">动手学深度学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/11/01/Scrapy%E7%88%AC%E8%99%AB%E8%BF%9B%E9%98%B6/">Scrapy爬虫进阶</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/10/28/%E7%88%AC%E8%99%AB/">爬虫基础</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/10/26/%E7%AE%97%E6%B3%95%E6%B1%87%E6%80%BB%EF%BC%88Python%EF%BC%89/">算法汇总（Python）</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/10/15/CS224n%E6%96%AF%E5%9D%A6%E7%A6%8F%E6%B7%B1%E5%BA%A6%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E8%AF%BE/">CS224n斯坦福深度自然语言处理课</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/10/11/%E8%BD%AF%E4%BB%B6%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/">软件体系结构</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/10/10/%E5%8F%8C%E7%A2%B3%E5%A4%A7%E8%B5%9B-%E5%9E%83%E5%9C%BE%E5%88%86%E7%B1%BB/">双碳大赛-垃圾分类</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/10/07/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5/">PyTorch深度学习实践</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/10/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/">机器学习实战之工业蒸汽</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/09/17/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/">统计学习方法</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/09/06/%E5%88%A9%E7%94%A8python%E8%BF%9B%E8%A1%8C%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/">利用python进行数据分析</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/04/07/python%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E5%AE%9E%E8%B7%B5%E8%AF%BE%E6%9C%AC%E8%AF%BE%E5%90%8E%E9%A2%98/">python从入门到实践课本课后题</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/12/31/python/">python</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/06/28/B%E5%86%8C%E7%BC%96%E7%A8%8B%E9%A2%98/">B册编程题</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/06/23/c%E8%AF%AD%E8%A8%80%E8%AF%BE%E6%9C%AC%E9%A2%98%E7%9B%AE/">c语言课本题目</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/04/07/%E5%88%9D%E8%AF%95code/">初试code</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/25/%E7%A2%8E%E7%A2%8E%E5%BF%B5/">碎碎念</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/07/%E8%93%9D%E6%A1%A5%E6%9D%AF%E5%9B%BD%E8%B5%9B/">蓝桥杯国赛</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/10/23/Linux%E7%B3%BB%E7%BB%9F%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/">Linux系统目录结构</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/10/04/LeetCode%E9%93%BE%E8%A1%A8/">LeetCode链表</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/08/21/%E6%9C%AC%E5%9C%B0%E9%A1%B9%E7%9B%AE%E4%B8%8A%E4%BC%A0Github/">本地项目上传Github</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/08/13/JVM/">JVM</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/08/05/Mysql%E5%A4%8D%E4%B9%A0/">Mysql复习</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/08/02/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E6%80%BB%E7%BB%93/">设计模式总结</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/07/31/%E4%BA%AC%E4%B8%9C2019%E6%A0%A1%E6%8B%9B%E7%AC%94%E8%AF%95Java%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88%E7%AC%94%E8%AF%95%E9%A2%98/">京东2019校招笔试Java开发工程师笔试题</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/07/30/%E4%BA%AC%E4%B8%9C2019%E6%98%A5%E6%8B%9B%E4%BA%AC%E4%B8%9CJava%E5%BC%80%E5%8F%91%E8%AF%95%E5%8D%B7/">京东2019春招京东Java开发试卷</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/07/29/%E6%8B%BC%E5%A4%9A%E5%A4%9A2020%E6%A0%A1%E6%8B%9B%E9%83%A8%E5%88%86%E7%BC%96%E7%A8%8B%E9%A2%98%E5%90%88%E9%9B%86/">拼多多2020校招部分编程题合集</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/07/21/Git%E5%A4%8D%E4%B9%A0/">Git复习</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/07/16/leetcode%E5%89%91%E6%8C%87offer/">leetcode剑指offer</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/07/12/Hexo%E5%8D%9A%E5%AE%A2%E9%87%8D%E8%A3%85%E7%B3%BB%E7%BB%9F%E9%87%8D%E6%96%B0%E9%83%A8%E7%BD%B2/">Hexo博客重装系统重新部署</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/07/08/%E5%B0%9A%E5%AD%A6%E5%A0%82CRUD%E6%A8%A1%E6%9D%BF/">尚学堂CRUD模板</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/06/19/LeetCode%E7%B2%BE%E9%80%89TOP%E9%9D%A2%E8%AF%95%E9%A2%98/">LeetCode精选TOP面试题</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/06/16/LeetCode%E5%93%88%E5%B8%8C%E8%A1%A8/">LeetCode哈希表</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/06/16/LeetCode%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95/">LeetCode贪心算法</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/06/15/LeetCode%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/">LeetCode二分查找</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/06/14/LeetCode%E5%8F%8C%E6%8C%87%E9%92%88/">LeetCode双指针</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/06/13/LeetCode%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/">LeetCode动态规划</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/06/12/LeetCode%E6%95%B0%E5%AD%A6%E9%97%AE%E9%A2%98/">LeetCode数学问题</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/06/11/LeetCode%E9%80%92%E5%BD%92/">LeetCode递归</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/06/10/LeetCode%E6%8E%92%E5%BA%8F/">LeetCode排序</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/06/05/LeetCode%E5%AD%97%E7%AC%A6%E4%B8%B2/">LeetCode字符串</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/05/27/LeetCode%E6%95%B0%E7%BB%84/">LeetCode数组</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/05/11/%E5%89%91%E6%8C%87offer/">剑指offer</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/05/02/%E5%9B%BE/">图</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/05/01/%E5%93%88%E5%B8%8C%E8%A1%A8/">哈希表</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/22/%E5%93%88%E5%BC%97%E6%9B%BC%E6%A0%91/">哈弗曼树</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/18/%E4%BA%8C%E5%8F%89%E6%A0%91/">二叉树</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/18/%E6%A0%91/">树</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/15/%E6%8E%92%E5%BA%8F/">排序</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/15/%E6%97%B6%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%92%8C%E7%A9%BA%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%88%86%E6%9E%90/">时间复杂度和空间复杂度分析</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/14/%E9%80%92%E5%BD%92/">递归</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/12/SpringBoot/">SpringBoot</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/12/%E9%93%BE%E8%A1%A8/">链表</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/11/%E9%98%9F%E5%88%97/">队列</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/11/%E6%A0%88/">栈</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/11/SpringMVC%E5%AF%B9Date%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2/">SpringMVC对Date类型转换</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/11/SpringMVC%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/">SpringMVC原理分析</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/11/SpringMVC%E5%AE%9E%E7%8E%B0%E8%87%AA%E5%AE%9A%E4%B9%89%E6%8B%A6%E6%88%AA%E5%99%A8/">SpringMVC实现自定义拦截器</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/10/SpringMVC%E5%AE%9E%E7%8E%B0%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E5%92%8C%E4%B8%8B%E8%BD%BD/">SpringMVC实现文件上传和下载</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/09/JSP%E4%B9%9D%E5%A4%A7%E5%86%85%E7%BD%AE%E5%AF%B9%E8%B1%A1%E5%92%8C%E5%9B%9B%E5%A4%A7%E4%BD%9C%E7%94%A8%E5%9F%9F/">JSP九大内置对象和四大作用域</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/09/SpringMVC%E5%AE%9E%E7%8E%B0%E8%8F%9C%E5%8D%95%E5%8A%9F%E8%83%BD/">SpringMVC实现菜单功能</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/07/SpringMVC/">SpringMVC</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/06/Ajax%E6%95%B4%E7%90%86/">Ajax整理</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/06/Spring%E5%B8%B8%E7%94%A8%E6%B3%A8%E8%A7%A3%E6%95%B4%E7%90%86/">Spring常用注解整理</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/04/Spring%E4%BA%8B%E5%8A%A1/">Spring事务</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/04/Spring%E5%8D%95%E4%BE%8B%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/">Spring单例设计模式</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/04/Spring%E5%8A%A0%E8%BD%BD%E5%B1%9E%E6%80%A7%E6%96%87%E4%BB%B6%E5%92%8Cscope%E5%B1%9E%E6%80%A7/">Spring加载属性文件和scope属性</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/03/Spring%E8%87%AA%E5%8A%A8%E6%B3%A8%E5%85%A5/">Spring自动注入</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/03/Spring%E4%BB%A3%E7%90%86%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/">Spring代理设计模式</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/02/AOP/">AOP</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/01/Spring%E6%95%B4%E5%90%88Mybatis/">Spring整合Mybatis</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/01/Spring%E7%BB%99Bean%E6%B3%A8%E5%85%A5/">Spring给Bean注入</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/31/Spring/">Spring</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/31/Mybatis%E8%BF%90%E8%A1%8C%E5%8E%9F%E7%90%86%E6%80%BB%E7%BB%93/">Mybatis运行原理总结</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/30/Mybatis%E6%B3%A8%E8%A7%A3/">Mybatis注解</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/29/%E4%BD%BF%E7%94%A8Mybatis%E7%9A%84%E5%8A%A8%E6%80%81Sql%E5%AE%9E%E7%8E%B0%E5%A4%9A%E8%A1%A8%E6%9F%A5%E8%AF%A2/">使用Mybatis的动态Sql实现多表查询</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/28/Mybatis%E7%BC%93%E5%AD%98/">Mybatis缓存</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/28/ThreadLocal/">ThreadLocal</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/28/%E5%8A%A8%E6%80%81SQL/">动态SQL</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/27/getMapper%E6%8E%A5%E5%8F%A3%E7%BB%91%E5%AE%9A%E5%92%8C%E5%A4%9A%E5%8F%82%E6%95%B0%E4%BC%A0%E9%80%92/">getMapper接口绑定和多参数传递</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/25/Mybatis%E5%AE%9E%E7%8E%B0%E8%BD%AC%E8%B4%A6/">Mybatis实现转账</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/25/Mybatis%E5%AE%9E%E7%8E%B0%E5%88%86%E9%A1%B5%E5%8A%9F%E8%83%BD%EF%BC%88%E5%AE%8C%E6%95%B4%E6%B5%81%E7%A8%8B%EF%BC%89/">Mybatis实现分页功能（完整流程）</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/24/Mybatis%E5%AE%9E%E7%8E%B0%E6%96%B0%E5%A2%9E%E5%88%A0%E9%99%A4%E4%BF%AE%E6%94%B9%E5%92%8C%E4%BA%8B%E5%8A%A1%E8%AE%B2%E8%A7%A3/">Mybatis实现新增删除修改和事务讲解</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/24/Mybatis%E5%AE%9E%E7%8E%B0mysql%E5%88%86%E9%A1%B5/">Mybatis实现mysql分页</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/21/Mybatis%E6%9F%A5%E8%AF%A2%E6%89%80%E6%9C%89/">Mybatis查询所有</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/21/Log4J/">Log4J</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/20/Mybatis%E5%85%A8%E5%B1%80%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/">Mybatis全局配置文件详解</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/20/Mybatis%EF%BC%88eclipse%E8%AF%A6%E7%BB%86%EF%BC%89/">Mybatis（eclipse详细）</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/18/Mybatis%EF%BC%88idea+maven%EF%BC%89/">Mybatis（idea+maven）</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/17/Nginx/">Nginx</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/17/Linux%E9%83%A8%E7%BD%B2/">Linux部署</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/16/Linux%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86/">Linux网络知识</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/16/Vim/">Vim</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/14/maven/">maven</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/13/redis%E9%85%8D%E5%90%88ajax%E5%AE%9E%E7%8E%B0%E6%98%BE%E7%A4%BA%E4%B8%8B%E6%8B%89%E5%88%97%E8%A1%A8%E7%9C%81%E4%BB%BD/">redis配合ajax实现显示下拉列表省份</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/10/Linux%E5%AE%89%E8%A3%85%E8%BD%AF%E4%BB%B6/">Linux安装软件</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/10/redis/">redis</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/10/%E8%B0%B7%E6%AD%8CCar%E5%BC%95%E5%85%A5%E8%A3%85%E9%A5%B0%E8%80%85%E6%A8%A1%E5%BC%8F/">谷歌Car引入装饰者模式</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/10/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/">设计模式</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/10/%E6%B3%A8%E8%A7%A3/">注解</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/08/%E8%87%AA%E5%8A%A8%E7%99%BB%E5%BD%95%EF%BC%88%E8%BF%87%E6%BB%A4%E5%99%A8%EF%BC%89/">自动登录（过滤器）</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/08/Filter/">Filter</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/07/JQuery%E7%9C%81%E5%B8%82%E8%81%94%E5%8A%A8/">JQuery省市联动</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/06/Listener/">Listener</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/06/JQuery%E4%BB%BF%E7%99%BE%E5%BA%A6%E6%90%9C%E7%B4%A2/">JQuery仿百度搜索</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/06/JQuery%E6%A0%A1%E9%AA%8C%E7%94%A8%E6%88%B7%E5%90%8D/">JQuery校验用户名</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/06/JQuery%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/">JQuery基本用法</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/05/Ajax%E5%AE%9E%E7%8E%B0%E6%A0%A1%E9%AA%8C%E7%94%A8%E6%88%B7%E5%90%8D/">Ajax实现校验用户名</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/04/Ajax/">Ajax</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/29/%E5%AD%A6%E7%94%9F%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%EF%BC%882-0%EF%BC%89/">学生管理系统（2.0）</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/29/%E4%B8%89%E5%B1%82%E6%9E%B6%E6%9E%84/">三层架构</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/29/JSP%E5%BC%80%E5%8F%91%E6%A8%A1%E5%BC%8F/">JSP开发模式</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/29/DBUtils%E9%80%9A%E7%94%A8%E7%9A%84%E5%A2%9E%E5%88%A0%E6%9F%A5%E6%94%B9/">DBUtils通用的增删查改</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/29/DBUtils/">DBUtils</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/28/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0/">数据库连接池</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/27/%E4%BA%8B%E5%8A%A1/">事务</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/27/%E5%AD%A6%E7%94%9F%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/">学生管理系统</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/26/JSTL/">JSTL</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/26/EL%E8%A1%A8%E8%BE%BE%E5%BC%8F/">EL表达式</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/25/JSP/">JSP</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/25/Session%E5%AE%9E%E7%8E%B0%E8%B4%AD%E7%89%A9%E8%BD%A6/">Session实现购物车</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/24/Cookie%E8%8E%B7%E5%8F%96%E5%95%86%E5%93%81%E6%B5%8F%E8%A7%88%E8%AE%B0%E5%BD%95/">Cookie获取商品浏览记录</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/24/Cookie%E8%8E%B7%E5%8F%96%E4%B8%8A%E6%AC%A1%E7%99%BB%E5%BD%95%E6%97%B6%E9%97%B4/">Cookie获取上次登录时间</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/23/Session/">Session</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/23/Cookie/">Cookie</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/19/Linux/">Linux</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/18/ServletContext/">ServletContext</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/18/HTTPServletReauest%E5%92%8CHTTPServletResponse/">HTTPServletReauest和HTTPServletResponse</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/17/Servlet/">Servlet</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/17/HTTP%E5%8D%8F%E8%AE%AE/">HTTP协议</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/16/Tomcat/">Tomcat</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/16/dom4j%E5%85%A5%E9%97%A8/">dom4j入门</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/15/XML/">XML</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/15/%E6%95%B0%E6%8D%AE%E5%BA%93cmd%E7%9A%84%E6%93%8D%E4%BD%9C%EF%BC%88%E4%BB%A5%E5%90%8E%E5%86%99%EF%BC%89/">数据库cmd的操作（以后写）</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/15/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E5%88%9B%E5%BB%BA%E6%9F%A5%E7%9C%8B%E5%88%A0%E9%99%A4/">数据库的创建查看删除</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/14/JDBC%E4%B8%AD%E7%9A%84JAVAEE%E7%BB%93%E6%9E%84/">JDBC中的JAVAEE结构</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/13/JDBC%E5%AF%B9%E4%BA%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84CRUD/">数据库的CRUD</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/12/%E6%95%B0%E6%8D%AE%E5%BA%93/">数据库</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/12/JDBC%E7%9A%84%E5%B7%A5%E5%85%B7%E7%B1%BB/">JDBC的工具类</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/12/JDBC/">JDBC</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/12/bootstrap%E5%AE%9E%E7%8E%B0%E7%BD%91%E7%AB%99%E9%A6%96%E9%A1%B5/">bootstrap实现网站首页</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/12/boostrap%E5%AE%9E%E7%8E%B0%E5%AF%BC%E8%88%AA%E6%9D%A1/">boostrap实现导航条</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/10/JQ%E5%AE%9E%E7%8E%B0%E8%80%81%E9%BB%84%E5%8E%86/">JQ实现老黄历</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/10/JQ%E5%AE%9E%E7%8E%B0%E8%A1%A8%E5%8D%95%E6%A0%A1%E9%AA%8C/">JQ实现表单校验</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/10/Bootstrap/">Bootstrap</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/09/JQ%E5%AE%9E%E7%8E%B0%E5%95%86%E5%93%81%E5%B7%A6%E5%8F%B3%E9%80%89%E6%8B%A9/">JQ实现商品左右选择</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/09/JQ%E5%AE%9E%E7%8E%B0%E7%9C%81%E5%B8%82%E8%81%94%E5%8A%A8/">JQ实现省市联动</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/09/JQ%E5%AE%9E%E7%8E%B0%E8%A1%A8%E6%A0%BC%E5%8F%98%E8%89%B2%E5%92%8C%E5%85%A8%E9%80%89%E9%97%AE%E9%A2%98/">JQ实现表格隔行换色</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/09/JQ%E5%AE%9E%E7%8E%B0%E8%A1%A8%E5%8D%95%E5%B1%9E%E6%80%A7%E8%BF%87%E6%BB%A4/">JQ实现表单属性过滤</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/08/JQuery%E9%80%89%E6%8B%A9%E5%99%A8/">JQuery选择器</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/08/JQuery%E5%AE%9E%E7%8E%B0%E5%AE%9A%E6%97%B6%E6%92%AD%E6%94%BE%E5%B9%BF%E5%91%8A/">JQuery实现定时播放广告</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/07/JQuery/">JQuery</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/07/JS%E6%8E%A7%E5%88%B6%E4%B8%8B%E6%8B%89%E5%88%97%E8%A1%A8%E5%B7%A6%E5%8F%B3%E9%80%89%E6%8B%A9/">JS控制下拉列表左右选择</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/07/JS%E5%AE%9E%E7%8E%B0%E8%A1%A8%E5%8D%95%E6%A3%80%E9%AA%8C%EF%BC%88%E4%BD%BF%E7%94%A8onfoucs%E7%AD%89%E7%84%A6%E7%82%B9%E6%97%B6%E9%97%B4%EF%BC%89/">JS实现表单检验（使用onfoucs等焦点时间）</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/07/JS%E5%AE%9E%E7%8E%B0%E8%A1%A8%E6%A0%BC%E5%8F%98%E8%89%B2%E5%92%8C%E5%85%A8%E9%80%89%E9%97%AE%E9%A2%98/">JS实现表格变色和全选问题</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/07/JS%E5%AE%9E%E7%8E%B0DOM%E6%93%8D%E4%BD%9C%EF%BC%88%E5%85%B3%E4%BA%8Eselect%E6%A0%87%E7%AD%BE%E7%9A%84%E4%B8%8B%E6%8B%89%E7%9C%81%E5%B8%82%E8%81%94%E5%8A%A8%EF%BC%89/">JS实现DOM操作（关于select标签的下拉省市联动）</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/05/JS%E5%AE%9E%E7%8E%B0%E8%87%AA%E5%8A%A8%E6%92%AD%E6%94%BE%E5%B9%BF%E5%91%8A/">JS实现页面表单表格</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/05/JS%E5%AE%9E%E7%8E%B0%E8%BD%AE%E6%92%AD%E5%9B%BE/">JS实现轮播图</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/04/JS/">JS</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/04/CSS%E7%BD%91%E7%AB%99%E6%B3%A8%E5%86%8C%E6%A1%88%E4%BE%8B/">CSS网站注册案例</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/04/CSS-div%E5%AE%9E%E7%8E%B0%E7%BD%91%E7%AB%99%E9%A6%96%E9%A1%B5%E4%BC%98%E5%8C%96/">CSS+div实现网站首页优化</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/02/CSS/">CSS和DIV</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/02/HTML%E7%BD%91%E7%AB%99%E5%90%8E%E5%8F%B0%E6%A1%88%E4%BE%8B/">网站后台案例</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/02/HTML%E7%BD%91%E7%AB%99%E6%B3%A8%E5%86%8C%E6%A1%88%E4%BE%8B/">网站注册案例</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/01/HTML%E7%BD%91%E7%AB%99%E9%A6%96%E9%A1%B5%E6%A1%88%E4%BE%8B/">HTML网站首页案例</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/01/HTML/">HTML</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/01/30/%E5%8F%8D%E5%B0%84/">反射</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/01/28/%E7%A8%80%E7%96%8F%E6%95%B0%E7%BB%84/">稀疏数组</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/12/30/%E7%BD%91%E7%BB%9C%E8%AF%BE%E8%AE%BE/">网络课设</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/12/19/webserver/">webserver</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/25/TCP/">TCP编程</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/17/%E4%BC%A0%E8%BE%93%E5%8D%8F%E8%AE%AE/">传输协议(UDP)</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/13/%E7%AC%AC%E5%8D%81%E5%B1%8A%E8%93%9D%E6%A1%A5%E6%9D%AF%E7%9C%81%E8%B5%9B/">第十届蓝桥杯省赛</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/12/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/">网络编程</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/11/%E7%AD%89%E5%BE%85%E5%94%A4%E9%86%92%E6%9C%BA%E5%88%B6/">等待唤醒机制</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/07/%E8%93%9D%E6%A1%A5%E6%9D%AF%E6%A0%A1%E8%B5%9B/">蓝桥杯校赛</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/07/%E7%BA%BF%E7%A8%8B%E7%8A%B6%E6%80%81/">线程状态</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/05/%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8/">线程安全</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/04/JAVA-%E5%A4%9A%E7%BA%BF%E7%A8%8B/">JAVA-多线程</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/02/List/">List接口</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/02/Set/">Set集合</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/31/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/">正则表达式(regex)</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/29/%E8%BF%AD%E4%BB%A3%E5%99%A8/">集合2</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/29/%E6%B3%9B%E5%9E%8B/">泛型</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/26/%E8%93%9D%E6%A1%A5%E6%9D%AF%E7%BB%83%E4%B9%A0/">蓝桥杯</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/26/%E9%9B%86%E5%90%88/">集合1</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/24/Lambda/">Lambda表达式</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/23/%E9%A1%B5%E9%9D%A2/">人机交互实验</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/17/%E5%9B%9E%E6%BA%AF%E6%B3%95/">回溯算法</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/15/%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95/">贪心算法</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/11/%E7%88%AC%E6%A5%BC%E6%A2%AF/">以爬楼梯为例</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/11/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/">动态规划</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/08/idea%E5%AE%89%E8%A3%85/">IntelliJ IDEA</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/08/%E6%8E%A5%E9%9B%A8%E6%B0%B4(%E5%8F%8C%E6%8C%87%E9%92%88)/">接雨水</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/08/%E4%B9%98%E6%9B%B4%E5%A4%9A%E7%9A%84%E6%B0%B4(%E5%8F%8C%E6%8C%87%E9%92%88)/">乘更多的水</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/04/wenzipian2/">文字篇2-《码农翻身》</a></li></ul>
    <script src="https://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js"></script>
    <script>
        $(".post-list").addClass("toc-article");
        $(".post-list-item a").attr("target","_blank");
        $("#post-nav-button > a:nth-child(2)").click(function() {
            $(".fa-bars, .fa-times").toggle();
            $(".post-list").toggle(300);
            if ($(".toc").length > 0) {
                $("#toc, #tocButton").toggle(200, function() {
                    if ($(".switch-area").is(":visible")) {
                        $("#tocButton").attr("value", valueHide);
                        }
                    })
            }
            else {
            }
        })
    </script>



    <script>
        
    </script>
</div>
      <footer id="footer">
    <div class="outer">
        <div id="footer-info">
            <div class="footer-left">
                &copy; 2023 Larkkkkkkk
            </div>
            <div class="footer-right">
                <a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="http://bestwing.me" target="_blank">Sw'blog</a> by Swing
            </div>
        </div>
        
            <div class="visit">
                
                    <span id="busuanzi_container_site_pv" style='display:none'>
                        <span id="site-visit" >海贼到访数: 
                            <span id="busuanzi_value_site_uv"></span>
                        </span>
                    </span>
                
                
                    <span>, </span>
                
                
                    <span id="busuanzi_container_page_pv" style='display:none'>
                        <span id="page-visit">本页阅读量: 
                            <span id="busuanzi_value_page_pv"></span>
                        </span>
                    </span>
                
            </div>
        
    </div>
</footer>

    </div>
    
<script src="https://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js"></script>


<script src="/js/main.js"></script>


    <script>
        $(document).ready(function() {
            var backgroundnum = 24;
            var backgroundimg = "url(/background/bg-x.jpg)".replace(/x/gi, Math.ceil(Math.random() * backgroundnum));
            $("#mobile-nav").css({"background-image": backgroundimg,"background-size": "cover","background-position": "center"});
            $(".left-col").css({"background-image": backgroundimg,"background-size": "cover","background-position": "center"});
        })
    </script>





<div class="scroll" id="scroll">
    <a href="#"><i class="fa fa-arrow-up"></i></a>
    <a href="#comments"><i class="fa fa-comments-o"></i></a>
    <a href="#footer"><i class="fa fa-arrow-down"></i></a>
</div>
<script>
    $(document).ready(function() {
        if ($("#comments").length < 1) {
            $("#scroll > a:nth-child(2)").hide();
        };
    })
</script>

<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>

  <script language="javascript">
    $(function() {
        $("a[title]").each(function() {
            var a = $(this);
            var title = a.attr('title');
            if (title == undefined || title == "") return;
            a.data('title', title).removeAttr('title').hover(

            function() {
                var offset = a.offset();
                $("<div id=\"anchortitlecontainer\"></div>").appendTo($("body")).html(title).css({
                    top: offset.top - a.outerHeight() - 15,
                    left: offset.left + a.outerWidth()/2 + 1
                }).fadeIn(function() {
                    var pop = $(this);
                    setTimeout(function() {
                        pop.remove();
                    }, pop.text().length * 800);
                });
            }, function() {
                $("#anchortitlecontainer").remove();
            });
        });
    });
</script>


    <script type="text/javascript">
      window.onload = function(){
        document.getElementById("search").onclick = function(){
            console.log("search")
            search();
        }
      }
      function search(){
        (function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){
        (w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);
        e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);
        })(window,document,'script','//s.swiftypecdn.com/install/v2/st.js','_st');

        _st('install','A1Pz-LKMXbrzcFg2FWi6','2.0.0');
      }
    </script>

  </div>
</body>
</html>