<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>机器学习 | Larkkkkkkk</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="机器学习计划学习思路1234561.用书	西瓜书(机器学习)	python机器学习(蜥蜴书)2.视频	b站浙大教授带你全面解读机器学习西瓜书！	黑马程序员3天机器学习入门  参考视频pdf文件参考笔记  机器学习简介相关关系 应用领域12341.传统预测:店铺销量预测&#x2F;量化投资&#x2F;广告推荐&#x2F;企业客户分类&#x2F;sql语句安全监测分类2.图像识别:人脸识别&#x2F;">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习">
<meta property="og:url" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/index.html">
<meta property="og:site_name" content="Larkkkkkkk">
<meta property="og:description" content="机器学习计划学习思路1234561.用书	西瓜书(机器学习)	python机器学习(蜥蜴书)2.视频	b站浙大教授带你全面解读机器学习西瓜书！	黑马程序员3天机器学习入门  参考视频pdf文件参考笔记  机器学习简介相关关系 应用领域12341.传统预测:店铺销量预测&#x2F;量化投资&#x2F;广告推荐&#x2F;企业客户分类&#x2F;sql语句安全监测分类2.图像识别:人脸识别&#x2F;">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/1.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/3.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/4.1.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/4.2.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/4.3.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/4.4.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/4.5.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/4.6.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/4.7.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/4.8.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/4.10.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/4.9.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/4.11.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/4.12.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/4.13.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/4.14.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/4.15.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/4.16.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/4.17.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/4.18.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/4.19.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/4.20.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/4.21.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/4.22.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/4.23.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/4.24.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/4.25.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/4.26.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/4.27.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/4.28.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/4.29.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/4.30.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/4.31.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/4.32.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/4.33.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/4.34.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/4.35.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/4.38.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/4.36.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/4.37.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/4.39.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/4.40.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/4.41.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/4.42.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/4.43.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/4.44.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/4.45.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/4.46.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/4.47.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/4.48.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/4.49.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/4.50.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/4.51.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/4.52.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/53.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/54.png">
<meta property="article:published_time" content="2022-04-01T02:04:02.000Z">
<meta property="article:modified_time" content="2022-09-30T05:42:48.000Z">
<meta property="article:author" content="Larkkkkkkk">
<meta property="article:tag" content="机器学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/1.png">
  
    <link rel="alternative" href="/atom.xml" title="Larkkkkkkk" type="application/atom+xml">
  
  
    <link rel="icon" href="/http://oayoilchh.bkt.clouddn.com/2016/07/27/18:05:26%20">
  
  
      
<link rel="stylesheet" href="//cdn.bootcss.com/animate.css/3.5.0/animate.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  <link rel="stylesheet" href="/font-awesome/css/font-awesome.min.css">
  <link rel="apple-touch-icon" href="/apple-touch-icon.png">
  
  
      <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  
  <!-- 加载特效 -->
    <script src="/js/pace.js"></script>
    <link href="/css/pace/pace-theme-flash.css" rel="stylesheet" />
  <script>
      var yiliaConfig = {
          rootUrl: '/',
          fancybox: true,
          animate: true,
          isHome: false,
          isPost: true,
          isArchive: false,
          isTag: false,
          isCategory: false,
          open_in_new: false
      }
  </script>
<meta name="generator" content="Hexo 4.2.1"></head>
<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
    <header id="header" class="inner">
        <script src="http://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js"></script>
        <a href="/" class="profilepic">
            
            <img lazy-src="img/head.jpg" class="js-avatar">
            
        </a>
        <hgroup>
          <h1 class="header-author"><a href="/">Larkkkkkkk</a></h1>
        </hgroup>
        
        
            <form>
                <input type="text" class="st-default-search-input search" id="local-search-input" placeholder="搜索一下" autocomplete="off">
            </form>
            <div id="local-search-result"></div>
        
        
            <script type="text/javascript">
                (function() {
                    'use strict';
                    function getMatchData(keyword, data) {
                        var matchData = [];
                        for(var i =0;i<data.length;i++){
                            if(data[i].title.toLowerCase().indexOf(keyword)>=0) 
                                matchData.push(data[i])
                        }
                        return matchData;
                    }
                    var $input = $('#local-search-input');
                    var $resultContent = $('#local-search-result');
                    $input.keyup(function(){
                        $.ajax({
                            url: '/search.json',
                            dataType: "json",
                            success: function( json ) {
                                var str='<ul class=\"search-result-list\">';                
                                var keyword = $input.val().trim().toLowerCase();
                                $resultContent.innerHTML = "";
                                if ($input.val().trim().length <= 0) {
                                    $resultContent.empty();
                                    $('#switch-area').show();
                                    return;
                                }
                                var results = getMatchData(keyword, json);
                                if(results.length === 0){
                                    $resultContent.empty();
                                    $('#switch-area').show();
                                    return;
                                } 
                                for(var i =0; i<results.length; i++){
                                    str += "<li><a href='"+ results[i].url +"' class='search-result-title'>"+ results[i].title +"</a></li>";
                                }
                                str += "</ul>";
                                $resultContent.empty();
                                $resultContent.append(str);
                                $('#switch-area').hide();
                            }
                        });
                    });
                })();
            </script>
        
        
            <div id="switch-btn" class="switch-btn">
                <div class="icon">
                    <div class="icon-ctn">
                        <div class="icon-wrap icon-house" data-idx="0">
                            <div class="birdhouse"></div>
                            <div class="birdhouse_holes"></div>
                        </div>
                        <div class="icon-wrap icon-ribbon hide" data-idx="1">
                            <div class="ribbon"></div>
                        </div>
                        
                        <div class="icon-wrap icon-link hide" data-idx="2">
                            <div class="loopback_l"></div>
                            <div class="loopback_r"></div>
                        </div>
                        
                        
                        <div class="icon-wrap icon-me hide" data-idx="3">
                            <div class="user"></div>
                            <div class="shoulder"></div>
                        </div>
                        
                    </div>
                </div>
                <div class="tips-box hide">
                    <div class="tips-arrow"></div>
                    <ul class="tips-inner">
                        <li>菜单</li>
                        <li>标签</li>
                        
                        <li>友情链接</li>
                        
                        
                        <li>关于我</li>
                        
                    </ul>
                </div>
            </div>
        
        <div id="switch-area" class="switch-area">
            <div class="switch-wrap">
                <section class="switch-part switch-part1">
                    <nav class="header-menu">
                        <ul>
                        
                            <li><a  href="https://github.com/Larkkkkkkk" target="_blank" rel="noopener">博客首页</a></li>
                        
                            <li><a  href="/archives">文章归档</a></li>
                        
                            <li><a  href="/CTFStudy">学习导航</a></li>
                        
                            <li><a  href="/PWNABLE">PWNABLE</a></li>
                        
                            <li><a  href="/resume">个人简历</a></li>
                        
                        </ul>
                    </nav>
                    <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fl mail"  target="_blank" href="http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&email=U2JgZ2ZlY2VmamATIiJ9MDw_" title="mail">mail</a>
                            
                                <a class="fl github"  target="_blank" href="https://github.com/Larkkkkkkk" title="github">github</a>
                            
                                <a class="fl zhihu"  target="_blank" href="https://www.zhihu.com/people/plain-3-78/activities" title="zhihu">zhihu</a>
                            
                                <a class="fl weibo"  target="_blank" href="https://weibo.com/5304208276/profile?topnav=1&wvr=6" title="weibo">weibo</a>
                            
                                <a class="fl rss"  target="_blank" href="/atom.xml" title="rss">rss</a>
                            
                        </ul>
                    </nav>
                </section>
                
                <section class="switch-part switch-part2">
                    <div class="widget tagcloud" id="js-tagcloud">
                        <a href="/tags/Ajax/" style="font-size: 12.22px;">Ajax</a> <a href="/tags/Cookie%E5%92%8CSession/" style="font-size: 14.44px;">Cookie和Session</a> <a href="/tags/DBUtils/" style="font-size: 11.11px;">DBUtils</a> <a href="/tags/Docker/" style="font-size: 10px;">Docker</a> <a href="/tags/EL%E8%A1%A8%E8%BE%BE%E5%BC%8F/" style="font-size: 10px;">EL表达式</a> <a href="/tags/Filter/" style="font-size: 11.11px;">Filter</a> <a href="/tags/HTTP/" style="font-size: 10px;">HTTP</a> <a href="/tags/HTTPServletReauest%E5%92%8CHTTPServletResponse/" style="font-size: 10px;">HTTPServletReauest和HTTPServletResponse</a> <a href="/tags/IDEA%E5%AE%89%E8%A3%85%E5%92%8C%E7%A0%B4%E8%A7%A3/" style="font-size: 10px;">IDEA安装和破解</a> <a href="/tags/JAVA/" style="font-size: 15.56px;">JAVA</a> <a href="/tags/JAVA-Lambda%E8%A1%A8%E8%BE%BE%E5%BC%8F/" style="font-size: 10px;">JAVA-Lambda表达式</a> <a href="/tags/JAVA-Set%E9%9B%86%E5%90%88/" style="font-size: 10px;">JAVA-Set集合</a> <a href="/tags/JAVA-%E5%8F%8D%E5%B0%84/" style="font-size: 10px;">JAVA-反射</a> <a href="/tags/JAVA-%E5%A4%9A%E7%BA%BF%E7%A8%8B/" style="font-size: 12.22px;">JAVA-多线程</a> <a href="/tags/JAVA-%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/" style="font-size: 10px;">JAVA-正则表达式</a> <a href="/tags/JAVA-%E6%B3%9B%E5%9E%8B/" style="font-size: 10px;">JAVA-泛型</a> <a href="/tags/JAVA-%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/" style="font-size: 12.22px;">JAVA-网络编程</a> <a href="/tags/JAVA-%E9%9B%86%E5%90%88/" style="font-size: 12.22px;">JAVA-集合</a> <a href="/tags/JAVA%E7%BB%83%E4%B9%A0/" style="font-size: 11.11px;">JAVA练习</a> <a href="/tags/JAVA%E7%BB%83%E4%B9%A0-%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/" style="font-size: 10px;">JAVA练习-动态规划</a> <a href="/tags/JQuery/" style="font-size: 13.33px;">JQuery</a> <a href="/tags/JSP/" style="font-size: 10px;">JSP</a> <a href="/tags/JVM/" style="font-size: 10px;">JVM</a> <a href="/tags/LeetCode/" style="font-size: 17.78px;">LeetCode</a> <a href="/tags/Linux/" style="font-size: 15.56px;">Linux</a> <a href="/tags/Listener/" style="font-size: 10px;">Listener</a> <a href="/tags/Mybatis/" style="font-size: 18.89px;">Mybatis</a> <a href="/tags/Mysql/" style="font-size: 10px;">Mysql</a> <a href="/tags/Mysql%E6%95%B0%E6%8D%AE%E5%BA%93%E5%92%8CJDBC/" style="font-size: 15.56px;">Mysql数据库和JDBC</a> <a href="/tags/Redis/" style="font-size: 11.11px;">Redis</a> <a href="/tags/Servlet/" style="font-size: 11.11px;">Servlet</a> <a href="/tags/Spring/" style="font-size: 16.67px;">Spring</a> <a href="/tags/SpringBoot/" style="font-size: 10px;">SpringBoot</a> <a href="/tags/SpringMVC/" style="font-size: 15.56px;">SpringMVC</a> <a href="/tags/Tomcat/" style="font-size: 10px;">Tomcat</a> <a href="/tags/Web%E5%89%8D%E7%AB%AF%E7%9F%A5%E8%AF%86%E7%82%B9/" style="font-size: 20px;">Web前端知识点</a> <a href="/tags/XML/" style="font-size: 11.11px;">XML</a> <a href="/tags/django/" style="font-size: 10px;">django</a> <a href="/tags/flask%E6%A1%86%E6%9E%B6/" style="font-size: 10px;">flask框架</a> <a href="/tags/git/" style="font-size: 10px;">git</a> <a href="/tags/jsp%E6%A0%87%E5%87%86%E6%A0%87%E7%AD%BE%E5%BA%93/" style="font-size: 10px;">jsp标准标签库</a> <a href="/tags/maven/" style="font-size: 10px;">maven</a> <a href="/tags/picture/" style="font-size: 10px;">picture</a> <a href="/tags/python/" style="font-size: 12.22px;">python</a> <a href="/tags/pytorch/" style="font-size: 10px;">pytorch</a> <a href="/tags/ssm%E6%A1%86%E6%9E%B6%E6%A8%A1%E6%9D%BF/" style="font-size: 10px;">ssm框架模板</a> <a href="/tags/webserver%E7%BC%96%E7%A8%8B/" style="font-size: 10px;">webserver编程</a> <a href="/tags/%E4%BA%8B%E5%8A%A1/" style="font-size: 10px;">事务</a> <a href="/tags/%E4%BA%AC%E4%B8%9C/" style="font-size: 11.11px;">京东</a> <a href="/tags/%E5%90%8E%E7%BC%80%E6%A0%91/" style="font-size: 10px;">后缀树</a> <a href="/tags/%E5%93%88%E5%B8%8C%E8%A1%A8/" style="font-size: 10px;">哈希表</a> <a href="/tags/%E5%9B%BE/" style="font-size: 10px;">图</a> <a href="/tags/%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%88%86%E6%9E%90/" style="font-size: 10px;">复杂度分析</a> <a href="/tags/%E5%AD%A6%E7%94%9F%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/" style="font-size: 10px;">学生管理系统</a> <a href="/tags/%E5%AD%A6%E7%94%9F%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F2-0/" style="font-size: 12.22px;">学生管理系统2.0</a> <a href="/tags/%E6%8B%BC%E5%A4%9A%E5%A4%9A/" style="font-size: 10px;">拼多多</a> <a href="/tags/%E6%8E%92%E5%BA%8F/" style="font-size: 10px;">排序</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/" style="font-size: 10px;">数据分析</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0/" style="font-size: 10px;">数据库连接池</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%A8%80%E7%96%8F%E6%95%B0%E7%BB%84/" style="font-size: 10px;">数据结构-稀疏数组</a> <a href="/tags/%E6%96%87%E5%AD%97%E7%AF%87-%E8%AE%B0%E5%BD%95/" style="font-size: 10px;">文字篇-记录</a> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="font-size: 12.22px;">机器学习</a> <a href="/tags/%E6%A0%88/" style="font-size: 10px;">栈</a> <a href="/tags/%E6%A0%91/" style="font-size: 12.22px;">树</a> <a href="/tags/%E6%B3%A8%E8%A7%A3/" style="font-size: 10px;">注解</a> <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" style="font-size: 14.44px;">深度学习</a> <a href="/tags/%E7%88%AC%E8%99%AB/" style="font-size: 11.11px;">爬虫</a> <a href="/tags/%E7%94%9F%E7%89%A9%E4%BF%A1%E6%81%AF%E5%AD%A6/" style="font-size: 10px;">生物信息学</a> <a href="/tags/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/" style="font-size: 12.22px;">知识图谱</a> <a href="/tags/%E7%A0%94%E7%A9%B6%E7%94%9F%E5%88%9D%E8%AF%95/" style="font-size: 12.22px;">研究生初试</a> <a href="/tags/%E7%A7%8B%E6%8B%9B/" style="font-size: 10px;">秋招</a> <a href="/tags/%E7%AE%97%E6%B3%95-%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/" style="font-size: 10px;">算法-动态规划</a> <a href="/tags/%E7%AE%97%E6%B3%95-%E5%9B%9E%E6%BA%AF%E6%B3%95/" style="font-size: 10px;">算法-回溯法</a> <a href="/tags/%E7%AE%97%E6%B3%95-%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95/" style="font-size: 10px;">算法-贪心算法</a> <a href="/tags/%E8%80%83%E7%A0%94/" style="font-size: 10px;">考研</a> <a href="/tags/%E8%93%9D%E6%A1%A5%E6%9D%AF/" style="font-size: 13.33px;">蓝桥杯</a> <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E8%AF%BE%E8%AE%BE-%E8%BD%AF%E4%BB%B6%E4%B8%93%E4%B8%9A%E9%A2%98%E7%9B%AE/" style="font-size: 10px;">计算机网络课设(软件专业题目)</a> <a href="/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/" style="font-size: 12.22px;">设计模式</a> <a href="/tags/%E8%BD%AF%E4%BB%B6%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/" style="font-size: 10px;">软件体系结构</a> <a href="/tags/%E9%80%92%E5%BD%92/" style="font-size: 10px;">递归</a> <a href="/tags/%E9%87%8D%E6%96%B0%E9%83%A8%E7%BD%B2/" style="font-size: 10px;">重新部署</a> <a href="/tags/%E9%93%BE%E8%A1%A8/" style="font-size: 10px;">链表</a> <a href="/tags/%E9%98%9F%E5%88%97/" style="font-size: 10px;">队列</a> <a href="/tags/%E9%9D%A2%E8%AF%95/" style="font-size: 10px;">面试</a> <a href="/tags/%E9%A1%B5%E9%9D%A2%EF%BC%88H5-CSS%EF%BC%89/" style="font-size: 10px;">页面（H5+CSS）</a> <a href="/tags/%E9%A1%B9%E7%9B%AE%E4%B8%8A%E4%BC%A0/" style="font-size: 10px;">项目上传</a>
                    </div>
                </section>
                
                
                <section class="switch-part switch-part3">
                    <div id="js-friends">
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://ring3.xyz/">Yllen</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://mxny.org/">麦香浓郁</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://whereisk0shl.top/">K0sh1</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://www.ycjcl.cc/">信鑫</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://bystudent.com/">ByStundet表哥</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="https://www.jarviswang.me/">汪神_Jarvis</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://sh3ll.me/">Chu</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="https://www.hackfun.org/">4ido10n</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://www.cnblogs.com/iamstudy">L3m0n</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://o0xmuhe.me/">muhe</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://blog.nuptzj.cn/">_画船听雨</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://www.virzz.com/index.html">Virink</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://www.sqlsec.com/">国光</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://www.bodkin.ren/">老锥</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://www.cizel.cn/">C1zel</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://1phan.cc">1phan</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="https://www.liuil.top/">liuil</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://www.cnblogs.com/Ox9A82/">Ox9A82</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://burnegg.com/">burnegg</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="https://jwrsec.cn/">jwr-sec</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://sudalover.cn/">苏打</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://blog.binklac.com">VeroFess</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://www.bendawang.site/">bendawang</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://weeklyalgo.codes/">hook</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://www.flier.net.cn/">Flier&#39;blog</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://www.mutepig.club">mutepig</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="https://blog.iret.xyz/list.aspx">Silver</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://simp1e.leanote.com/">Simple</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://processor.pub/">Processor</a>
                    
                    </div>
                </section>
                
                
                
                <section class="switch-part switch-part4">
                
                    <div id="js-aboutme">一只淹死在二进制海洋里的二进制狗!</div>
                </section>
                
            </div>
        </div>
    </header>
</div>

    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
      <div class="overlay">
          <div class="slider-trigger"></div>
          <h1 class="header-author js-mobile-header hide"><a href="/" title="Me">Larkkkkkkk</a></h1>
      </div>
    <div class="intrude-less">
        <header id="header" class="inner">
            <a href="/" class="profilepic">
                
                    <img lazy-src="/img/head.jpg" class="js-avatar">
                
            </a>
            <hgroup>
              <h1 class="header-author"><a href="/" title="Me">Larkkkkkkk</a></h1>
            </hgroup>
            
            <nav class="header-menu">
                <ul>
                
                    <li><a href="https://github.com/Larkkkkkkk" target="_blank" rel="noopener">博客首页</a></li>
                
                    <li><a href="/archives">文章归档</a></li>
                
                    <li><a href="/CTFStudy">学习导航</a></li>
                
                    <li><a href="/PWNABLE">PWNABLE</a></li>
                
                    <li><a href="/resume">个人简历</a></li>
                
                <div class="clearfix"></div>
                </ul>
            </nav>
            <nav class="header-nav">
                <div class="social">
                    
                        <a class="mail" target="_blank" href="http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&email=U2JgZ2ZlY2VmamATIiJ9MDw_" title="mail">mail</a>
                    
                        <a class="github" target="_blank" href="https://github.com/Larkkkkkkk" title="github">github</a>
                    
                        <a class="zhihu" target="_blank" href="https://www.zhihu.com/people/plain-3-78/activities" title="zhihu">zhihu</a>
                    
                        <a class="weibo" target="_blank" href="https://weibo.com/5304208276/profile?topnav=1&wvr=6" title="weibo">weibo</a>
                    
                        <a class="rss" target="_blank" href="/atom.xml" title="rss">rss</a>
                    
                </div>
            </nav>
        </header>                
    </div>
</nav>
      <div class="body-wrap"><article id="post-机器学习" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="article-date">
      <time datetime="2022-04-01T02:04:02.000Z" itemprop="datePublished">2022-04-01</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      机器学习
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        

        
    <div class="article-tag tagcloud">
        <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a></li></ul>
    </div>

        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h1 id="机器学习计划"><a href="#机器学习计划" class="headerlink" title="机器学习计划"></a>机器学习计划</h1><h2 id="学习思路"><a href="#学习思路" class="headerlink" title="学习思路"></a>学习思路</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1.用书</span><br><span class="line">	西瓜书(机器学习)</span><br><span class="line">	python机器学习(蜥蜴书)</span><br><span class="line">2.视频</span><br><span class="line">	b站浙大教授带你全面解读机器学习西瓜书！</span><br><span class="line">	黑马程序员3天机器学习入门</span><br></pre></td></tr></table></figure>

<h2 id="参考视频pdf文件"><a href="#参考视频pdf文件" class="headerlink" title="参考视频pdf文件"></a>参考视频pdf文件</h2><p><a href="机器学习.pdf">参考笔记</a></p>
<hr>
<h1 id="机器学习简介"><a href="#机器学习简介" class="headerlink" title="机器学习简介"></a>机器学习简介</h1><h2 id="相关关系"><a href="#相关关系" class="headerlink" title="相关关系"></a>相关关系</h2><p><img src="1.png" alt=""></p>
<h2 id="应用领域"><a href="#应用领域" class="headerlink" title="应用领域"></a>应用领域</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">1.传统预测:店铺销量预测&#x2F;量化投资&#x2F;广告推荐&#x2F;企业客户分类&#x2F;sql语句安全监测分类</span><br><span class="line">2.图像识别:人脸识别&#x2F;街道交通标志检测</span><br><span class="line">3.自然语言处理:文本分类&#x2F;情感分析&#x2F;自动聊天</span><br></pre></td></tr></table></figure>

<h2 id="相关概念"><a href="#相关概念" class="headerlink" title="相关概念"></a>相关概念</h2><h3 id="数据集-特征值-目标值"><a href="#数据集-特征值-目标值" class="headerlink" title="数据集(特征值+目标值)"></a>数据集(特征值+目标值)</h3><p><img src="2.png" alt=""></p>
<h3 id="常见三类问题"><a href="#常见三类问题" class="headerlink" title="常见三类问题"></a>常见三类问题</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1.**分类问题**:给一堆小猫小狗 --&gt; 分类是小狗还是小猫</span><br><span class="line">2.**回归问题**:给一堆房价和地理位置等信息 --&gt; 得到连续的房价数据</span><br><span class="line">3.**聚类问题**:给一堆属性信息 --&gt; 合成在一起</span><br></pre></td></tr></table></figure>

<h3 id="算法分类"><a href="#算法分类" class="headerlink" title="算法分类"></a>算法分类</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1.监督学习(**预测**):输入数据有特征有标签(有标准答案)---分类和回归</span><br><span class="line">	1.1 分类： k-近邻算法&#x2F;贝叶斯分类&#x2F;决策树与随机森林&#x2F;逻辑回归&#x2F;神经网络</span><br><span class="line">	1.2 回归: 线性回归&#x2F;岭回归</span><br><span class="line">2.无监督学习:输入数据有特征无标签(无标准答案)---聚类</span><br><span class="line">	2.1 聚类： k-means</span><br></pre></td></tr></table></figure>

<h3 id="开发流程"><a href="#开发流程" class="headerlink" title="开发流程"></a>开发流程</h3><p><img src="3.png" alt=""></p>
<hr>
<h1 id="特征工程"><a href="#特征工程" class="headerlink" title="特征工程"></a>特征工程</h1><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><h3 id="可用数据集"><a href="#可用数据集" class="headerlink" title="可用数据集"></a>可用数据集</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">1. Kaggle:https:&#x2F;&#x2F;www.kaggle.com&#x2F;datasets</span><br><span class="line">	1.1 数据量巨大</span><br><span class="line">	1.2 真实数据</span><br><span class="line">	1.3 80万科学家</span><br><span class="line">	1.4 大数据竞赛平台</span><br><span class="line">2. UCI：http:&#x2F;&#x2F;archive.ics.uci.edu&#x2F;ml&#x2F;</span><br><span class="line">	2.1 数据量几十万</span><br><span class="line">	2.2 涵盖科学&#x2F;生活&#x2F;经济等领域</span><br><span class="line">	2.3 收录360个数据集</span><br><span class="line">3. scikit-learn：https:&#x2F;&#x2F;scikit-learn.org&#x2F;stable&#x2F;</span><br><span class="line">	3.1 数据量较小</span><br><span class="line">	3.2 方便学习</span><br></pre></td></tr></table></figure>

<h3 id="sklearn数据集"><a href="#sklearn数据集" class="headerlink" title="sklearn数据集"></a>sklearn数据集</h3><h4 id="sklearn数据集内容"><a href="#sklearn数据集内容" class="headerlink" title="sklearn数据集内容"></a>sklearn数据集内容</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1.分类&#x2F;聚类&#x2F;回归</span><br><span class="line">2.特征工程</span><br><span class="line">3.模型选择&#x2F;调优</span><br></pre></td></tr></table></figure>

<h4 id="sklearn获取流行数据集-datasets"><a href="#sklearn获取流行数据集-datasets" class="headerlink" title="sklearn获取流行数据集(datasets)"></a>sklearn获取流行数据集(datasets)</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1.sklearn.datasets  --- 加载获取流行数据集</span><br><span class="line">	1.1 datasets.load_*()  ---获取小规模数据集</span><br><span class="line">		数据包含在datasets里</span><br><span class="line">	1.2 datasets.fetch_*(data_home&#x3D;None)  ---获取大规模数据集</span><br><span class="line">		需要从网络上下载，函数的第一个参数是data_home，表示数据集下载的目录,默认是 ~&#x2F;scikit_learn_data&#x2F;</span><br></pre></td></tr></table></figure>

<h4 id="sklearn小数据集-load"><a href="#sklearn小数据集-load" class="headerlink" title="sklearn小数据集(load)"></a>sklearn小数据集(load)</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from sklearn import datasets</span><br><span class="line">iris&#x3D;datasets.load_iris()</span><br><span class="line">print(iris)</span><br><span class="line">----------------------------------</span><br><span class="line">from sklearn import datasets</span><br><span class="line">boston&#x3D;datasets.load_boston()</span><br><span class="line">print(boston)</span><br></pre></td></tr></table></figure>

<p><img src="4.1.png" alt=""></p>
<h4 id="sklearn大数据集-fetch"><a href="#sklearn大数据集-fetch" class="headerlink" title="sklearn大数据集(fetch)"></a>sklearn大数据集(fetch)</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">from sklearn import datasets</span><br><span class="line">newgroup&#x3D;datasets.fetch_20newsgroups()</span><br><span class="line">print(newgroup)</span><br></pre></td></tr></table></figure>

<p><img src="4.2.png" alt=""></p>
<h4 id="sklearn返回值-字典格式"><a href="#sklearn返回值-字典格式" class="headerlink" title="sklearn返回值(字典格式)"></a>sklearn返回值(字典格式)</h4><p><strong>以鸢尾花为例(iris)</strong></p>
<p><img src="4.3.png" alt=""></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#load和fetch均返回数据类型是datasets.base.Bunch(字典格式)</span><br><span class="line"></span><br><span class="line">	1.data：特征数据数组(特征值)</span><br><span class="line">	2.target：标签数组(目标值)</span><br><span class="line">	3.DESCR：数据描述</span><br><span class="line">	4.feature_names:特征名</span><br><span class="line">	5.target_names:目标名</span><br></pre></td></tr></table></figure>

<h3 id="数据集划分"><a href="#数据集划分" class="headerlink" title="数据集划分"></a>数据集划分</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">数据集划分：</span><br><span class="line">	1.训练数据: 用于训练&#x2F;构建模型</span><br><span class="line">	2.测试数据: 用于评估模型是否有效</span><br><span class="line">数据集划分比例：</span><br><span class="line">	训练集: 70% 80% 75%</span><br><span class="line">	测试集: 30% 20% 30%</span><br></pre></td></tr></table></figure>

<h4 id="数据集划分API-model-selection"><a href="#数据集划分API-model-selection" class="headerlink" title="数据集划分API(model_selection)"></a>数据集划分API(model_selection)</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sklearn.model_selection.train_test_split(arrays,*option)</span><br><span class="line">	1.x: 特征值</span><br><span class="line">	2.y: 目标值</span><br><span class="line">	3.test_size: 测试集大小(一般是float&#x2F;默认是0.25)</span><br><span class="line">	4.random_state: 随机数种子(相同种子采样结果相同)</span><br></pre></td></tr></table></figure>

<p><strong>使用鸢尾花数据集:</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">from sklearn import datasets</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line"></span><br><span class="line">iris&#x3D;datasets.load_iris()</span><br><span class="line"></span><br><span class="line">#训练集特征值x_train</span><br><span class="line">#测试集特征值x_test</span><br><span class="line">#训练集目标值y_train</span><br><span class="line">#测试集目标值y_test</span><br><span class="line">x_train,x_test,y_train,y_test&#x3D;train_test_split(iris.data,iris.target,random_state&#x3D;22)   #随机数种子是22  测试集大小默认是0.25</span><br><span class="line">print(f&quot;训练集特征值x_train: &#123;x_train&#125;&quot;)</span><br><span class="line">print(f&quot;测试集特征值x_test: &#123;x_test&#125;&quot;)</span><br><span class="line">print(f&quot;训练集目标值y_train: &#123;y_train&#125;&quot;)</span><br><span class="line">print(f&quot;测试集目标值y_test: &#123;y_test&#125;&quot;)</span><br></pre></td></tr></table></figure>

<p><img src="4.4.png" alt=""></p>
<hr>
<h2 id="特征工程介绍"><a href="#特征工程介绍" class="headerlink" title="特征工程介绍"></a>特征工程介绍</h2><h3 id="特征提取-sklearn-feature-extraction"><a href="#特征提取-sklearn-feature-extraction" class="headerlink" title="特征提取(sklearn.feature_extraction)"></a>特征提取(sklearn.feature_extraction)</h3><ul>
<li>任意数据(文本/图像) –&gt; 数字特征(机器学习)</li>
</ul>
<h4 id="特征提取分类"><a href="#特征提取分类" class="headerlink" title="特征提取分类"></a>特征提取分类</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1.字典特征提取(特征离散化) </span><br><span class="line">2.文本特征提取</span><br><span class="line">3.图像特征提取(深度学习)</span><br></pre></td></tr></table></figure>

<h4 id="字典特征提取-DictVectorizer类"><a href="#字典特征提取-DictVectorizer类" class="headerlink" title="字典特征提取(DictVectorizer类)"></a>字典特征提取(DictVectorizer类)</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#有三个方法:</span><br><span class="line">1.fit_transform(X): 输入一个字典返回稀疏矩阵</span><br><span class="line">2.inverse_transform(X)： 输入一个稀疏数组&#x2F;数组返回原始数据格式</span><br><span class="line">3.get_feature_names()： 返回类别名称</span><br></pre></td></tr></table></figure>

<p><strong>以城市为例:</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.feature_extraction import DictVectorizer</span><br><span class="line">#对字典类型数据进行特征抽取</span><br><span class="line">data &#x3D; [&#123;&#39;city&#39;: &#39;北京&#39;,&#39;temperature&#39;:100&#125;, &#123;&#39;city&#39;: &#39;上海&#39;,&#39;temperature&#39;:60&#125;, &#123;&#39;city&#39;: &#39;深圳&#39;,&#39;temperature&#39;:30&#125;]</span><br><span class="line">#1.实例化一个转换器类</span><br><span class="line">transfer&#x3D;DictVectorizer(sparse&#x3D;False)    #sparse默认是True打开的是稀疏矩阵</span><br><span class="line">#2.调用fit_transform()方法抽取特征</span><br><span class="line">data_new&#x3D;transfer.fit_transform(data)</span><br><span class="line">#获得特征名称</span><br><span class="line">print(transfer.get_feature_names())</span><br><span class="line">#获得特征</span><br><span class="line">print(data_new)          #sparse默认是True打开的是稀疏矩阵</span><br><span class="line">#反转最初的数据格式</span><br><span class="line">print(f&quot;原来的数据格式是:&#123;transfer.inverse_transform(data_new)&#125;&quot;)</span><br></pre></td></tr></table></figure>

<p><img src="4.5.png" alt=""></p>
<h4 id="文本特征提取-CountVectorizer类统计特征词出现个数"><a href="#文本特征提取-CountVectorizer类统计特征词出现个数" class="headerlink" title="文本特征提取(CountVectorizer类统计特征词出现个数)"></a>文本特征提取(CountVectorizer类统计特征词出现个数)</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#有三个方法:</span><br><span class="line">1.fit_transform(X): 输入一个文本&#x2F;文本字符串返回稀疏矩阵</span><br><span class="line">2.inverse_transform(X)： 输入一个稀疏数组&#x2F;数组返回原始数据格式</span><br><span class="line">3.get_feature_names()： 返回类别名称</span><br></pre></td></tr></table></figure>

<p><strong>以英文段落为例:</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.feature_extraction.text import CountVectorizer</span><br><span class="line">#准备数据</span><br><span class="line">data &#x3D;[&quot;life is short,i like like python&quot;, &quot;life is too long,i dislike python&quot;]</span><br><span class="line">#1.实例化一个转换器</span><br><span class="line">count&#x3D;CountVectorizer()</span><br><span class="line">#2.调用fit_transfrom()方法获取数据</span><br><span class="line">data_new&#x3D;count.fit_transform(data)</span><br><span class="line">print(count.get_feature_names_out())   #get_feature_names已经过期了！！！</span><br><span class="line">#二维数组要用toarray()方法展示出来  没有sparse&#x3D;False这个设置！！！</span><br><span class="line">print(data_new.toarray())</span><br><span class="line">print(count.inverse_transform(data_new))</span><br></pre></td></tr></table></figure>

<p><img src="4.6.png" alt=""></p>
<h4 id="文本特征提取-TfidfVectorier类-jieba库的cut方法分词"><a href="#文本特征提取-TfidfVectorier类-jieba库的cut方法分词" class="headerlink" title="文本特征提取(TfidfVectorier类+jieba库的cut方法分词)"></a>文本特征提取(TfidfVectorier类+jieba库的cut方法分词)</h4><h4 id="jieba库的cut方法"><a href="#jieba库的cut方法" class="headerlink" title="jieba库的cut方法"></a>jieba库的cut方法</h4><p><strong>以中文段落为例:</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.feature_extraction.text import CountVectorizer</span><br><span class="line">import jieba</span><br><span class="line">#准备数据</span><br><span class="line">data&#x3D;[&quot;一种还是一种今天很残酷，明天更残酷，后天很美好，但绝对大部分是死在明天晚上，所以 每个人不要放弃今天。&quot;,</span><br><span class="line">      &quot;我们看到的从很远星系来的光是在几百万年之前发出的，这样当我们看到宇宙时，我们是在 看它的过去。&quot;,</span><br><span class="line">      &quot;如果只用一种方式了解某样事物，你就不会真正了解它。了解事物真正含义的秘密取决于如 何将其与我们所了解的事物相联系。&quot;]</span><br><span class="line"></span><br><span class="line">#1.将中文文本分词</span><br><span class="line">data_new&#x3D;[]</span><br><span class="line">for sent in data:</span><br><span class="line">      data_new.append(&quot; &quot;.join(list(jieba.cut(sent))))   #使用jieba库的cut分词方法!!!</span><br><span class="line">#2.调用fit_transform()方法</span><br><span class="line">transfer&#x3D;CountVectorizer(stop_words&#x3D;[&quot;一种&quot;,&quot;哈哈&quot;])     #禁用词--- 分词的时候不把他们当做特征词！！！</span><br><span class="line">data_final&#x3D;transfer.fit_transform(data_new)</span><br><span class="line">print(f&quot;特征名称:\n &#123;transfer.get_feature_names_out()&#125;&quot;)</span><br><span class="line">print(f&quot;data_new内容:\n&#123;data_final.toarray()&#125;&quot;)</span><br></pre></td></tr></table></figure>

<p><img src="4.7.png" alt=""></p>
<hr>
<h4 id="TfidfVectorier类"><a href="#TfidfVectorier类" class="headerlink" title="TfidfVectorier类"></a>TfidfVectorier类</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1.TF-IDF思想:某个词&#x2F;短语在一篇文章中出现概率高，并且在其他文章中很少出现，则认为有很好的区分度，适合用来分类</span><br><span class="line">2.TF-IDF作用:用于评估对于一个文件&#x2F;语料库文件的重要程度</span><br><span class="line">3.TF-IDF公式:</span><br><span class="line">	TF(词频): 词语在文件中出现频率</span><br><span class="line">	IDF(逆向文档频率): log[总文件数目&#x2F;文件数目]10</span><br><span class="line">	tfidf&#x3D;TF*IDF</span><br></pre></td></tr></table></figure>

<p><strong>以中文段落为例:</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.feature_extraction.text import TfidfVectorizer</span><br><span class="line">import jieba</span><br><span class="line">#准备数据</span><br><span class="line">data&#x3D;[&quot;一种还是一种今天很残酷，明天更残酷，后天很美好，但绝对大部分是死在明天晚上，所以 每个人不要放弃今天。&quot;,</span><br><span class="line">      &quot;我们看到的从很远星系来的光是在几百万年之前发出的，这样当我们看到宇宙时，我们是在 看它的过去。&quot;,</span><br><span class="line">      &quot;如果只用一种方式了解某样事物，你就不会真正了解它。了解事物真正含义的秘密取决于如 何将其与我们所了解的事物相联系。&quot;]</span><br><span class="line">#1.将中文文本分词</span><br><span class="line">data_new&#x3D;[]</span><br><span class="line">for sent in data:</span><br><span class="line">      data_new.append(&quot; &quot;.join(list(jieba.cut(sent))))</span><br><span class="line">#2.调用fit_transform()方法</span><br><span class="line">transfer&#x3D;TfidfVectorizer()     #禁用词--- 分词的时候不把他们当做特征词！！！</span><br><span class="line">data_final&#x3D;transfer.fit_transform(data_new)</span><br><span class="line">print(f&quot;特征名称:\n &#123;transfer.get_feature_names_out()&#125;&quot;)</span><br><span class="line">print(f&quot;data_new内容:\n&#123;data_final.toarray()&#125;&quot;)</span><br></pre></td></tr></table></figure>

<p><img src="4.8.png" alt=""></p>
<hr>
<h3 id="特征预处理-sklearn-preprocessing"><a href="#特征预处理-sklearn-preprocessing" class="headerlink" title="特征预处理(sklearn.preprocessing)"></a>特征预处理(sklearn.preprocessing)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">特征预处理:特征数据 --(转换函数)--&gt; 特征数据[更加适合算法模型]	</span><br><span class="line">特征预处理:</span><br><span class="line">	1.归一化(传统精确小数据场景): MinMaxScaler   ----最大值最小值是变化并且容易受到异常点影响 ---&gt; 鲁棒性较差</span><br><span class="line">	2.标准化(嘈杂大数据场景): StandardScaler ----</span><br></pre></td></tr></table></figure>

<h4 id="归一化-MinMaxScaler"><a href="#归一化-MinMaxScaler" class="headerlink" title="归一化(MinMaxScaler)"></a>归一化(MinMaxScaler)</h4><p><strong>归一化推导公式:</strong></p>
<p><img src="4.10.png" alt=""></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">from sklearn.preprocessing import MinMaxScaler  #标准化</span><br><span class="line">#1.获取数据</span><br><span class="line">data&#x3D;pd.read_csv(&quot;dating.txt&quot;)  #文档在.py文件所在目录</span><br><span class="line">data&#x3D;data.iloc[:,:3]</span><br><span class="line">print(data)</span><br><span class="line">#2.实例化一个转换器类</span><br><span class="line">transfer&#x3D;MinMaxScaler(feature_range&#x3D;[0,1])   #默认归一化在0-1</span><br><span class="line">#3.调用fit_transform()</span><br><span class="line">data_new&#x3D;transfer.fit_transform(data)</span><br><span class="line">print(data_new)</span><br></pre></td></tr></table></figure>

<p><img src="4.9.png" alt=""></p>
<h4 id="标准化-StandardScaler"><a href="#标准化-StandardScaler" class="headerlink" title="标准化(StandardScaler)"></a>标准化(StandardScaler)</h4><p><strong>标准化推导公式:</strong></p>
<p><img src="4.11.png" alt=""></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">from sklearn.preprocessing import StandardScaler   #统一化</span><br><span class="line">#1.获取数据</span><br><span class="line">data&#x3D;pd.read_csv(&quot;dating.txt&quot;)  #文档在.py文件所在目录</span><br><span class="line">print(data)</span><br><span class="line">#2.实例化一个转换器类</span><br><span class="line">transfer&#x3D;StandardScaler()</span><br><span class="line">#3.调用fit_transform()</span><br><span class="line">data_new&#x3D;transfer.fit_transform(data[[&#39;milage&#39;,&#39;Liters&#39;,&#39;Consumtime&#39;]])</span><br><span class="line">print(&quot;标准化的结果:\n&quot;, data_new)</span><br><span class="line">print(&quot;每一列特征的平均值：\n&quot;, transfer.mean_)</span><br><span class="line">print(&quot;每一列特征的方差：\n&quot;, transfer.var_)</span><br></pre></td></tr></table></figure>

<p><img src="4.12.png" alt=""></p>
<hr>
<h3 id="特征降维"><a href="#特征降维" class="headerlink" title="特征降维"></a>特征降维</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">概念:</span><br><span class="line">	在某些限定条件下，降低随机变量(特征)个数 ---&gt; 一组“不相关”主变量</span><br><span class="line"></span><br><span class="line">分类:</span><br><span class="line">	1.特征选择</span><br><span class="line">		1.1 嵌入式 Embeded</span><br><span class="line">			决策树</span><br><span class="line">			正则化</span><br><span class="line">			深度学习</span><br><span class="line">		1.2 过滤式 Filter </span><br><span class="line">			方差选择法:低方差特征过滤</span><br><span class="line">			相关系数:特征与特征之间的相关过程</span><br><span class="line">		1.3 包裹式</span><br><span class="line">	2.主成分分析</span><br></pre></td></tr></table></figure>

<h4 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h4><h4 id="低方差特征过滤-varianceThreshold"><a href="#低方差特征过滤-varianceThreshold" class="headerlink" title="低方差特征过滤(varianceThreshold)"></a>低方差特征过滤(varianceThreshold)</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1.删除低方差的一些特征，再结合方差的大小来考虑这个方式的角度</span><br><span class="line">2. API: </span><br><span class="line">sklearn.feature_selection.VarianceThreshold(threshold &#x3D; 0.0)  --删除所有低方差特征</span><br><span class="line">Variance.fit_transform(X):</span><br><span class="line">	X是numpy array格式的数据[行,列]</span><br><span class="line">	返回值:删除训练集差异低于threshold的特征(默认是删除所有样本中具有相同值的特征)</span><br></pre></td></tr></table></figure>

<p><strong>筛选某些股票的指标特征</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">from sklearn.feature_selection import VarianceThreshold</span><br><span class="line">#1.获取数据</span><br><span class="line">data&#x3D;pd.read_csv(&quot;factor_returns.csv&quot;)</span><br><span class="line">data&#x3D;data.iloc[:,1:-2]</span><br><span class="line">#2.实例化转换器类</span><br><span class="line">transfer&#x3D;VarianceThreshold(threshold&#x3D;10)  &#x2F;&#x2F;特征方差选10</span><br><span class="line">#3.调用fit_transform</span><br><span class="line">data_new&#x3D;transfer.fit_transform(data)</span><br><span class="line">print(data_new)</span><br></pre></td></tr></table></figure>
<p><img src="4.13.png" alt=""></p>
<h4 id="相关系数过滤-scipy"><a href="#相关系数过滤-scipy" class="headerlink" title="相关系数过滤(scipy)"></a>相关系数过滤(scipy)</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">1.皮尔逊相关系数:反映变量之间相关关系密切程度的统计指标</span><br><span class="line">	相关系数(r):-1到1之间</span><br><span class="line">	1.1 r&gt;0表示正相关</span><br><span class="line">	1.2 r&lt;0表示负相关</span><br><span class="line">       1.3 |r|&#x3D;1表示两变量之间完全相关</span><br><span class="line">	1.4 r&#x3D;0表示两变量之间无相关</span><br><span class="line">	1.5 0&lt;|r|&lt;1表示两变量存在一定程度相关，且越接近1之间的线性关系越密切，接近0之间表示线性相关越弱</span><br><span class="line">	1.6 |r|&lt;0.4低度相关,0.4≤|r|&lt;0.7显著性相关,0.7≤|r|&lt;1高度线性相关</span><br><span class="line">	</span><br><span class="line">2. from scipy.stats import pearsonr</span><br><span class="line">	X: 特征值x,</span><br><span class="line">	Y: 特征值y,返回值是[特征值相关,特征值]</span><br><span class="line"></span><br><span class="line">3.特征之间相关性很高: </span><br><span class="line">	3.1 选其中一个</span><br><span class="line">	3.2 加权求和 每个占比多少</span><br><span class="line">	3.3 主成分分析</span><br></pre></td></tr></table></figure>
<h4 id="主成分分析-PCA降维保留信息"><a href="#主成分分析-PCA降维保留信息" class="headerlink" title="主成分分析(PCA降维保留信息)"></a>主成分分析(PCA降维保留信息)</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1.API：通过矩阵运算得到一个合适的直线-&gt;主成分分析的结果</span><br><span class="line">	sklearn.decomposition.PCA(n_components&#x3D;None) </span><br><span class="line">		n_components：</span><br><span class="line">			小数:表示保留百分之多少的信息</span><br><span class="line">			整数:减少到多少特征</span><br><span class="line">		PCA.fit_transform(X是numpy array格式数据)</span><br><span class="line">		返回值:转换后指定维度的array</span><br></pre></td></tr></table></figure>

<p><strong>举例使用</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.decomposition import PCA</span><br><span class="line">#1.获取数据</span><br><span class="line">data&#x3D;[[2,8,4,5],</span><br><span class="line">     [6,3,0,8],</span><br><span class="line">     [5,4,9,1]]</span><br><span class="line">#2.实例化转换器类</span><br><span class="line">transfer&#x3D;PCA(n_components&#x3D;2)  #转换后有2个维度(2个特征)</span><br><span class="line">data_new&#x3D;transfer.fit_transform(data)</span><br><span class="line">print(data_new)</span><br></pre></td></tr></table></figure>

<p><img src="4.14.png" alt=""></p>
<h4 id="instacart降维案例"><a href="#instacart降维案例" class="headerlink" title="instacart降维案例"></a>instacart降维案例</h4><p><strong>问题分析</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;探究用户对物品类别的喜好细分&gt;</span><br><span class="line">2.order_products_prior.csv订单与商品信息: order_id,product_id,add_to_cart_order,reordered   </span><br><span class="line">  products.csv商品信息: product_id,product_name,aisle_id,department_id</span><br><span class="line">  orders.csv用户的订单信息: order_id,user_id,eval_set,order_number.....</span><br><span class="line">  aisles.csv商品所属物品类别: aisle_id,aisle</span><br><span class="line">2. 得到四个csv文件 ----&gt; 需要将user_id和aisle放在同一个表中</span><br><span class="line">3. 找到user_id和aisle ----&gt; 交叉表和透视表</span><br><span class="line">4. 特征冗余过多 ----&gt;PCA降维</span><br></pre></td></tr></table></figure>

<p><strong>具体实现</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">from sklearn.decomposition import PCA</span><br><span class="line">#1.获取数据(记得放在代码当前位置文件夹下)</span><br><span class="line">data1&#x3D;pd.read_csv(&quot;order_products__prior.csv&quot;)</span><br><span class="line">data2&#x3D;pd.read_csv(&quot;products.csv&quot;)</span><br><span class="line">data3&#x3D;pd.read_csv(&quot;orders.csv&quot;)</span><br><span class="line">data4&#x3D;pd.read_csv(&quot;aisles.csv&quot;)</span><br><span class="line"></span><br><span class="line">#2.合并表 merge()函数</span><br><span class="line">table1&#x3D;pd.merge(data4,data2,on&#x3D;[&quot;aisle_id&quot;,&quot;aisle_id&quot;])</span><br><span class="line">table2&#x3D;pd.merge(table1,data1,on&#x3D;[&quot;product_id&quot;,&quot;product_id&quot;])</span><br><span class="line">table3&#x3D;pd.merge(table2,data3,on&#x3D;[&quot;order_id&quot;,&quot;order_id&quot;])</span><br><span class="line"></span><br><span class="line">#3.交叉表 crosstab()函数</span><br><span class="line">table&#x3D;pd.crosstab(table3[&quot;user_id&quot;],table3[&quot;aisle&quot;])</span><br><span class="line"></span><br><span class="line">#4.PCA降维 PCA()函数</span><br><span class="line">transfer&#x3D;PCA(n_components&#x3D;0.95)  #保留百分之95的数据</span><br><span class="line">data_new&#x3D;transfer.fit_transform(table)  #降维</span><br><span class="line">print(data_new)  #输出PCA降维后的数据</span><br></pre></td></tr></table></figure>

<p><img src="4.15.png" alt=""></p>
<hr>
<h2 id="sklearn转换器和估计器"><a href="#sklearn转换器和估计器" class="headerlink" title="sklearn转换器和估计器"></a>sklearn转换器和估计器</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"> 1.特征工程的步骤:</span><br><span class="line">1.1 实例化(实例化的是一个转换器类(Transformer))</span><br><span class="line">1.2 调用fit_transform(对于文档简历分类词频矩阵，不能同时调用)</span><br><span class="line"></span><br><span class="line"> 2.转换器:特征工程的接口</span><br><span class="line">   2.1 转换器的形式:</span><br><span class="line">	2.1.1 fit_transform</span><br><span class="line">	2.1.2 fit</span><br><span class="line">	2.1.3 transform</span><br></pre></td></tr></table></figure>

<h3 id="转换器-fit-transform"><a href="#转换器-fit-transform" class="headerlink" title="转换器(fit_transform)"></a>转换器(fit_transform)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line">from sklearn.preprocessing import StandardScaler  #引入特征预处理中的标准化</span><br><span class="line"></span><br><span class="line">#特征预处理</span><br><span class="line">##1.归一化(MinMaxScaler)</span><br><span class="line">##2.标准化(StandardScaler)</span><br><span class="line"></span><br><span class="line">std1&#x3D;StandardScaler()</span><br><span class="line">a&#x3D;[[1,2,3],[4,5,6]]</span><br><span class="line">print(std1.fit_transform(a))</span><br><span class="line"></span><br><span class="line">std2&#x3D;StandardScaler()</span><br><span class="line">print(std2.fit(a))</span><br><span class="line">print(std2.transform(a))</span><br></pre></td></tr></table></figure>

<p><img src="4.16.png" alt=""></p>
<h3 id="估计器-estimator"><a href="#估计器-estimator" class="headerlink" title="估计器(estimator)"></a>估计器(estimator)</h3><p><img src="4.17.png" alt=""></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"> 1.估计器的步骤:</span><br><span class="line">1.1 实例化一个estimator</span><br><span class="line">1.2 调用estimator.fit(x_train,y_train)计算 --&gt; 调用完毕，模型生成</span><br><span class="line">1.3 模型评估:</span><br><span class="line">	1.3.1 直接对比真实值和预测值: </span><br><span class="line">		y_predict&#x3D;estimator.predict(x_test)</span><br><span class="line">		y_test&#x3D;&#x3D;y_predict</span><br><span class="line">       1.3.2 计算准确率:</span><br><span class="line">		accuracy&#x3D;estimator.score(x_test,y_test)</span><br></pre></td></tr></table></figure>

<p><strong>估计器的分类:</strong></p>
<p><img src="4.18.png" alt=""></p>
<h2 id="K-近邻算法-sklearn-neighbors-KNeighborsClassifier"><a href="#K-近邻算法-sklearn-neighbors-KNeighborsClassifier" class="headerlink" title="K-近邻算法(sklearn.neighbors.KNeighborsClassifier)"></a>K-近邻算法(sklearn.neighbors.KNeighborsClassifier)</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1.核心思想: 你的&quot;邻居&quot;来推断你的类别</span><br><span class="line">   2.距离公式: 欧式距离 &#x2F; 明可夫斯基距离</span><br><span class="line">3.API: sklearn.neighbors.KNeighborsClassifier(n_neighbors&#x3D;5,algorithm&#x3D;&#39;auto&#39;)</span><br><span class="line">	3.1 n_neighbors: (默认整数类型为5)  --&gt;通过k_neighbors查询默认使用的邻居数</span><br><span class="line">	3.2 algorithm: 可选用于计算最近邻居的算法[auto&#x2F;ball_tree&#x2F;kd_tree&#x2F;brute]</span><br></pre></td></tr></table></figure>

<h3 id="模型选择与调优-sklearn-model-selection-GridSearchCV"><a href="#模型选择与调优-sklearn-model-selection-GridSearchCV" class="headerlink" title="模型选择与调优(sklearn.model_selection.GridSearchCV)"></a>模型选择与调优(sklearn.model_selection.GridSearchCV)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">1.交叉验证(cross validation):为了让被评估的模型更加准确可信</span><br><span class="line">     1.1将拿到的训练数据更加细化: </span><br><span class="line">		训练集:训练集+验证集 </span><br><span class="line">		测试集:测试集</span><br><span class="line">2.超参数搜索-网格搜索(Grid Search):</span><br><span class="line">  2.1 超参数:有很多参数是需要手动指定的(如k-近邻算法中的K值)</span><br><span class="line">  2.2 API: sklearn.model_selection.GridSearchCV(estimator,param_grid&#x3D;None,cv&#x3D;None)</span><br><span class="line">	2.2.1 estimator:估计器对象</span><br><span class="line">	2.2.2 param_grid:估计器参数(dict) --&gt; 一般是取字典&#123;&quot;n_neighbors&quot;:[1,3,5]&#125;</span><br><span class="line">	2.2.3 cv:指定几折交叉验证(训练集中训练集和验证集的划分有几次，然后得出平均值)</span><br><span class="line">	2.2.4 fit():输入训练数据</span><br><span class="line">	2.2.5 score()：准确率</span><br></pre></td></tr></table></figure>

<h3 id="电影类型分析"><a href="#电影类型分析" class="headerlink" title="电影类型分析"></a>电影类型分析</h3><p><img src="4.19.png" alt=""></p>
<h3 id="鸢尾花分析"><a href="#鸢尾花分析" class="headerlink" title="鸢尾花分析"></a>鸢尾花分析</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line">from sklearn.preprocessing import StandardScaler  #引入特征预处理中的标准化</span><br><span class="line">from sklearn.datasets import load_iris</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.neighbors import KNeighborsClassifier</span><br><span class="line">#用KNN算法对鸢尾花进行分类</span><br><span class="line">#1.获取数据</span><br><span class="line">iris&#x3D;load_iris()</span><br><span class="line"></span><br><span class="line">#2.划分数据集</span><br><span class="line">x_train,x_test,y_train,y_test&#x3D;train_test_split(iris.data,iris.target,random_state&#x3D;6)</span><br><span class="line"></span><br><span class="line">#3.特征工程(标准化)</span><br><span class="line">transfer&#x3D;StandardScaler()</span><br><span class="line">x_train&#x3D;transfer.fit_transform(x_train)</span><br><span class="line">x_test&#x3D;transfer.transform(x_test)</span><br><span class="line"></span><br><span class="line">#4.KNN算法预估器</span><br><span class="line">estimator&#x3D;KNeighborsClassifier(n_neighbors&#x3D;3)</span><br><span class="line">estimator.fit(x_train,y_train)</span><br><span class="line"></span><br><span class="line">#5.模型评估</span><br><span class="line">##方法一:直接对比真实值和预测值</span><br><span class="line">y_predict&#x3D;estimator.predict(x_test)</span><br><span class="line">print(y_test&#x3D;&#x3D;y_predict)</span><br><span class="line">##方法二:计算准确率</span><br><span class="line">score&#x3D;estimator.score(x_test,y_test)</span><br><span class="line">print(&quot;准确率为:&quot;,score)</span><br></pre></td></tr></table></figure>

<p><img src="4.20.png" alt=""></p>
<h3 id="鸢尾花分析-添加网格搜索和交叉验证"><a href="#鸢尾花分析-添加网格搜索和交叉验证" class="headerlink" title="鸢尾花分析(添加网格搜索和交叉验证)"></a>鸢尾花分析(添加网格搜索和交叉验证)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line">from sklearn.preprocessing import StandardScaler  #引入特征预处理中的标准化</span><br><span class="line">from sklearn.datasets import load_iris</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.neighbors import KNeighborsClassifier</span><br><span class="line">from sklearn.model_selection import GridSearchCV</span><br><span class="line">#用KNN算法对鸢尾花进行分类</span><br><span class="line">#1.获取数据</span><br><span class="line">iris&#x3D;load_iris()</span><br><span class="line"></span><br><span class="line">#2.划分数据集</span><br><span class="line">x_train,x_test,y_train,y_test&#x3D;train_test_split(iris.data,iris.target,random_state&#x3D;6)</span><br><span class="line"></span><br><span class="line">#3.特征工程(标准化)</span><br><span class="line">transfer&#x3D;StandardScaler()</span><br><span class="line">x_train&#x3D;transfer.fit_transform(x_train)</span><br><span class="line">x_test&#x3D;transfer.transform(x_test)</span><br><span class="line"></span><br><span class="line">#4.KNN算法预估器</span><br><span class="line">estimator&#x3D;KNeighborsClassifier()</span><br><span class="line"></span><br><span class="line">##加入网格搜索和交叉验证</span><br><span class="line">param_dict&#x3D;&#123;&quot;n_neighbors&quot;:[1,3,5,7,9,11]&#125;</span><br><span class="line">estimator&#x3D;GridSearchCV(estimator,param_grid&#x3D;param_dict,cv&#x3D;10)</span><br><span class="line"></span><br><span class="line">estimator.fit(x_train,y_train)</span><br><span class="line"></span><br><span class="line">#5.模型评估</span><br><span class="line">##方法一:直接对比真实值和预测值</span><br><span class="line">y_predict&#x3D;estimator.predict(x_test)</span><br><span class="line">print(y_test&#x3D;&#x3D;y_predict)</span><br><span class="line">##方法二:计算准确率</span><br><span class="line">score&#x3D;estimator.score(x_test,y_test)</span><br><span class="line">print(&quot;准确率为:&quot;,score)</span><br><span class="line"></span><br><span class="line">#6.获取结果分析</span><br><span class="line">print(&quot;最佳参数:&quot;,estimator.best_params_)</span><br><span class="line">print(&quot;最佳结果:&quot;,estimator.best_score_)</span><br><span class="line">print(&quot;最佳估计器:&quot;,estimator.best_estimator_)</span><br><span class="line">print(&quot;交叉验证的结果:&quot;,estimator.cv_results_)</span><br></pre></td></tr></table></figure>

<p><img src="4.21.png" alt=""></p>
<h3 id="预测facebook签到位置"><a href="#预测facebook签到位置" class="headerlink" title="预测facebook签到位置"></a>预测facebook签到位置</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line">from sklearn.preprocessing import StandardScaler  #引入特征预处理中的标准化</span><br><span class="line">from sklearn.datasets import load_iris</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.neighbors import KNeighborsClassifier</span><br><span class="line">from sklearn.model_selection import GridSearchCV</span><br><span class="line">#Facebook预测签到位置</span><br><span class="line"></span><br><span class="line">##1.获取数据</span><br><span class="line">data&#x3D;pd.read_csv(&quot;train.csv&quot;)</span><br><span class="line"></span><br><span class="line">##2.数据处理(获取特征值和目标值)</span><br><span class="line">###2.1 缩小数据范围 2&lt;x&lt;2.5 1.0&lt;y&lt;1.5</span><br><span class="line">###2.2 改变time时间 年月日时分秒</span><br><span class="line">###2.3 过滤签到次数少的地点</span><br><span class="line">data&#x3D;data.query(&quot;x&lt;2.5&amp;x&gt;2&amp;y&gt;1.0&amp;y&lt;1.5&quot;)</span><br><span class="line">time_value&#x3D;pd.to_datetime(data[&quot;time&quot;],unit&#x3D;&quot;s&quot;)</span><br><span class="line">data&#x3D;pd.DatetimeIndex(time_value)</span><br><span class="line"></span><br><span class="line">place_count&#x3D;data.groupby(&quot;place_id&quot;)</span><br><span class="line">data_final&#x3D;data[data[&quot;place_id&quot;].isin(place_count[place_count&gt;3].index.values)]</span><br><span class="line">##3.特征工程</span><br><span class="line">x&#x3D;data_final[[&quot;x&quot;,&quot;y&quot;,&quot;accuracy&quot;,&quot;day&quot;,&quot;weekday&quot;,&quot;hour&quot;]]</span><br><span class="line">y&#x3D;data_final[&quot;place_id&quot;]</span><br><span class="line">x_train,x_test,y_train,y_test&#x3D;train_test_split(x,y)</span><br><span class="line"></span><br><span class="line">##4.KNN算法预估器</span><br><span class="line">estimator&#x3D;KNeighborsClassifier()</span><br><span class="line"></span><br><span class="line">###加入网格搜索和交叉验证</span><br><span class="line">param_dict&#x3D;&#123;&quot;n_neighbors&quot;:[1,3,5,7,9,11]&#125;</span><br><span class="line">estimator&#x3D;GridSearchCV(estimator,param_grid&#x3D;param_dict,cv&#x3D;10)</span><br><span class="line"></span><br><span class="line">estimator.fit(x_train,y_train)</span><br><span class="line"></span><br><span class="line">##5.模型评估</span><br><span class="line">###方法一:直接对比真实值和预测值</span><br><span class="line">y_predict&#x3D;estimator.predict(x_test)</span><br><span class="line">print(y_test&#x3D;&#x3D;y_predict)</span><br><span class="line">###方法二:计算准确率</span><br><span class="line">score&#x3D;estimator.score(x_test,y_test)</span><br><span class="line">print(&quot;准确率为:&quot;,score)</span><br><span class="line"></span><br><span class="line">##6.获取结果分析</span><br><span class="line">print(&quot;最佳参数:&quot;,estimator.best_params_)</span><br><span class="line">print(&quot;最佳结果:&quot;,estimator.best_score_)</span><br><span class="line">print(&quot;最佳估计器:&quot;,estimator.best_estimator_)</span><br><span class="line">print(&quot;交叉验证的结果:&quot;,estimator.cv_results_)</span><br></pre></td></tr></table></figure>

<h2 id="朴素贝叶斯算法-sklearn-naive-bayes-MultinomialNB-alpha-1-0"><a href="#朴素贝叶斯算法-sklearn-naive-bayes-MultinomialNB-alpha-1-0" class="headerlink" title="朴素贝叶斯算法(sklearn.naive_bayes.MultinomialNB(alpha=1.0))"></a>朴素贝叶斯算法(sklearn.naive_bayes.MultinomialNB(alpha=1.0))</h2><h3 id="条件概率与联合概率"><a href="#条件概率与联合概率" class="headerlink" title="条件概率与联合概率"></a>条件概率与联合概率</h3><p><img src="4.22.png" alt=""></p>
<h3 id="贝叶斯公式"><a href="#贝叶斯公式" class="headerlink" title="贝叶斯公式"></a>贝叶斯公式</h3><p><img src="4.23.png" alt=""></p>
<h3 id="拉普拉斯平滑系数-防止计算出的分类概率为0"><a href="#拉普拉斯平滑系数-防止计算出的分类概率为0" class="headerlink" title="拉普拉斯平滑系数(防止计算出的分类概率为0)"></a>拉普拉斯平滑系数(防止计算出的分类概率为0)</h3><p><img src="4.24.png" alt=""></p>
<h3 id="文本分类分析-新闻分类"><a href="#文本分类分析-新闻分类" class="headerlink" title="文本分类分析(新闻分类)"></a>文本分类分析(新闻分类)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line">from sklearn.preprocessing import StandardScaler  #引入特征预处理中的标准化</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.neighbors import KNeighborsClassifier</span><br><span class="line">from sklearn.model_selection import GridSearchCV</span><br><span class="line">from sklearn.naive_bayes import MultinomialNB</span><br><span class="line">from sklearn.datasets import fetch_20newsgroups  #引入新闻数据集</span><br><span class="line">from sklearn.feature_extraction.text import TfidfVectorizer #文本提取的库</span><br><span class="line">#1.获取数据</span><br><span class="line">news&#x3D;fetch_20newsgroups(subset&#x3D;&quot;all&quot;)</span><br><span class="line">#2.划分数据集</span><br><span class="line">x_train,x_test,y_train,y_test&#x3D;train_test_split(news.data,news.target)</span><br><span class="line">#3.特征工程</span><br><span class="line">transfer&#x3D;TfidfVectorizer()</span><br><span class="line">##3.1文本特征提取</span><br><span class="line">x_train&#x3D;transfer.fit_transform(x_train)</span><br><span class="line">x_test&#x3D;transfer.transform(x_test)</span><br><span class="line">#4.朴素贝叶斯预估器流程</span><br><span class="line">estimator&#x3D;MultinomialNB()</span><br><span class="line">estimator.fit(x_train,y_train)</span><br><span class="line">#5.模型评估</span><br><span class="line">##方法一:直接对比真实值和预测值</span><br><span class="line">y_predict&#x3D;estimator.predict(x_test)</span><br><span class="line">print(y_test&#x3D;&#x3D;y_predict)</span><br><span class="line">##方法二:计算准确率</span><br><span class="line">score&#x3D;estimator.score(x_test,y_test)</span><br><span class="line">print(&quot;准确率为:&quot;,score)</span><br></pre></td></tr></table></figure>

<p><img src="4.25.png" alt=""></p>
<h2 id="决策树-sklearn-tree-DecisionTreeClassifier"><a href="#决策树-sklearn-tree-DecisionTreeClassifier" class="headerlink" title="决策树(sklearn.tree.DecisionTreeClassifier)"></a>决策树(sklearn.tree.DecisionTreeClassifier)</h2><h3 id="信息论基础"><a href="#信息论基础" class="headerlink" title="信息论基础"></a>信息论基础</h3><p><img src="4.26.png" alt=""></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1.信息:</span><br><span class="line">  香农:消除随机不定性的东西</span><br><span class="line">  例:小明 年龄未知 &quot;我今年18岁了&quot; (我可以通过说的这句话推断出年龄，消除了不知道的年龄)--就是信息  	 </span><br><span class="line">        小华 &quot;小明明年19岁&quot; (因为小明的话已经推断出年龄，所以这句话不算消除) --不是信息	</span><br><span class="line">   2.信息的衡量(信息商&#x2F;信息熵)</span><br><span class="line">3.信息增益[g(D,A)]&#x3D;信息熵[H(D)]-条件熵[H(D|A)]</span><br></pre></td></tr></table></figure>

<h3 id="决策树划分依据-3种"><a href="#决策树划分依据-3种" class="headerlink" title="决策树划分依据(3种)"></a>决策树划分依据(3种)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1. ID3  信息增益(最大的准则)</span><br><span class="line">2. C4.5 信息增益比(最大的准则)</span><br><span class="line">3. CART 分类树:基尼系数(最小的准则) 在sklearn中可以选择划分的默认原则</span><br></pre></td></tr></table></figure>

<h3 id="决策树的实现"><a href="#决策树的实现" class="headerlink" title="决策树的实现"></a>决策树的实现</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sklearn.tree.DecisionTreeClassifier(criterion&#x3D;&#39;gini&#39;,max_depth&#x3D;None,random_state&#x3D;None)</span><br><span class="line"> 1.决策树分类器</span><br><span class="line"> 2.criterion: 默认是gini系数(也可以选择信息增益的熵entropy)</span><br><span class="line"> 3.2.</span><br><span class="line"> 4.random_state: 随机数种子</span><br></pre></td></tr></table></figure>
<h3 id="鸢尾花预测"><a href="#鸢尾花预测" class="headerlink" title="鸢尾花预测"></a>鸢尾花预测</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line">from sklearn.preprocessing import StandardScaler  #引入特征预处理中的标准化</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.feature_extraction.text import TfidfVectorizer #文本提取的库</span><br><span class="line">from sklearn.tree import DecisionTreeClassifier #决策树</span><br><span class="line">from sklearn.datasets import load_iris  #传入鸢尾花数据集</span><br><span class="line">#1.获取数据</span><br><span class="line">iris&#x3D;load_iris()</span><br><span class="line">#2.划分数据集</span><br><span class="line">x_train,x_test,y_train,y_test&#x3D;train_test_split(iris.data,iris.target,random_state&#x3D;22)</span><br><span class="line">#4.决策树预估器流程</span><br><span class="line">estimator&#x3D;DecisionTreeClassifier(criterion&#x3D;&#39;entropy&#39;) #设置为数据增益</span><br><span class="line">estimator.fit(x_train,y_train)</span><br><span class="line">#5.模型评估</span><br><span class="line">##方法一:直接对比真实值和预测值</span><br><span class="line">y_predict&#x3D;estimator.predict(x_test)</span><br><span class="line">print(y_test&#x3D;&#x3D;y_predict)</span><br><span class="line">##方法二:计算准确率</span><br><span class="line">score&#x3D;estimator.score(x_test,y_test)</span><br><span class="line">print(&quot;准确率为:&quot;,score)</span><br></pre></td></tr></table></figure>

<p><img src="4.27.png" alt=""></p>
<h3 id="决策树可视化-sklearn-tree-export-graphviz-导出DOT格式"><a href="#决策树可视化-sklearn-tree-export-graphviz-导出DOT格式" class="headerlink" title="决策树可视化(sklearn.tree.export_graphviz()导出DOT格式)"></a>决策树可视化(sklearn.tree.export_graphviz()导出DOT格式)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sklearn.tree.export_graphviz()该函数能够导出DOT格式</span><br><span class="line"> 1.决策树可视化</span><br><span class="line"> 2.estimator: 预估器对象</span><br><span class="line"> 3.out_file: 输出名称</span><br><span class="line">    4.feature_names:特征的名字</span><br><span class="line"></span><br><span class="line">得到dot文件之后复制内容去http:&#x2F;&#x2F;webgraphviz.com&#x2F;执行</span><br></pre></td></tr></table></figure>

<p><img src="4.28.png" alt=""></p>
<h3 id="泰坦尼克号乘客生存预测"><a href="#泰坦尼克号乘客生存预测" class="headerlink" title="泰坦尼克号乘客生存预测"></a>泰坦尼克号乘客生存预测</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line">from sklearn.preprocessing import StandardScaler  #引入特征预处理中的标准化</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.feature_extraction import DictVectorizer  #缺失值处理</span><br><span class="line">from sklearn.feature_extraction.text import TfidfVectorizer #文本提取的库</span><br><span class="line">from sklearn.tree import DecisionTreeClassifier #决策树</span><br><span class="line">from sklearn.tree import export_graphviz #决策树可视化</span><br><span class="line">#1.获取数据</span><br><span class="line">titanic&#x3D;pd.read_csv(&#39;http:&#x2F;&#x2F;biostat.mc.vanderbilt.edu&#x2F;wiki&#x2F;pub&#x2F;Main&#x2F;DataSets&#x2F;titanic.txt&#39;)</span><br><span class="line">##1.1数据处理</span><br><span class="line">x&#x3D;titanic[[&#39;pclass&#39;,&#39;age&#39;,&#39;sex&#39;]]</span><br><span class="line">y&#x3D;titanic[&#39;survived&#39;]</span><br><span class="line">##1.2缺失值处理(将特征当中有类别的特征进行字典特征抽取)</span><br><span class="line">x[&#39;age&#39;].fillna(x[&#39;age&#39;].mean(),inplace&#x3D;True)</span><br><span class="line">dict&#x3D;DictVectorizer(sparse&#x3D;False)</span><br><span class="line">x&#x3D;dict.fit_transform(x.to_dict(orient&#x3D;&quot;records&quot;))</span><br><span class="line">#2.划分数据集</span><br><span class="line">x_train,x_test,y_train,y_test&#x3D;train_test_split(x,y,test_size&#x3D;0.3)</span><br><span class="line">#3.决策树预估器流程</span><br><span class="line">estimator&#x3D;DecisionTreeClassifier(max_depth&#x3D;5) #设置为数据增益</span><br><span class="line">estimator.fit(x_train,y_train)</span><br><span class="line">#4.模型评估</span><br><span class="line">score&#x3D;estimator.score(x_test,y_test)</span><br><span class="line">print(&quot;准确率为:&quot;,score)</span><br></pre></td></tr></table></figure>

<h2 id="随机森林-sklearn-ensemble-RandomForestClassifier"><a href="#随机森林-sklearn-ensemble-RandomForestClassifier" class="headerlink" title="随机森林(sklearn.ensemble.RandomForestClassifier)"></a>随机森林(sklearn.ensemble.RandomForestClassifier)</h2><p><img src="4.29.png" alt=""></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">1.随机森林: 一个包含多个决策树的分类器(输出的类型是通过个别树输出的类别的众数决定)</span><br><span class="line">2.随机:</span><br><span class="line">  2.1 训练集随机: bootstrap随机有放回抽样 </span><br><span class="line">  2.2 特征随机: 从M个特征中随机抽取m个特征(很像降维)</span><br><span class="line"></span><br><span class="line">3.API: sklearn.ensemble.RandomForestClassifier</span><br><span class="line">  3.1 随机森林分类器</span><br><span class="line">  3.2 n_estimators: 几个估计器</span><br><span class="line">     3.3 criterion: 默认gini系数，(也可以使用信息增益的熵entropy)</span><br><span class="line">  3.4 max_depth: 树的深度</span><br><span class="line">     3.5 bootstrap: 是否设置随机有放回抽样</span><br><span class="line">  3.6 random_state:  </span><br><span class="line">  3.7 min_samples_split:</span><br></pre></td></tr></table></figure>

<h1 id="回归问题"><a href="#回归问题" class="headerlink" title="回归问题"></a>回归问题</h1><h2 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h2><h3 id="线性回归定义"><a href="#线性回归定义" class="headerlink" title="线性回归定义"></a>线性回归定义</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">1.基本概念:通过回归方程(函数)对一个&#x2F;多个自变量(特征值)和因变量(目标值)之间关系进行建模的一种分析方式</span><br><span class="line">2.线性模型(回归方程):特征值和目标值之间建立一个关系</span><br><span class="line">	3.线性模型分类:</span><br><span class="line">	3.1 线性关系   </span><br><span class="line">		3.1.1 直线关系: 单特征与目标值的关系</span><br><span class="line">		3.1.2 平面关系: 两个特征与目标值的关系</span><br><span class="line">	3.2 非线性关系 </span><br><span class="line">		3.2.1 自变量一次: y&#x3D;ax1+bx2+cx3+....+b (最多是x的一次方)</span><br><span class="line">		3.2.2 参数一次: y&#x3D;ax1+bx2^2+cx3^3+...+b (a1&#x2F;b&#x2F;c等等都是一次)</span><br></pre></td></tr></table></figure>

<p><strong>线性回归通用公式:</strong></p>
<p><img src="4.30.png" alt=""></p>
<h3 id="最小二乘法-损失函数"><a href="#最小二乘法-损失函数" class="headerlink" title="最小二乘法(损失函数)"></a>最小二乘法(损失函数)</h3><p><strong>最小二乘法公式:</strong></p>
<p><img src="4.31.png" alt=""></p>
<h3 id="优化方法之正规方程-直接求解sklearn-linear-model-LinearRegression"><a href="#优化方法之正规方程-直接求解sklearn-linear-model-LinearRegression" class="headerlink" title="优化方法之正规方程(直接求解sklearn.linear_model.LinearRegression)"></a>优化方法之正规方程(直接求解sklearn.linear_model.LinearRegression)</h3><p><img src="4.32.png" alt=""></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"> sklearn.linear_model.LinearRegression(fit_intercept&#x3D;True)</span><br><span class="line">1.fit_intercept: 是否计算偏置</span><br><span class="line">2.LinearRegression.coef_: 回归系数</span><br><span class="line">3.LinearRegression.intercept_: 偏置</span><br></pre></td></tr></table></figure>

<h3 id="优化方法之梯度下降-不断试错sklearn-linear-model-SGDRegressor"><a href="#优化方法之梯度下降-不断试错sklearn-linear-model-SGDRegressor" class="headerlink" title="优化方法之梯度下降(不断试错sklearn.linear_model.SGDRegressor)"></a>优化方法之梯度下降(不断试错sklearn.linear_model.SGDRegressor)</h3><p><img src="4.33.png" alt=""></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"> sklearn.linear_model.SGDRegressor(loss&#x3D;&quot;squared_loss&quot;,fit_intercept&#x3D;True,learing_rate&#x3D;&#39;invscaling&#39;,eta0&#x3D;0.01)</span><br><span class="line">1.SGDRegressor类实现了随机梯度下降学习(支持不同的loss函数和正则化惩罚项来拟合线性回归模型)</span><br><span class="line">2.loss: 默认是普通最小二乘法squared_loss</span><br><span class="line">3.fit_intercept: 是否计算偏置</span><br><span class="line">4.learing_rate: 学习率填充</span><br><span class="line">	4.1 constant(常数值的学习率): eta&#x3D;eta0</span><br><span class="line">	4.2 optimal(默认): eta&#x3D;1.0&#x2F;(alpha&#x3D;*(t+t0)) </span><br><span class="line">	4.3 invscaling: eta&#x3D;eta0&#x2F;pow(t,power_t) [power_t&#x3D;0.25存在父类当中]</span><br><span class="line">	4.4 SGDRegressor.coef_: 回归系数</span><br><span class="line">	4.5 SGDRegressor.intercept_: 偏置</span><br></pre></td></tr></table></figure>

<h3 id="波士顿房价预测-正规方程和梯度下降对比"><a href="#波士顿房价预测-正规方程和梯度下降对比" class="headerlink" title="波士顿房价预测(正规方程和梯度下降对比)"></a>波士顿房价预测(正规方程和梯度下降对比)</h3><h4 id="正则方程"><a href="#正则方程" class="headerlink" title="正则方程"></a>正则方程</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line">from sklearn.datasets import load_boston #导入波士顿数据集</span><br><span class="line">from sklearn.model_selection import train_test_split #划分数据集</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line">from sklearn.linear_model import LinearRegression</span><br><span class="line">#1.获取数据集</span><br><span class="line">boston&#x3D;load_boston()</span><br><span class="line">#2.划分数据集</span><br><span class="line">x_train,x_test,y_train,y_test&#x3D;train_test_split(boston.data,boston.target,random_state&#x3D;22)</span><br><span class="line">#3.标准化</span><br><span class="line">transfer&#x3D;StandardScaler()</span><br><span class="line">x_train&#x3D;transfer.fit_transform(x_train) #训练集</span><br><span class="line">x_test&#x3D;transfer.transform(x_test) #测试集</span><br><span class="line">#4.决策树预估器流程</span><br><span class="line">estimator&#x3D;LinearRegression()</span><br><span class="line">estimator.fit(x_train,y_train)</span><br><span class="line">##得出模型</span><br><span class="line">print(&quot;权重系数为:&quot;,estimator.coef_)</span><br><span class="line">print(&quot;偏置为:&quot;,estimator.intercept_)</span><br></pre></td></tr></table></figure>

<p><img src="4.34.png" alt=""></p>
<h4 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line">from sklearn.datasets import load_boston #导入波士顿数据集</span><br><span class="line">from sklearn.model_selection import train_test_split #划分数据集</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line">from sklearn.linear_model.stochastic_gradient import SGDRegressor</span><br><span class="line">#1.获取数据集</span><br><span class="line">boston&#x3D;load_boston()</span><br><span class="line">#2.划分数据集</span><br><span class="line">x_train,x_test,y_train,y_test&#x3D;train_test_split(boston.data,boston.target,random_state&#x3D;22)</span><br><span class="line">#3.标准化</span><br><span class="line">transfer&#x3D;StandardScaler()</span><br><span class="line">x_train&#x3D;transfer.fit_transform(x_train) #训练集</span><br><span class="line">x_test&#x3D;transfer.transform(x_test) #测试集</span><br><span class="line">#4.决策树预估器流程</span><br><span class="line">estimator&#x3D;SGDRegressor()</span><br><span class="line">estimator.fit(x_train,y_train)</span><br><span class="line">##得出模型</span><br><span class="line">print(&quot;权重系数为:&quot;,estimator.coef_)</span><br><span class="line">print(&quot;偏置为:&quot;,estimator.intercept_)</span><br></pre></td></tr></table></figure>

<p><img src="4.35.png" alt=""></p>
<h4 id="两者对比"><a href="#两者对比" class="headerlink" title="两者对比"></a>两者对比</h4><p><img src="4.38.png" alt=""></p>
<h3 id="回归性能评估-sklearn-metrics-mean-squared-error"><a href="#回归性能评估-sklearn-metrics-mean-squared-error" class="headerlink" title="回归性能评估(sklearn.metrics.mean_squared_error)"></a>回归性能评估(sklearn.metrics.mean_squared_error)</h3><p><strong>回归性能评估公式:</strong></p>
<p><img src="4.36.png" alt=""></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">	1.API: sklearn.metrics.mean_squared_error(y_true,y_pred)</span><br><span class="line">	  1.1 均方误差回归损失</span><br><span class="line">	  1.2 y_true: 真实值</span><br><span class="line">	  1.3 y_pred: 预测值</span><br><span class="line"></span><br><span class="line">#在之前的基础上:</span><br><span class="line">from sklearn.metrics import mean_squared_error</span><br><span class="line">#5.模型评估</span><br><span class="line">y_predict&#x3D;estimator.predict(x_test)</span><br><span class="line">print(&quot;预测房价:&quot;,y_predict)</span><br><span class="line">error&#x3D;mean_squared_error(y_test,y_predict)</span><br><span class="line">print(&quot;梯度下降的-均方误差为:&quot;,error)</span><br></pre></td></tr></table></figure>

<p><strong>刚才的波士顿房价上进行预测:</strong></p>
<p><img src="4.37.png" alt=""></p>
<h3 id="梯度下降优化方法-GD-SGD-SAG"><a href="#梯度下降优化方法-GD-SGD-SAG" class="headerlink" title="梯度下降优化方法(GD/SGD/SAG)"></a>梯度下降优化方法(GD/SGD/SAG)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1.GD(原始的):计算所有样本的值才能够得到梯度(计算量大)</span><br><span class="line">	</span><br><span class="line">2.SGD(随机梯度下降):一次迭代只考虑一个训练样本</span><br><span class="line"></span><br><span class="line">3.SAG(随机平均梯度法):提高收敛速度(SGDRegressor和岭回归以及逻辑回归中都会有SAG优化)</span><br></pre></td></tr></table></figure>

<h2 id="欠拟合与过拟合"><a href="#欠拟合与过拟合" class="headerlink" title="欠拟合与过拟合()"></a>欠拟合与过拟合()</h2><p><img src="4.39.png" alt=""></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"> 训练集很合理，测试集不行</span><br><span class="line">1.欠拟合:一个假设在训练数据上不能够获得比其他假设更好的拟合，测试集上不能很好拟合(学的特征太少)</span><br><span class="line">  1.1 原因:学习的特征过少</span><br><span class="line">  1.2 解决方法:增加数据的特征数量</span><br><span class="line"></span><br><span class="line">2.过拟合:一个假设在训练数据上能够获得比其他假设更好的拟合，测试集上不能很好拟合(学的特征太多)</span><br><span class="line">  2.1 原因:原始特征过多，存在一些嘈杂特征，模型过于复杂</span><br><span class="line">  2.2 解决方法:正则化</span><br></pre></td></tr></table></figure>

<h3 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1. L1正则化:可以使得其中一些w的值直接为0，删除这个特征的影响  (LASSO回归)</span><br><span class="line"></span><br><span class="line">2. L2正则化:可以使得其中一些w都很小，都接近0，削弱某个特征的影响  (Ridge回归)</span><br></pre></td></tr></table></figure>

<h2 id="岭回归-带L2正则化的线性回归"><a href="#岭回归-带L2正则化的线性回归" class="headerlink" title="岭回归(带L2正则化的线性回归)"></a>岭回归(带L2正则化的线性回归)</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1.API: sklearn.linear_model.Ridge(alpha&#x3D;1.0,fit_intercept&#x3D;True,solver&#x3D;&quot;auto&quot;,normalize&#x3D;False)</span><br><span class="line">  1.1 alpha: 正则化力度 (0-1 1-10)</span><br><span class="line">  	  1.2 solver: 会根据数据自动选择优化方法(如果数据集和特征都较大会使用SAG随机平均梯度法)</span><br><span class="line">     1.3 normalize: 数据是否进行标准化</span><br><span class="line">     1.4 Ridge.coef_: 回归权重</span><br><span class="line">  1.5 Ridge.intercept_: 回归偏置</span><br></pre></td></tr></table></figure>

<h3 id="波士顿房价预测-岭回归Ridge"><a href="#波士顿房价预测-岭回归Ridge" class="headerlink" title="波士顿房价预测(岭回归Ridge)"></a>波士顿房价预测(岭回归Ridge)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line">from sklearn.datasets import load_boston #导入波士顿数据集</span><br><span class="line">from sklearn.model_selection import train_test_split #划分数据集</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line">from sklearn.linear_model import Ridge</span><br><span class="line">#1.获取数据集</span><br><span class="line">boston&#x3D;load_boston()</span><br><span class="line">#2.划分数据集</span><br><span class="line">x_train,x_test,y_train,y_test&#x3D;train_test_split(boston.data,boston.target,random_state&#x3D;22)</span><br><span class="line">#3.标准化</span><br><span class="line">transfer&#x3D;StandardScaler()</span><br><span class="line">x_train&#x3D;transfer.fit_transform(x_train) #训练集</span><br><span class="line">x_test&#x3D;transfer.transform(x_test) #测试集</span><br><span class="line">#4.决策树预估器流程</span><br><span class="line">estimator&#x3D;Ridge()</span><br><span class="line">estimator.fit(x_train,y_train)</span><br><span class="line">##得出模型</span><br><span class="line">print(&quot;权重系数为:&quot;,estimator.coef_)</span><br><span class="line">print(&quot;偏置为:&quot;,estimator.intercept_)</span><br></pre></td></tr></table></figure>

<h1 id="分类算法"><a href="#分类算法" class="headerlink" title="分类算法"></a>分类算法</h1><h2 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h2><h3 id="逻辑回归概念"><a href="#逻辑回归概念" class="headerlink" title="逻辑回归概念"></a>逻辑回归概念</h3><p><strong>sigmoid函数</strong></p>
<p><img src="4.40.png" alt=""></p>
<h3 id="逻辑回归过程"><a href="#逻辑回归过程" class="headerlink" title="逻辑回归过程"></a>逻辑回归过程</h3><p><strong>流程:</strong></p>
<p><img src="4.41.png" alt=""></p>
<h3 id="逻辑回归损失-对数似然损失"><a href="#逻辑回归损失-对数似然损失" class="headerlink" title="逻辑回归损失(对数似然损失)"></a>逻辑回归损失(对数似然损失)</h3><p><strong>对数似然损失:</strong></p>
<p><img src="4.42.png" alt=""></p>
<p><strong>综合完整损失函数:</strong></p>
<p><img src="4.43.png" alt=""></p>
<h3 id="逻辑回归损失优化-梯度下降"><a href="#逻辑回归损失优化-梯度下降" class="headerlink" title="逻辑回归损失优化(梯度下降)"></a>逻辑回归损失优化(梯度下降)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">减少损失函数的值 --&gt; 更新逻辑回归前面对应算法的权重参数 --&gt; 提升原本属于1类别的概率，降低原本属于0类别的概率</span><br></pre></td></tr></table></figure>

<h3 id="逻辑回归API-sklearn-linear-model-LogisticRegression"><a href="#逻辑回归API-sklearn-linear-model-LogisticRegression" class="headerlink" title="逻辑回归API(sklearn.linear_model.LogisticRegression)"></a>逻辑回归API(sklearn.linear_model.LogisticRegression)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1. sklearn.linear_model.LogisticRegression(solver&#x3D;&#39;liblinear&#39;,penalty&#x3D;&#39;l2&#39;,c&#x3D;1.0)</span><br><span class="line">  1.1 solver: 优化求解方式(默认开源的liblinear库实现,内部使用了坐标轴下降法来迭代优化损失函数)</span><br><span class="line">  1.2 penalty: 正则化的种类(l1和l2(默认))</span><br><span class="line">  1.3 c: 正则化力度</span><br></pre></td></tr></table></figure>

<h3 id="癌症分类"><a href="#癌症分类" class="headerlink" title="癌症分类"></a>癌症分类</h3><p><strong>数据描述:</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">1.原始数据:https:&#x2F;&#x2F;archive.ics.uci.edu&#x2F;ml&#x2F;machine-learning-databases&#x2F;breast-cancer-wisconsin&#x2F;</span><br><span class="line">2.数据分析:</span><br><span class="line">  2.1 一共699条样本，共11列数据(第一列id,后9列分别是与肿瘤相关的医学特征，最后一列表示肿瘤类型的数值)</span><br><span class="line">  2.2 包含16个缺失值(用？标出)</span><br><span class="line"></span><br><span class="line">3.流程分析:</span><br><span class="line">  3.1 获取数据(读取时加上names)</span><br><span class="line">     3.2 数据处理(处理缺失值)</span><br><span class="line">     3.3 数据集划分</span><br><span class="line">     3.4 特征工程(无量纲化处理-标准化)</span><br><span class="line">  3.5 逻辑回归预估器</span><br><span class="line">  3.6 模型评估</span><br></pre></td></tr></table></figure>

<h4 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line">from sklearn.linear_model import LogisticRegression</span><br><span class="line">#3.1 获取数据(读取时加上names)</span><br><span class="line">path&#x3D;&quot;https:&#x2F;&#x2F;archive.ics.uci.edu&#x2F;ml&#x2F;machine-learning-databases&#x2F;breast-cancer-wisconsin&#x2F;breast-cancer-wisconsin.data&quot;</span><br><span class="line">column_name &#x3D; [&#39;Sample code number&#39;, &#39;Clump Thickness&#39;, &#39;Uniformity of Cell Size&#39;, &#39;Uniformity of Cell Shape&#39;, &#39;Marginal Adhesion&#39;, &#39;Single Epithelial Cell Size&#39;, &#39;Bare Nuclei&#39;, &#39;Bland Chromatin&#39;, &#39;Normal Nucleoli&#39;, &#39;Mitoses&#39;, &#39;Class&#39;]</span><br><span class="line">data&#x3D;pd.read_csv(path,names&#x3D;column_name)</span><br><span class="line">print(data)</span><br><span class="line">#3.2 数据处理(处理缺失值)</span><br><span class="line">data&#x3D;data.replace(to_replace&#x3D;&#39;?&#39;,value&#x3D;np.nan)  #将所有缺失值用NaN替换？</span><br><span class="line">data&#x3D;data.dropna()  #删掉所有NaN值</span><br><span class="line">#3.3 数据集划分</span><br><span class="line">x&#x3D;data[column_name[1:10]]</span><br><span class="line">y&#x3D;data[column_name[10]]</span><br><span class="line">x_train,x_test,y_train,y_test&#x3D;train_test_split(x,y,test_size&#x3D;0.3)</span><br><span class="line">#3.4 特征工程(无量纲化处理-标准化)</span><br><span class="line">std&#x3D;StandardScaler()</span><br><span class="line">x_train&#x3D;std.fit_transform(x_train)</span><br><span class="line">x_test&#x3D;std.transform(x_test)</span><br><span class="line">#3.5 逻辑回归预估器</span><br><span class="line">lr&#x3D;LogisticRegression()</span><br><span class="line">lr.fit(x_train,y_train)</span><br><span class="line">#3.6 模型评估</span><br><span class="line">print(&quot;得出来的权重:&quot;,lr.coef_)</span><br><span class="line">print(&quot;预测的类别:&quot;,lr.predict(x_test))</span><br><span class="line">print(&quot;预测的准确率:&quot;,lr.score(x_test,y_test))</span><br></pre></td></tr></table></figure>

<p><img src="4.44.png" alt=""></p>
<h2 id="分类的评估方法-sklearn-metrics-classification-report"><a href="#分类的评估方法-sklearn-metrics-classification-report" class="headerlink" title="分类的评估方法(sklearn.metrics.classification_report)"></a>分类的评估方法(sklearn.metrics.classification_report)</h2><h3 id="混淆矩阵"><a href="#混淆矩阵" class="headerlink" title="混淆矩阵"></a>混淆矩阵</h3><p><strong>混淆矩阵:</strong></p>
<p><img src="4.45.png" alt=""></p>
<h3 id="精确率-Precision-与召回率-Recall"><a href="#精确率-Precision-与召回率-Recall" class="headerlink" title="精确率(Precision)与召回率(Recall)"></a>精确率(Precision)与召回率(Recall)</h3><p><strong>精确率:</strong></p>
<p><img src="4.46.png" alt=""></p>
<p><strong>召回率:</strong></p>
<p><img src="4.47.png" alt=""></p>
<h3 id="F1-score"><a href="#F1-score" class="headerlink" title="F1-score"></a>F1-score</h3><p><img src="4.48.png" alt=""></p>
<h3 id="分类评估预测API"><a href="#分类评估预测API" class="headerlink" title="分类评估预测API"></a>分类评估预测API</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1.sklearn.metrics.classification_report(y_true,y_pred,labels&#x3D;[],target_names&#x3D;None)</span><br><span class="line">  1.1 y_true: 真实目标值</span><br><span class="line">	  1.2 y_pred: 估计器预测目标值</span><br><span class="line">  1.3 labels: 指定类别对应的数字</span><br><span class="line">     1.4 target_names: 目标类别名称</span><br><span class="line">     1.5 return: 每个类别精准率与召回率</span><br></pre></td></tr></table></figure>

<p><strong>上面基础上加入分类评估</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line">from sklearn.linear_model import LogisticRegression</span><br><span class="line">from sklearn.metrics import classification_report</span><br><span class="line">#3.1 获取数据(读取时加上names)</span><br><span class="line">path&#x3D;&quot;https:&#x2F;&#x2F;archive.ics.uci.edu&#x2F;ml&#x2F;machine-learning-databases&#x2F;breast-cancer-wisconsin&#x2F;breast-cancer-wisconsin.data&quot;</span><br><span class="line">column_name &#x3D; [&#39;Sample code number&#39;, &#39;Clump Thickness&#39;, &#39;Uniformity of Cell Size&#39;, &#39;Uniformity of Cell Shape&#39;, &#39;Marginal Adhesion&#39;, &#39;Single Epithelial Cell Size&#39;, &#39;Bare Nuclei&#39;, &#39;Bland Chromatin&#39;, &#39;Normal Nucleoli&#39;, &#39;Mitoses&#39;, &#39;Class&#39;]</span><br><span class="line">data&#x3D;pd.read_csv(path,names&#x3D;column_name)</span><br><span class="line">#3.2 数据处理(处理缺失值)</span><br><span class="line">data&#x3D;data.replace(to_replace&#x3D;&#39;?&#39;,value&#x3D;np.nan)</span><br><span class="line">data&#x3D;data.dropna()</span><br><span class="line">#3.3 数据集划分</span><br><span class="line">x&#x3D;data[column_name[1:10]]</span><br><span class="line">y&#x3D;data[column_name[10]]</span><br><span class="line">x_train,x_test,y_train,y_test&#x3D;train_test_split(x,y,test_size&#x3D;0.3)</span><br><span class="line">#3.4 特征工程(无量纲化处理-标准化)</span><br><span class="line">std&#x3D;StandardScaler()</span><br><span class="line">x_train&#x3D;std.fit_transform(x_train)</span><br><span class="line">x_test&#x3D;std.transform(x_test)</span><br><span class="line">#3.5 逻辑回归预估器</span><br><span class="line">lr&#x3D;LogisticRegression()</span><br><span class="line">lr.fit(x_train,y_train)</span><br><span class="line">print(&quot;得出来的权重:&quot;,lr.coef_)</span><br><span class="line">print(&quot;预测的类别:&quot;,lr.predict(x_test))</span><br><span class="line">print(&quot;预测的准确率:&quot;,lr.score(x_test,y_test))</span><br><span class="line"></span><br><span class="line">#3.6 模型评估</span><br><span class="line">print(&quot;精确率和召回率为:&quot;,classification_report(y_test,lr.predict(x_test),labels&#x3D;[2,4],target_names&#x3D;[&#39;良性&#39;,&#39;恶性&#39;]))</span><br></pre></td></tr></table></figure>

<p><img src="4.49.png" alt=""></p>
<h3 id="TPR和FPR"><a href="#TPR和FPR" class="headerlink" title="TPR和FPR"></a>TPR和FPR</h3><p><img src="4.50.png" alt=""></p>
<h3 id="ROC曲线"><a href="#ROC曲线" class="headerlink" title="ROC曲线"></a>ROC曲线</h3><p><strong>通过FPR和TPR来构成:</strong></p>
<p><img src="4.51.png" alt=""></p>
<h3 id="AUC指标-sklearn-metrics-roc-auc-score"><a href="#AUC指标-sklearn-metrics-roc-auc-score" class="headerlink" title="AUC指标(sklearn.metrics.roc_auc_score)"></a>AUC指标(sklearn.metrics.roc_auc_score)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">1.AUC的概率意义: 随机取一对正负样本,正样本得分&gt;负样本的概率</span><br><span class="line">2.AUC取值范围: 0.5-1(取值越高越好，说明TPR高)</span><br><span class="line">  2.1 0.5&lt;AUC&lt;1: 优于随机猜测</span><br><span class="line">  2.2 AUC&#x3D;1：完美分类器(不管怎么设定阈值都能完美预测)  </span><br><span class="line">3.API: sklearn.metrics.roc_auc_score(y_true,y_score)</span><br><span class="line">  3.1 计算ROC曲线面积(AUC值)</span><br><span class="line">  3.2 y_true: 每个样本的真实类别(必须为0&#x2F;1)</span><br><span class="line">  3.3 y_score: 每个样本预测的概率值</span><br></pre></td></tr></table></figure>

<p><strong>上面基础上加入auc指标</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line">from sklearn.linear_model import LogisticRegression</span><br><span class="line">from sklearn.metrics import classification_report</span><br><span class="line">from sklearn.metrics import roc_auc_score</span><br><span class="line">#3.1 获取数据(读取时加上names)</span><br><span class="line">path&#x3D;&quot;https:&#x2F;&#x2F;archive.ics.uci.edu&#x2F;ml&#x2F;machine-learning-databases&#x2F;breast-cancer-wisconsin&#x2F;breast-cancer-wisconsin.data&quot;</span><br><span class="line">column_name &#x3D; [&#39;Sample code number&#39;, &#39;Clump Thickness&#39;, &#39;Uniformity of Cell Size&#39;, &#39;Uniformity of Cell Shape&#39;, &#39;Marginal Adhesion&#39;, &#39;Single Epithelial Cell Size&#39;, &#39;Bare Nuclei&#39;, &#39;Bland Chromatin&#39;, &#39;Normal Nucleoli&#39;, &#39;Mitoses&#39;, &#39;Class&#39;]</span><br><span class="line">data&#x3D;pd.read_csv(path,names&#x3D;column_name)</span><br><span class="line">#3.2 数据处理(处理缺失值)</span><br><span class="line">data&#x3D;data.replace(to_replace&#x3D;&#39;?&#39;,value&#x3D;np.nan)</span><br><span class="line">data&#x3D;data.dropna()</span><br><span class="line">#3.3 数据集划分</span><br><span class="line">x&#x3D;data[column_name[1:10]]</span><br><span class="line">y&#x3D;data[column_name[10]]</span><br><span class="line">x_train,x_test,y_train,y_test&#x3D;train_test_split(x,y,test_size&#x3D;0.3)</span><br><span class="line">#3.4 特征工程(无量纲化处理-标准化)</span><br><span class="line">std&#x3D;StandardScaler()</span><br><span class="line">x_train&#x3D;std.fit_transform(x_train)</span><br><span class="line">x_test&#x3D;std.transform(x_test)</span><br><span class="line">#3.5 逻辑回归预估器</span><br><span class="line">lr&#x3D;LogisticRegression()</span><br><span class="line">lr.fit(x_train,y_train)</span><br><span class="line">print(&quot;得出来的权重:&quot;,lr.coef_)</span><br><span class="line">print(&quot;预测的类别:&quot;,lr.predict(x_test))</span><br><span class="line">print(&quot;预测的准确率:&quot;,lr.score(x_test,y_test))</span><br><span class="line"></span><br><span class="line">#3.6 模型评估</span><br><span class="line">print(&quot;精确率和召回率为:&quot;,classification_report(y_test,lr.predict(x_test),labels&#x3D;[2,4],target_names&#x3D;[&#39;良性&#39;,&#39;恶性&#39;]))</span><br><span class="line">y_test&#x3D;np.where(y_test&gt;2.5,1,0) #将2和4转换为0和1用于auc的参数</span><br><span class="line">print(&quot;auc&quot;,roc_auc_score(y_test,lr.predict(x_test)))</span><br></pre></td></tr></table></figure>

<p><img src="4.52.png" alt=""></p>
<h1 id="模型保存和加载-sklearn-externals-joblib"><a href="#模型保存和加载-sklearn-externals-joblib" class="headerlink" title="模型保存和加载(sklearn.externals.joblib)"></a>模型保存和加载(sklearn.externals.joblib)</h1><h2 id="sklearn模型API"><a href="#sklearn模型API" class="headerlink" title="sklearn模型API"></a>sklearn模型API</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1.sklearn.externals.joblib</span><br><span class="line">  1.1 保存: joblib.dump(estimator,&#39;test.pkl&#39;)  #后缀为pkl文件</span><br><span class="line">  1.2 加载: estimator&#x3D;joblib.load(&#39;test.pkl&#39;)</span><br></pre></td></tr></table></figure>

<h1 id="无监督学习"><a href="#无监督学习" class="headerlink" title="无监督学习"></a>无监督学习</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1.聚类: K-means算法(K均值聚类)</span><br><span class="line">2.降维: PCA</span><br></pre></td></tr></table></figure>

<h2 id="K-means算法-sklearn-cluster-KMeans"><a href="#K-means算法-sklearn-cluster-KMeans" class="headerlink" title="K-means算法(sklearn.cluster.KMeans)"></a>K-means算法(sklearn.cluster.KMeans)</h2><p><strong>四步骤示意图</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1、随机设置K个特征空间内的点作为初始的聚类中心</span><br><span class="line">2、对于其他每个点计算到K个中心的距离，未知的点选择最近的一个聚类中心点作为标记类别</span><br><span class="line">3、接着对着标记的聚类中心之后，重新计算出每个聚类的新中心点（平均值）</span><br><span class="line">4、如果计算得出的新中心点与原中心点一样，那么结束，否则重新进行第二步过程</span><br></pre></td></tr></table></figure>

<p><img src="53.png" alt=""></p>
<h3 id="K-means算法API"><a href="#K-means算法API" class="headerlink" title="K-means算法API"></a>K-means算法API</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1.API: sklearn.cluster.KMeans(n_clusters&#x3D;8,init&#x3D;&#39;k-means++&#39;)</span><br><span class="line">  1.1 k-means聚类</span><br><span class="line">  1.2 n_clusters: 开始聚类中心的数量(几个堆)</span><br><span class="line">  1.3 init: 初始方法</span><br><span class="line">  1.4 labels_：默认标记的类型(可以和真实值比较)</span><br></pre></td></tr></table></figure>

<h3 id="对Instacart-Market用户聚类"><a href="#对Instacart-Market用户聚类" class="headerlink" title="对Instacart Market用户聚类"></a>对Instacart Market用户聚类</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">	1.降维后的数据</span><br><span class="line">	2.k-means聚类</span><br><span class="line">	3.聚类结果显示</span><br><span class="line">km&#x3D;KMeans(n_clusters&#x3D;4)</span><br><span class="line">km.fit(data)</span><br><span class="line">pre&#x3D;km.predict(data)</span><br></pre></td></tr></table></figure>
<h3 id="Kmeans性能评估指标-sklearn-metrics-silhouette-score"><a href="#Kmeans性能评估指标-sklearn-metrics-silhouette-score" class="headerlink" title="Kmeans性能评估指标(sklearn.metrics.silhouette_score)"></a>Kmeans性能评估指标(sklearn.metrics.silhouette_score)</h3><p><strong>轮廓系数</strong></p>
<p><img src="54.png" alt=""></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1.很像高级语言程序里面的&quot;高内聚低耦合&quot;</span><br><span class="line">2.轮廓系数介于[-1,1]</span><br><span class="line">3.b_i &gt;&gt; a_i : 轮廓系数趋近于1  效果很好</span><br><span class="line">4.b_i &lt;&lt; a_i : 轮廓系数趋近于-1 效果不好</span><br></pre></td></tr></table></figure>

<h3 id="轮廓系数API"><a href="#轮廓系数API" class="headerlink" title="轮廓系数API"></a>轮廓系数API</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sklearn.metrics.silhouette_score(X,labels)</span><br><span class="line">  1.计算所有样本的平均轮廓系数</span><br><span class="line">  2.X：特征值</span><br><span class="line">  3.labels:被聚类标记的目标值</span><br></pre></td></tr></table></figure>
      
      
        <div class="page-reward">
          <p><a href="javascript:void(0)" onclick="dashangToggle()" class="dashang">赏</a></p>
          <div class="hide_box"></div>
          <div class="shang_box">
            <a class="shang_close" href="javascript:void(0)" onclick="dashangToggle()">×</a>
            <div class="shang_tit">
              <p>纯属好玩</p>
            </div>
            <div class="shang_payimg">
              <img src="/img/alipayimg.jpg" alt="扫码支持" title="扫一扫" />
            </div>
              <div class="pay_explain">扫码打赏，你说多少就多少</div>
            <div class="shang_payselect">
              
                <div class="pay_item checked" data-id="alipay">
                  <span class="radiobox"></span>
                  <span class="pay_logo"><img src="/img/alipay.png" alt="支付宝" /></span>
                </div>
              
              
                <div class="pay_item" data-id="wechat">
                  <span class="radiobox"></span>
                  <span class="pay_logo"><img src="/img/weixin.png" alt="微信" /></span>
                </div>
              
            </div>
            <div class="shang_info">
              <p>打开<span id="shang_pay_txt">支付宝</span>扫一扫，即可进行扫码打赏哦</p>
            </div>
          </div>
        </div>
        <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/zepto/1.2.0/zepto.min.js"></script>
        <script type="text/javascript">
          $(".pay_item").click(function(){
            $(this).addClass('checked').siblings('.pay_item').removeClass('checked');
            var dataid=$(this).attr('data-id');
            $(".shang_payimg img").attr("src","/img/"+dataid+"img.jpg");
            $("#shang_pay_txt").text(dataid=="alipay"?"支付宝":"微信");
          });
          function dashangToggle(){
            
            $(".hide_box").fadeToggle();
            $(".shang_box").fadeToggle();
          }
        </script>
      
    </div>
    
  </div>
  
    
    <div class="copyright">
        <p><span>本文标题:</span><a href="/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></p>
        <p><span>文章作者:</span><a href="/" title="访问 Larkkkkkkk 的个人博客">Larkkkkkkk</a></p>
        <p><span>发布时间:</span>2022年04月01日 - 10时04分</p>
        <p><span>最后更新:</span>2022年09月30日 - 13时42分</p>
        <p>
            <span>原始链接:</span><a class="post-url" href="/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" title="机器学习">https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</a>
            <span class="copy-path" data-clipboard-text="原文: https://larkkkkkkk.github.io/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/　　作者: Larkkkkkkk" title="点击复制文章链接"><i class="fa fa-clipboard"></i></span>
            <script src="/js/clipboard.min.js"></script>
            <script> var clipboard = new Clipboard('.copy-path'); </script>
        </p>
        <p>
            <span>许可协议:</span><i class="fa fa-creative-commons"></i> <a rel="license noopener" href="http://creativecommons.org/licenses/by-nc-sa/3.0/cn/" target="_blank" title="中国大陆 (CC BY-NC-SA 3.0 CN)" target = "_blank">"署名-非商用-相同方式共享 3.0"</a> 转载请保留原文链接及作者。
        </p>
    </div>



<nav id="article-nav">
  
    <a href="/2022/04/07/python%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E5%AE%9E%E8%B7%B5%E8%AF%BE%E6%9C%AC%E8%AF%BE%E5%90%8E%E9%A2%98/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption"><</strong>
      <div class="article-nav-title">
        
          python从入门到实践课本课后题
        
      </div>
    </a>
  
  
    <a href="/2021/12/31/python/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">python</div>
      <strong class="article-nav-caption">></strong>
    </a>
  
</nav>

  
</article>

    <div id="toc" class="toc-article">
    <strong class="toc-title">文章目录</strong>
    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#机器学习计划"><span class="toc-number">1.</span> <span class="toc-text">机器学习计划</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#学习思路"><span class="toc-number">1.1.</span> <span class="toc-text">学习思路</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#参考视频pdf文件"><span class="toc-number">1.2.</span> <span class="toc-text">参考视频pdf文件</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#机器学习简介"><span class="toc-number">2.</span> <span class="toc-text">机器学习简介</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#相关关系"><span class="toc-number">2.1.</span> <span class="toc-text">相关关系</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#应用领域"><span class="toc-number">2.2.</span> <span class="toc-text">应用领域</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#相关概念"><span class="toc-number">2.3.</span> <span class="toc-text">相关概念</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#数据集-特征值-目标值"><span class="toc-number">2.3.1.</span> <span class="toc-text">数据集(特征值+目标值)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#常见三类问题"><span class="toc-number">2.3.2.</span> <span class="toc-text">常见三类问题</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#算法分类"><span class="toc-number">2.3.3.</span> <span class="toc-text">算法分类</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#开发流程"><span class="toc-number">2.3.4.</span> <span class="toc-text">开发流程</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#特征工程"><span class="toc-number">3.</span> <span class="toc-text">特征工程</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#数据集"><span class="toc-number">3.1.</span> <span class="toc-text">数据集</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#可用数据集"><span class="toc-number">3.1.1.</span> <span class="toc-text">可用数据集</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#sklearn数据集"><span class="toc-number">3.1.2.</span> <span class="toc-text">sklearn数据集</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#sklearn数据集内容"><span class="toc-number">3.1.2.1.</span> <span class="toc-text">sklearn数据集内容</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#sklearn获取流行数据集-datasets"><span class="toc-number">3.1.2.2.</span> <span class="toc-text">sklearn获取流行数据集(datasets)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#sklearn小数据集-load"><span class="toc-number">3.1.2.3.</span> <span class="toc-text">sklearn小数据集(load)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#sklearn大数据集-fetch"><span class="toc-number">3.1.2.4.</span> <span class="toc-text">sklearn大数据集(fetch)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#sklearn返回值-字典格式"><span class="toc-number">3.1.2.5.</span> <span class="toc-text">sklearn返回值(字典格式)</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#数据集划分"><span class="toc-number">3.1.3.</span> <span class="toc-text">数据集划分</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#数据集划分API-model-selection"><span class="toc-number">3.1.3.1.</span> <span class="toc-text">数据集划分API(model_selection)</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#特征工程介绍"><span class="toc-number">3.2.</span> <span class="toc-text">特征工程介绍</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#特征提取-sklearn-feature-extraction"><span class="toc-number">3.2.1.</span> <span class="toc-text">特征提取(sklearn.feature_extraction)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#特征提取分类"><span class="toc-number">3.2.1.1.</span> <span class="toc-text">特征提取分类</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#字典特征提取-DictVectorizer类"><span class="toc-number">3.2.1.2.</span> <span class="toc-text">字典特征提取(DictVectorizer类)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#文本特征提取-CountVectorizer类统计特征词出现个数"><span class="toc-number">3.2.1.3.</span> <span class="toc-text">文本特征提取(CountVectorizer类统计特征词出现个数)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#文本特征提取-TfidfVectorier类-jieba库的cut方法分词"><span class="toc-number">3.2.1.4.</span> <span class="toc-text">文本特征提取(TfidfVectorier类+jieba库的cut方法分词)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#jieba库的cut方法"><span class="toc-number">3.2.1.5.</span> <span class="toc-text">jieba库的cut方法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#TfidfVectorier类"><span class="toc-number">3.2.1.6.</span> <span class="toc-text">TfidfVectorier类</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#特征预处理-sklearn-preprocessing"><span class="toc-number">3.2.2.</span> <span class="toc-text">特征预处理(sklearn.preprocessing)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#归一化-MinMaxScaler"><span class="toc-number">3.2.2.1.</span> <span class="toc-text">归一化(MinMaxScaler)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#标准化-StandardScaler"><span class="toc-number">3.2.2.2.</span> <span class="toc-text">标准化(StandardScaler)</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#特征降维"><span class="toc-number">3.2.3.</span> <span class="toc-text">特征降维</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#特征选择"><span class="toc-number">3.2.3.1.</span> <span class="toc-text">特征选择</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#低方差特征过滤-varianceThreshold"><span class="toc-number">3.2.3.2.</span> <span class="toc-text">低方差特征过滤(varianceThreshold)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#相关系数过滤-scipy"><span class="toc-number">3.2.3.3.</span> <span class="toc-text">相关系数过滤(scipy)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#主成分分析-PCA降维保留信息"><span class="toc-number">3.2.3.4.</span> <span class="toc-text">主成分分析(PCA降维保留信息)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#instacart降维案例"><span class="toc-number">3.2.3.5.</span> <span class="toc-text">instacart降维案例</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#sklearn转换器和估计器"><span class="toc-number">3.3.</span> <span class="toc-text">sklearn转换器和估计器</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#转换器-fit-transform"><span class="toc-number">3.3.1.</span> <span class="toc-text">转换器(fit_transform)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#估计器-estimator"><span class="toc-number">3.3.2.</span> <span class="toc-text">估计器(estimator)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#K-近邻算法-sklearn-neighbors-KNeighborsClassifier"><span class="toc-number">3.4.</span> <span class="toc-text">K-近邻算法(sklearn.neighbors.KNeighborsClassifier)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#模型选择与调优-sklearn-model-selection-GridSearchCV"><span class="toc-number">3.4.1.</span> <span class="toc-text">模型选择与调优(sklearn.model_selection.GridSearchCV)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#电影类型分析"><span class="toc-number">3.4.2.</span> <span class="toc-text">电影类型分析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#鸢尾花分析"><span class="toc-number">3.4.3.</span> <span class="toc-text">鸢尾花分析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#鸢尾花分析-添加网格搜索和交叉验证"><span class="toc-number">3.4.4.</span> <span class="toc-text">鸢尾花分析(添加网格搜索和交叉验证)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#预测facebook签到位置"><span class="toc-number">3.4.5.</span> <span class="toc-text">预测facebook签到位置</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#朴素贝叶斯算法-sklearn-naive-bayes-MultinomialNB-alpha-1-0"><span class="toc-number">3.5.</span> <span class="toc-text">朴素贝叶斯算法(sklearn.naive_bayes.MultinomialNB(alpha&#x3D;1.0))</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#条件概率与联合概率"><span class="toc-number">3.5.1.</span> <span class="toc-text">条件概率与联合概率</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#贝叶斯公式"><span class="toc-number">3.5.2.</span> <span class="toc-text">贝叶斯公式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#拉普拉斯平滑系数-防止计算出的分类概率为0"><span class="toc-number">3.5.3.</span> <span class="toc-text">拉普拉斯平滑系数(防止计算出的分类概率为0)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#文本分类分析-新闻分类"><span class="toc-number">3.5.4.</span> <span class="toc-text">文本分类分析(新闻分类)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#决策树-sklearn-tree-DecisionTreeClassifier"><span class="toc-number">3.6.</span> <span class="toc-text">决策树(sklearn.tree.DecisionTreeClassifier)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#信息论基础"><span class="toc-number">3.6.1.</span> <span class="toc-text">信息论基础</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#决策树划分依据-3种"><span class="toc-number">3.6.2.</span> <span class="toc-text">决策树划分依据(3种)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#决策树的实现"><span class="toc-number">3.6.3.</span> <span class="toc-text">决策树的实现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#鸢尾花预测"><span class="toc-number">3.6.4.</span> <span class="toc-text">鸢尾花预测</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#决策树可视化-sklearn-tree-export-graphviz-导出DOT格式"><span class="toc-number">3.6.5.</span> <span class="toc-text">决策树可视化(sklearn.tree.export_graphviz()导出DOT格式)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#泰坦尼克号乘客生存预测"><span class="toc-number">3.6.6.</span> <span class="toc-text">泰坦尼克号乘客生存预测</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#随机森林-sklearn-ensemble-RandomForestClassifier"><span class="toc-number">3.7.</span> <span class="toc-text">随机森林(sklearn.ensemble.RandomForestClassifier)</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#回归问题"><span class="toc-number">4.</span> <span class="toc-text">回归问题</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#线性回归"><span class="toc-number">4.1.</span> <span class="toc-text">线性回归</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#线性回归定义"><span class="toc-number">4.1.1.</span> <span class="toc-text">线性回归定义</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#最小二乘法-损失函数"><span class="toc-number">4.1.2.</span> <span class="toc-text">最小二乘法(损失函数)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#优化方法之正规方程-直接求解sklearn-linear-model-LinearRegression"><span class="toc-number">4.1.3.</span> <span class="toc-text">优化方法之正规方程(直接求解sklearn.linear_model.LinearRegression)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#优化方法之梯度下降-不断试错sklearn-linear-model-SGDRegressor"><span class="toc-number">4.1.4.</span> <span class="toc-text">优化方法之梯度下降(不断试错sklearn.linear_model.SGDRegressor)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#波士顿房价预测-正规方程和梯度下降对比"><span class="toc-number">4.1.5.</span> <span class="toc-text">波士顿房价预测(正规方程和梯度下降对比)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#正则方程"><span class="toc-number">4.1.5.1.</span> <span class="toc-text">正则方程</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#梯度下降"><span class="toc-number">4.1.5.2.</span> <span class="toc-text">梯度下降</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#两者对比"><span class="toc-number">4.1.5.3.</span> <span class="toc-text">两者对比</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#回归性能评估-sklearn-metrics-mean-squared-error"><span class="toc-number">4.1.6.</span> <span class="toc-text">回归性能评估(sklearn.metrics.mean_squared_error)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#梯度下降优化方法-GD-SGD-SAG"><span class="toc-number">4.1.7.</span> <span class="toc-text">梯度下降优化方法(GD&#x2F;SGD&#x2F;SAG)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#欠拟合与过拟合"><span class="toc-number">4.2.</span> <span class="toc-text">欠拟合与过拟合()</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#正则化"><span class="toc-number">4.2.1.</span> <span class="toc-text">正则化</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#岭回归-带L2正则化的线性回归"><span class="toc-number">4.3.</span> <span class="toc-text">岭回归(带L2正则化的线性回归)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#波士顿房价预测-岭回归Ridge"><span class="toc-number">4.3.1.</span> <span class="toc-text">波士顿房价预测(岭回归Ridge)</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#分类算法"><span class="toc-number">5.</span> <span class="toc-text">分类算法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#逻辑回归"><span class="toc-number">5.1.</span> <span class="toc-text">逻辑回归</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#逻辑回归概念"><span class="toc-number">5.1.1.</span> <span class="toc-text">逻辑回归概念</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#逻辑回归过程"><span class="toc-number">5.1.2.</span> <span class="toc-text">逻辑回归过程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#逻辑回归损失-对数似然损失"><span class="toc-number">5.1.3.</span> <span class="toc-text">逻辑回归损失(对数似然损失)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#逻辑回归损失优化-梯度下降"><span class="toc-number">5.1.4.</span> <span class="toc-text">逻辑回归损失优化(梯度下降)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#逻辑回归API-sklearn-linear-model-LogisticRegression"><span class="toc-number">5.1.5.</span> <span class="toc-text">逻辑回归API(sklearn.linear_model.LogisticRegression)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#癌症分类"><span class="toc-number">5.1.6.</span> <span class="toc-text">癌症分类</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#代码实现"><span class="toc-number">5.1.6.1.</span> <span class="toc-text">代码实现</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#分类的评估方法-sklearn-metrics-classification-report"><span class="toc-number">5.2.</span> <span class="toc-text">分类的评估方法(sklearn.metrics.classification_report)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#混淆矩阵"><span class="toc-number">5.2.1.</span> <span class="toc-text">混淆矩阵</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#精确率-Precision-与召回率-Recall"><span class="toc-number">5.2.2.</span> <span class="toc-text">精确率(Precision)与召回率(Recall)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#F1-score"><span class="toc-number">5.2.3.</span> <span class="toc-text">F1-score</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#分类评估预测API"><span class="toc-number">5.2.4.</span> <span class="toc-text">分类评估预测API</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#TPR和FPR"><span class="toc-number">5.2.5.</span> <span class="toc-text">TPR和FPR</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ROC曲线"><span class="toc-number">5.2.6.</span> <span class="toc-text">ROC曲线</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#AUC指标-sklearn-metrics-roc-auc-score"><span class="toc-number">5.2.7.</span> <span class="toc-text">AUC指标(sklearn.metrics.roc_auc_score)</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#模型保存和加载-sklearn-externals-joblib"><span class="toc-number">6.</span> <span class="toc-text">模型保存和加载(sklearn.externals.joblib)</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#sklearn模型API"><span class="toc-number">6.1.</span> <span class="toc-text">sklearn模型API</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#无监督学习"><span class="toc-number">7.</span> <span class="toc-text">无监督学习</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#K-means算法-sklearn-cluster-KMeans"><span class="toc-number">7.1.</span> <span class="toc-text">K-means算法(sklearn.cluster.KMeans)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#K-means算法API"><span class="toc-number">7.1.1.</span> <span class="toc-text">K-means算法API</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#对Instacart-Market用户聚类"><span class="toc-number">7.1.2.</span> <span class="toc-text">对Instacart Market用户聚类</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kmeans性能评估指标-sklearn-metrics-silhouette-score"><span class="toc-number">7.1.3.</span> <span class="toc-text">Kmeans性能评估指标(sklearn.metrics.silhouette_score)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#轮廓系数API"><span class="toc-number">7.1.4.</span> <span class="toc-text">轮廓系数API</span></a></li></ol></li></ol></li></ol>
</div>
<input type="button" id="tocButton" value="隐藏目录"  title="点击按钮隐藏或者显示文章目录">


<script src="https://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js"></script>

<script>
    var valueHide = "隐藏目录";
    var valueShow = "显示目录";

    if ($(".left-col").is(":hidden")) {
        $("#tocButton").attr("value", valueShow);
    }
    $("#tocButton").click(function() {
        if ($("#toc").is(":hidden")) {
            $("#tocButton").attr("value", valueHide);
            $("#toc").slideDown(320);
        }
        else {
            $("#tocButton").attr("value", valueShow);
            $("#toc").slideUp(350);
        }
    })
    if ($(".toc").length < 1) {
        $("#toc, #tocButton").hide();
    }
</script>





<div class="bdsharebuttonbox">
	<a href="#" class="fx fa-weibo bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a>
	<a href="#" class="fx fa-weixin bds_weixin" data-cmd="weixin" title="分享到微信"></a>
	<a href="#" class="fx fa-qq bds_sqq" data-cmd="sqq" title="分享到QQ好友"></a>
	<a href="#" class="fx fa-facebook-official bds_fbook" data-cmd="fbook" title="分享到Facebook"></a>
	<a href="#" class="fx fa-twitter bds_twi" data-cmd="twi" title="分享到Twitter"></a>
	<a href="#" class="fx fa-linkedin bds_linkedin" data-cmd="linkedin" title="分享到linkedin"></a>
	<a href="#" class="fx fa-files-o bds_copy" data-cmd="copy" title="分享到复制网址"></a>
</div>
<script>window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"2","bdSize":"24"},"share":{}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];</script>




    
        <section id="comments">
  <div id="disqus_thread"></div>
    <script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'swing'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" target="_blank" rel="noopener">comments powered by Disqus.</a></noscript>
</section>
    



    <div class="scroll" id="post-nav-button">
        
            <a href="/2022/04/07/python%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E5%AE%9E%E8%B7%B5%E8%AF%BE%E6%9C%AC%E8%AF%BE%E5%90%8E%E9%A2%98/" title="上一篇: python从入门到实践课本课后题">
                <i class="fa fa-angle-left"></i>
            </a>
        
        <a title="文章列表"><i class="fa fa-bars"></i><i class="fa fa-times"></i></a>
        
            <a href="/2021/12/31/python/" title="下一篇: python">
                <i class="fa fa-angle-right"></i>
            </a>
        
    </div>
    <ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2023/10/24/JAVA-%E9%9B%86%E5%90%88%E6%A1%86%E6%9E%B6/">JAVA-集合框架</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/10/21/picgo/">picgo</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/10/20/%E4%BB%A3%E7%A0%81%E9%9A%8F%E6%83%B3%E5%BD%95-JAVA/">代码随想录</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/10/20/JAVA-%E5%B8%B8%E7%94%A8%E7%B1%BB%E5%92%8C%E5%9F%BA%E7%A1%80API/">JAVA-常用类和基础API</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/10/20/JAVA-%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/">JAVA-异常处理</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/10/20/JAVA-%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/">JAVA-面向对象</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/10/20/JAVA-%E5%9F%BA%E7%A1%80%E7%AF%87/">JAVA-基础篇</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/09/19/%E5%B0%9A%E7%A1%85%E8%B0%B7java/">尚硅谷JAVA基础</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/07/18/pytorch%E5%B0%8F%E5%9C%9F%E5%A0%86/">pytorch小土堆</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/06/04/python%E6%89%93%E5%8C%85/">python打包</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/25/pytorch/">pytorch</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/23/django/">django</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/22/flask%E6%8E%A5%E5%8F%A3/">flask接口</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/22/Docker/">Docker</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/22/JQ%E5%AE%9E%E7%8E%B0%E8%A1%A8%E5%8D%95%E6%A0%A1%E9%AA%8C/style/">JQ实现表单校验/style</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/22/JQ%E5%AE%9E%E7%8E%B0%E8%A1%A8%E5%8D%95%E6%A0%A1%E9%AA%8C/jquery-1.11.0/">JQ实现表单校验/jquery-1.11.0</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/22/JQ%E5%AE%9E%E7%8E%B0%E8%80%81%E9%BB%84%E5%8E%86/style/">JQ实现老黄历/style</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/22/JQ%E5%AE%9E%E7%8E%B0%E8%80%81%E9%BB%84%E5%8E%86/laohuangli/">JQ实现老黄历/laohuangli</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/22/JQ%E5%AE%9E%E7%8E%B0%E8%80%81%E9%BB%84%E5%8E%86/jquery-1.11.0/">JQ实现老黄历/jquery-1.11.0</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/22/JQ%E5%AE%9E%E7%8E%B0%E8%80%81%E9%BB%84%E5%8E%86/data/">JQ实现老黄历/data</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/22/JQuery%E9%80%89%E6%8B%A9%E5%99%A8/style/">JQuery选择器/style</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/22/JQuery%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/jquery-1.11.3.min/">JQuery基本用法/jquery-1.11.3.min</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/22/JQuery/jquery-1.11.0/">JQuery/jquery-1.11.0</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/22/Bootstrap/bootstrap-3.3.5-dist/js/npm/">Bootstrap/bootstrap-3.3.5-dist/js/npm</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/22/Bootstrap/bootstrap-3.3.5-dist/js/bootstrap.min/">Bootstrap/bootstrap-3.3.5-dist/js/bootstrap.min</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/22/Bootstrap/bootstrap-3.3.5-dist/js/bootstrap/">Bootstrap/bootstrap-3.3.5-dist/js/bootstrap</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/22/Bootstrap/bootstrap-3.3.5-dist/css/bootstrap.min/">Bootstrap/bootstrap-3.3.5-dist/css/bootstrap.min</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/22/Bootstrap/bootstrap-3.3.5-dist/css/bootstrap/">Bootstrap/bootstrap-3.3.5-dist/css/bootstrap</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/22/Bootstrap/bootstrap-3.3.5-dist/css/bootstrap-theme.min/">Bootstrap/bootstrap-3.3.5-dist/css/bootstrap-theme.min</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/22/Bootstrap/bootstrap-3.3.5-dist/css/bootstrap-theme/">Bootstrap/bootstrap-3.3.5-dist/css/bootstrap-theme</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/22/Larkkkkkkk/">Larkkkkkkk</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/04/17/py2neo/">py2neo</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/04/17/neo4j/">neo4j</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/04/16/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/">知识图谱</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/11/22/%E5%90%8E%E7%BC%80%E6%A0%91/">后缀树</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/11/11/%E7%94%9F%E7%89%A9%E4%BF%A1%E6%81%AF%E5%AD%A6/">生物信息学</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/11/02/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">动手学深度学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/11/01/Scrapy%E7%88%AC%E8%99%AB%E8%BF%9B%E9%98%B6/">Scrapy爬虫进阶</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/10/28/%E7%88%AC%E8%99%AB/">爬虫基础</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/10/26/%E7%AE%97%E6%B3%95%E6%B1%87%E6%80%BB%EF%BC%88Python%EF%BC%89/">算法汇总（Python）</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/10/15/CS224n%E6%96%AF%E5%9D%A6%E7%A6%8F%E6%B7%B1%E5%BA%A6%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E8%AF%BE/">CS224n斯坦福深度自然语言处理课</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/10/11/%E8%BD%AF%E4%BB%B6%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/">软件体系结构</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/10/10/%E5%8F%8C%E7%A2%B3%E5%A4%A7%E8%B5%9B-%E5%9E%83%E5%9C%BE%E5%88%86%E7%B1%BB/">双碳大赛-垃圾分类</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/10/07/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5/">PyTorch深度学习实践</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/10/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/">机器学习实战之工业蒸汽</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/09/17/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/">统计学习方法</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/09/06/%E5%88%A9%E7%94%A8python%E8%BF%9B%E8%A1%8C%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/">利用python进行数据分析</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/04/07/python%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E5%AE%9E%E8%B7%B5%E8%AF%BE%E6%9C%AC%E8%AF%BE%E5%90%8E%E9%A2%98/">python从入门到实践课本课后题</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/12/31/python/">python</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/06/28/B%E5%86%8C%E7%BC%96%E7%A8%8B%E9%A2%98/">B册编程题</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/06/23/c%E8%AF%AD%E8%A8%80%E8%AF%BE%E6%9C%AC%E9%A2%98%E7%9B%AE/">c语言课本题目</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/04/07/%E5%88%9D%E8%AF%95code/">初试code</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/25/%E7%A2%8E%E7%A2%8E%E5%BF%B5/">碎碎念</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/07/%E8%93%9D%E6%A1%A5%E6%9D%AF%E5%9B%BD%E8%B5%9B/">蓝桥杯国赛</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/10/23/Linux%E7%B3%BB%E7%BB%9F%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/">Linux系统目录结构</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/10/04/LeetCode%E9%93%BE%E8%A1%A8/">LeetCode链表</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/08/21/%E6%9C%AC%E5%9C%B0%E9%A1%B9%E7%9B%AE%E4%B8%8A%E4%BC%A0Github/">本地项目上传Github</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/08/13/JVM/">JVM</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/08/05/Mysql%E5%A4%8D%E4%B9%A0/">Mysql复习</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/08/02/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E6%80%BB%E7%BB%93/">设计模式总结</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/07/31/%E4%BA%AC%E4%B8%9C2019%E6%A0%A1%E6%8B%9B%E7%AC%94%E8%AF%95Java%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88%E7%AC%94%E8%AF%95%E9%A2%98/">京东2019校招笔试Java开发工程师笔试题</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/07/30/%E4%BA%AC%E4%B8%9C2019%E6%98%A5%E6%8B%9B%E4%BA%AC%E4%B8%9CJava%E5%BC%80%E5%8F%91%E8%AF%95%E5%8D%B7/">京东2019春招京东Java开发试卷</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/07/29/%E6%8B%BC%E5%A4%9A%E5%A4%9A2020%E6%A0%A1%E6%8B%9B%E9%83%A8%E5%88%86%E7%BC%96%E7%A8%8B%E9%A2%98%E5%90%88%E9%9B%86/">拼多多2020校招部分编程题合集</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/07/21/Git%E5%A4%8D%E4%B9%A0/">Git复习</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/07/16/leetcode%E5%89%91%E6%8C%87offer/">leetcode剑指offer</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/07/12/Hexo%E5%8D%9A%E5%AE%A2%E9%87%8D%E8%A3%85%E7%B3%BB%E7%BB%9F%E9%87%8D%E6%96%B0%E9%83%A8%E7%BD%B2/">Hexo博客重装系统重新部署</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/07/08/%E5%B0%9A%E5%AD%A6%E5%A0%82CRUD%E6%A8%A1%E6%9D%BF/">尚学堂CRUD模板</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/06/19/LeetCode%E7%B2%BE%E9%80%89TOP%E9%9D%A2%E8%AF%95%E9%A2%98/">LeetCode精选TOP面试题</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/06/16/LeetCode%E5%93%88%E5%B8%8C%E8%A1%A8/">LeetCode哈希表</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/06/16/LeetCode%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95/">LeetCode贪心算法</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/06/15/LeetCode%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/">LeetCode二分查找</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/06/14/LeetCode%E5%8F%8C%E6%8C%87%E9%92%88/">LeetCode双指针</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/06/13/LeetCode%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/">LeetCode动态规划</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/06/12/LeetCode%E6%95%B0%E5%AD%A6%E9%97%AE%E9%A2%98/">LeetCode数学问题</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/06/11/LeetCode%E9%80%92%E5%BD%92/">LeetCode递归</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/06/10/LeetCode%E6%8E%92%E5%BA%8F/">LeetCode排序</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/06/05/LeetCode%E5%AD%97%E7%AC%A6%E4%B8%B2/">LeetCode字符串</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/05/27/LeetCode%E6%95%B0%E7%BB%84/">LeetCode数组</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/05/11/%E5%89%91%E6%8C%87offer/">剑指offer</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/05/02/%E5%9B%BE/">图</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/05/01/%E5%93%88%E5%B8%8C%E8%A1%A8/">哈希表</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/22/%E5%93%88%E5%BC%97%E6%9B%BC%E6%A0%91/">哈弗曼树</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/18/%E4%BA%8C%E5%8F%89%E6%A0%91/">二叉树</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/18/%E6%A0%91/">树</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/15/%E6%8E%92%E5%BA%8F/">排序</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/15/%E6%97%B6%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%92%8C%E7%A9%BA%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%88%86%E6%9E%90/">时间复杂度和空间复杂度分析</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/14/%E9%80%92%E5%BD%92/">递归</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/12/SpringBoot/">SpringBoot</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/12/%E9%93%BE%E8%A1%A8/">链表</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/11/%E9%98%9F%E5%88%97/">队列</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/11/%E6%A0%88/">栈</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/11/SpringMVC%E5%AF%B9Date%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2/">SpringMVC对Date类型转换</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/11/SpringMVC%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/">SpringMVC原理分析</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/11/SpringMVC%E5%AE%9E%E7%8E%B0%E8%87%AA%E5%AE%9A%E4%B9%89%E6%8B%A6%E6%88%AA%E5%99%A8/">SpringMVC实现自定义拦截器</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/10/SpringMVC%E5%AE%9E%E7%8E%B0%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E5%92%8C%E4%B8%8B%E8%BD%BD/">SpringMVC实现文件上传和下载</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/09/JSP%E4%B9%9D%E5%A4%A7%E5%86%85%E7%BD%AE%E5%AF%B9%E8%B1%A1%E5%92%8C%E5%9B%9B%E5%A4%A7%E4%BD%9C%E7%94%A8%E5%9F%9F/">JSP九大内置对象和四大作用域</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/09/SpringMVC%E5%AE%9E%E7%8E%B0%E8%8F%9C%E5%8D%95%E5%8A%9F%E8%83%BD/">SpringMVC实现菜单功能</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/07/SpringMVC/">SpringMVC</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/06/Ajax%E6%95%B4%E7%90%86/">Ajax整理</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/06/Spring%E5%B8%B8%E7%94%A8%E6%B3%A8%E8%A7%A3%E6%95%B4%E7%90%86/">Spring常用注解整理</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/04/Spring%E4%BA%8B%E5%8A%A1/">Spring事务</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/04/Spring%E5%8D%95%E4%BE%8B%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/">Spring单例设计模式</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/04/Spring%E5%8A%A0%E8%BD%BD%E5%B1%9E%E6%80%A7%E6%96%87%E4%BB%B6%E5%92%8Cscope%E5%B1%9E%E6%80%A7/">Spring加载属性文件和scope属性</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/03/Spring%E8%87%AA%E5%8A%A8%E6%B3%A8%E5%85%A5/">Spring自动注入</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/03/Spring%E4%BB%A3%E7%90%86%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/">Spring代理设计模式</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/02/AOP/">AOP</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/01/Spring%E6%95%B4%E5%90%88Mybatis/">Spring整合Mybatis</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/01/Spring%E7%BB%99Bean%E6%B3%A8%E5%85%A5/">Spring给Bean注入</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/31/Spring/">Spring</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/31/Mybatis%E8%BF%90%E8%A1%8C%E5%8E%9F%E7%90%86%E6%80%BB%E7%BB%93/">Mybatis运行原理总结</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/30/Mybatis%E6%B3%A8%E8%A7%A3/">Mybatis注解</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/29/%E4%BD%BF%E7%94%A8Mybatis%E7%9A%84%E5%8A%A8%E6%80%81Sql%E5%AE%9E%E7%8E%B0%E5%A4%9A%E8%A1%A8%E6%9F%A5%E8%AF%A2/">使用Mybatis的动态Sql实现多表查询</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/28/Mybatis%E7%BC%93%E5%AD%98/">Mybatis缓存</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/28/ThreadLocal/">ThreadLocal</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/28/%E5%8A%A8%E6%80%81SQL/">动态SQL</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/27/getMapper%E6%8E%A5%E5%8F%A3%E7%BB%91%E5%AE%9A%E5%92%8C%E5%A4%9A%E5%8F%82%E6%95%B0%E4%BC%A0%E9%80%92/">getMapper接口绑定和多参数传递</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/25/Mybatis%E5%AE%9E%E7%8E%B0%E8%BD%AC%E8%B4%A6/">Mybatis实现转账</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/25/Mybatis%E5%AE%9E%E7%8E%B0%E5%88%86%E9%A1%B5%E5%8A%9F%E8%83%BD%EF%BC%88%E5%AE%8C%E6%95%B4%E6%B5%81%E7%A8%8B%EF%BC%89/">Mybatis实现分页功能（完整流程）</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/24/Mybatis%E5%AE%9E%E7%8E%B0%E6%96%B0%E5%A2%9E%E5%88%A0%E9%99%A4%E4%BF%AE%E6%94%B9%E5%92%8C%E4%BA%8B%E5%8A%A1%E8%AE%B2%E8%A7%A3/">Mybatis实现新增删除修改和事务讲解</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/24/Mybatis%E5%AE%9E%E7%8E%B0mysql%E5%88%86%E9%A1%B5/">Mybatis实现mysql分页</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/21/Mybatis%E6%9F%A5%E8%AF%A2%E6%89%80%E6%9C%89/">Mybatis查询所有</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/21/Log4J/">Log4J</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/20/Mybatis%E5%85%A8%E5%B1%80%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/">Mybatis全局配置文件详解</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/20/Mybatis%EF%BC%88eclipse%E8%AF%A6%E7%BB%86%EF%BC%89/">Mybatis（eclipse详细）</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/18/Mybatis%EF%BC%88idea+maven%EF%BC%89/">Mybatis（idea+maven）</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/17/Nginx/">Nginx</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/17/Linux%E9%83%A8%E7%BD%B2/">Linux部署</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/16/Linux%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86/">Linux网络知识</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/16/Vim/">Vim</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/14/maven/">maven</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/13/redis%E9%85%8D%E5%90%88ajax%E5%AE%9E%E7%8E%B0%E6%98%BE%E7%A4%BA%E4%B8%8B%E6%8B%89%E5%88%97%E8%A1%A8%E7%9C%81%E4%BB%BD/">redis配合ajax实现显示下拉列表省份</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/10/Linux%E5%AE%89%E8%A3%85%E8%BD%AF%E4%BB%B6/">Linux安装软件</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/10/redis/">redis</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/10/%E8%B0%B7%E6%AD%8CCar%E5%BC%95%E5%85%A5%E8%A3%85%E9%A5%B0%E8%80%85%E6%A8%A1%E5%BC%8F/">谷歌Car引入装饰者模式</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/10/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/">设计模式</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/10/%E6%B3%A8%E8%A7%A3/">注解</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/08/%E8%87%AA%E5%8A%A8%E7%99%BB%E5%BD%95%EF%BC%88%E8%BF%87%E6%BB%A4%E5%99%A8%EF%BC%89/">自动登录（过滤器）</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/08/Filter/">Filter</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/07/JQuery%E7%9C%81%E5%B8%82%E8%81%94%E5%8A%A8/">JQuery省市联动</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/06/Listener/">Listener</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/06/JQuery%E4%BB%BF%E7%99%BE%E5%BA%A6%E6%90%9C%E7%B4%A2/">JQuery仿百度搜索</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/06/JQuery%E6%A0%A1%E9%AA%8C%E7%94%A8%E6%88%B7%E5%90%8D/">JQuery校验用户名</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/06/JQuery%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/">JQuery基本用法</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/05/Ajax%E5%AE%9E%E7%8E%B0%E6%A0%A1%E9%AA%8C%E7%94%A8%E6%88%B7%E5%90%8D/">Ajax实现校验用户名</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/04/Ajax/">Ajax</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/29/%E5%AD%A6%E7%94%9F%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%EF%BC%882-0%EF%BC%89/">学生管理系统（2.0）</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/29/%E4%B8%89%E5%B1%82%E6%9E%B6%E6%9E%84/">三层架构</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/29/JSP%E5%BC%80%E5%8F%91%E6%A8%A1%E5%BC%8F/">JSP开发模式</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/29/DBUtils%E9%80%9A%E7%94%A8%E7%9A%84%E5%A2%9E%E5%88%A0%E6%9F%A5%E6%94%B9/">DBUtils通用的增删查改</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/29/DBUtils/">DBUtils</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/28/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0/">数据库连接池</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/27/%E4%BA%8B%E5%8A%A1/">事务</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/27/%E5%AD%A6%E7%94%9F%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/">学生管理系统</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/26/JSTL/">JSTL</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/26/EL%E8%A1%A8%E8%BE%BE%E5%BC%8F/">EL表达式</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/25/JSP/">JSP</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/25/Session%E5%AE%9E%E7%8E%B0%E8%B4%AD%E7%89%A9%E8%BD%A6/">Session实现购物车</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/24/Cookie%E8%8E%B7%E5%8F%96%E5%95%86%E5%93%81%E6%B5%8F%E8%A7%88%E8%AE%B0%E5%BD%95/">Cookie获取商品浏览记录</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/24/Cookie%E8%8E%B7%E5%8F%96%E4%B8%8A%E6%AC%A1%E7%99%BB%E5%BD%95%E6%97%B6%E9%97%B4/">Cookie获取上次登录时间</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/23/Session/">Session</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/23/Cookie/">Cookie</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/19/Linux/">Linux</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/18/ServletContext/">ServletContext</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/18/HTTPServletReauest%E5%92%8CHTTPServletResponse/">HTTPServletReauest和HTTPServletResponse</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/17/Servlet/">Servlet</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/17/HTTP%E5%8D%8F%E8%AE%AE/">HTTP协议</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/16/Tomcat/">Tomcat</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/16/dom4j%E5%85%A5%E9%97%A8/">dom4j入门</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/15/XML/">XML</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/15/%E6%95%B0%E6%8D%AE%E5%BA%93cmd%E7%9A%84%E6%93%8D%E4%BD%9C%EF%BC%88%E4%BB%A5%E5%90%8E%E5%86%99%EF%BC%89/">数据库cmd的操作（以后写）</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/15/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E5%88%9B%E5%BB%BA%E6%9F%A5%E7%9C%8B%E5%88%A0%E9%99%A4/">数据库的创建查看删除</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/14/JDBC%E4%B8%AD%E7%9A%84JAVAEE%E7%BB%93%E6%9E%84/">JDBC中的JAVAEE结构</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/13/JDBC%E5%AF%B9%E4%BA%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84CRUD/">数据库的CRUD</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/12/%E6%95%B0%E6%8D%AE%E5%BA%93/">数据库</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/12/JDBC%E7%9A%84%E5%B7%A5%E5%85%B7%E7%B1%BB/">JDBC的工具类</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/12/JDBC/">JDBC</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/12/bootstrap%E5%AE%9E%E7%8E%B0%E7%BD%91%E7%AB%99%E9%A6%96%E9%A1%B5/">bootstrap实现网站首页</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/12/boostrap%E5%AE%9E%E7%8E%B0%E5%AF%BC%E8%88%AA%E6%9D%A1/">boostrap实现导航条</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/10/JQ%E5%AE%9E%E7%8E%B0%E8%80%81%E9%BB%84%E5%8E%86/">JQ实现老黄历</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/10/JQ%E5%AE%9E%E7%8E%B0%E8%A1%A8%E5%8D%95%E6%A0%A1%E9%AA%8C/">JQ实现表单校验</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/10/Bootstrap/">Bootstrap</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/09/JQ%E5%AE%9E%E7%8E%B0%E5%95%86%E5%93%81%E5%B7%A6%E5%8F%B3%E9%80%89%E6%8B%A9/">JQ实现商品左右选择</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/09/JQ%E5%AE%9E%E7%8E%B0%E7%9C%81%E5%B8%82%E8%81%94%E5%8A%A8/">JQ实现省市联动</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/09/JQ%E5%AE%9E%E7%8E%B0%E8%A1%A8%E6%A0%BC%E5%8F%98%E8%89%B2%E5%92%8C%E5%85%A8%E9%80%89%E9%97%AE%E9%A2%98/">JQ实现表格隔行换色</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/09/JQ%E5%AE%9E%E7%8E%B0%E8%A1%A8%E5%8D%95%E5%B1%9E%E6%80%A7%E8%BF%87%E6%BB%A4/">JQ实现表单属性过滤</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/08/JQuery%E9%80%89%E6%8B%A9%E5%99%A8/">JQuery选择器</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/08/JQuery%E5%AE%9E%E7%8E%B0%E5%AE%9A%E6%97%B6%E6%92%AD%E6%94%BE%E5%B9%BF%E5%91%8A/">JQuery实现定时播放广告</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/07/JQuery/">JQuery</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/07/JS%E6%8E%A7%E5%88%B6%E4%B8%8B%E6%8B%89%E5%88%97%E8%A1%A8%E5%B7%A6%E5%8F%B3%E9%80%89%E6%8B%A9/">JS控制下拉列表左右选择</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/07/JS%E5%AE%9E%E7%8E%B0%E8%A1%A8%E5%8D%95%E6%A3%80%E9%AA%8C%EF%BC%88%E4%BD%BF%E7%94%A8onfoucs%E7%AD%89%E7%84%A6%E7%82%B9%E6%97%B6%E9%97%B4%EF%BC%89/">JS实现表单检验（使用onfoucs等焦点时间）</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/07/JS%E5%AE%9E%E7%8E%B0%E8%A1%A8%E6%A0%BC%E5%8F%98%E8%89%B2%E5%92%8C%E5%85%A8%E9%80%89%E9%97%AE%E9%A2%98/">JS实现表格变色和全选问题</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/07/JS%E5%AE%9E%E7%8E%B0DOM%E6%93%8D%E4%BD%9C%EF%BC%88%E5%85%B3%E4%BA%8Eselect%E6%A0%87%E7%AD%BE%E7%9A%84%E4%B8%8B%E6%8B%89%E7%9C%81%E5%B8%82%E8%81%94%E5%8A%A8%EF%BC%89/">JS实现DOM操作（关于select标签的下拉省市联动）</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/05/JS%E5%AE%9E%E7%8E%B0%E8%87%AA%E5%8A%A8%E6%92%AD%E6%94%BE%E5%B9%BF%E5%91%8A/">JS实现页面表单表格</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/05/JS%E5%AE%9E%E7%8E%B0%E8%BD%AE%E6%92%AD%E5%9B%BE/">JS实现轮播图</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/04/JS/">JS</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/04/CSS%E7%BD%91%E7%AB%99%E6%B3%A8%E5%86%8C%E6%A1%88%E4%BE%8B/">CSS网站注册案例</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/04/CSS-div%E5%AE%9E%E7%8E%B0%E7%BD%91%E7%AB%99%E9%A6%96%E9%A1%B5%E4%BC%98%E5%8C%96/">CSS+div实现网站首页优化</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/02/CSS/">CSS和DIV</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/02/HTML%E7%BD%91%E7%AB%99%E5%90%8E%E5%8F%B0%E6%A1%88%E4%BE%8B/">网站后台案例</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/02/HTML%E7%BD%91%E7%AB%99%E6%B3%A8%E5%86%8C%E6%A1%88%E4%BE%8B/">网站注册案例</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/01/HTML%E7%BD%91%E7%AB%99%E9%A6%96%E9%A1%B5%E6%A1%88%E4%BE%8B/">HTML网站首页案例</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/01/HTML/">HTML</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/01/30/%E5%8F%8D%E5%B0%84/">反射</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/01/28/%E7%A8%80%E7%96%8F%E6%95%B0%E7%BB%84/">稀疏数组</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/12/30/%E7%BD%91%E7%BB%9C%E8%AF%BE%E8%AE%BE/">网络课设</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/12/19/webserver/">webserver</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/25/TCP/">TCP编程</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/17/%E4%BC%A0%E8%BE%93%E5%8D%8F%E8%AE%AE/">传输协议(UDP)</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/13/%E7%AC%AC%E5%8D%81%E5%B1%8A%E8%93%9D%E6%A1%A5%E6%9D%AF%E7%9C%81%E8%B5%9B/">第十届蓝桥杯省赛</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/12/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/">网络编程</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/11/%E7%AD%89%E5%BE%85%E5%94%A4%E9%86%92%E6%9C%BA%E5%88%B6/">等待唤醒机制</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/07/%E8%93%9D%E6%A1%A5%E6%9D%AF%E6%A0%A1%E8%B5%9B/">蓝桥杯校赛</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/07/%E7%BA%BF%E7%A8%8B%E7%8A%B6%E6%80%81/">线程状态</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/05/%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8/">线程安全</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/04/JAVA-%E5%A4%9A%E7%BA%BF%E7%A8%8B/">JAVA-多线程</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/02/List/">List接口</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/02/Set/">Set集合</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/31/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/">正则表达式(regex)</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/29/%E8%BF%AD%E4%BB%A3%E5%99%A8/">集合2</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/29/%E6%B3%9B%E5%9E%8B/">泛型</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/26/%E8%93%9D%E6%A1%A5%E6%9D%AF%E7%BB%83%E4%B9%A0/">蓝桥杯</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/26/%E9%9B%86%E5%90%88/">集合1</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/24/Lambda/">Lambda表达式</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/23/%E9%A1%B5%E9%9D%A2/">人机交互实验</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/17/%E5%9B%9E%E6%BA%AF%E6%B3%95/">回溯算法</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/15/%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95/">贪心算法</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/11/%E7%88%AC%E6%A5%BC%E6%A2%AF/">以爬楼梯为例</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/11/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/">动态规划</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/08/idea%E5%AE%89%E8%A3%85/">IntelliJ IDEA</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/08/%E6%8E%A5%E9%9B%A8%E6%B0%B4(%E5%8F%8C%E6%8C%87%E9%92%88)/">接雨水</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/08/%E4%B9%98%E6%9B%B4%E5%A4%9A%E7%9A%84%E6%B0%B4(%E5%8F%8C%E6%8C%87%E9%92%88)/">乘更多的水</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/04/wenzipian2/">文字篇2-《码农翻身》</a></li></ul>
    <script src="https://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js"></script>
    <script>
        $(".post-list").addClass("toc-article");
        $(".post-list-item a").attr("target","_blank");
        $("#post-nav-button > a:nth-child(2)").click(function() {
            $(".fa-bars, .fa-times").toggle();
            $(".post-list").toggle(300);
            if ($(".toc").length > 0) {
                $("#toc, #tocButton").toggle(200, function() {
                    if ($(".switch-area").is(":visible")) {
                        $("#tocButton").attr("value", valueHide);
                        }
                    })
            }
            else {
            }
        })
    </script>



    <script>
        
    </script>
</div>
      <footer id="footer">
    <div class="outer">
        <div id="footer-info">
            <div class="footer-left">
                &copy; 2023 Larkkkkkkk
            </div>
            <div class="footer-right">
                <a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="http://bestwing.me" target="_blank">Sw'blog</a> by Swing
            </div>
        </div>
        
            <div class="visit">
                
                    <span id="busuanzi_container_site_pv" style='display:none'>
                        <span id="site-visit" >海贼到访数: 
                            <span id="busuanzi_value_site_uv"></span>
                        </span>
                    </span>
                
                
                    <span>, </span>
                
                
                    <span id="busuanzi_container_page_pv" style='display:none'>
                        <span id="page-visit">本页阅读量: 
                            <span id="busuanzi_value_page_pv"></span>
                        </span>
                    </span>
                
            </div>
        
    </div>
</footer>

    </div>
    
<script src="https://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js"></script>


<script src="/js/main.js"></script>


    <script>
        $(document).ready(function() {
            var backgroundnum = 24;
            var backgroundimg = "url(/background/bg-x.jpg)".replace(/x/gi, Math.ceil(Math.random() * backgroundnum));
            $("#mobile-nav").css({"background-image": backgroundimg,"background-size": "cover","background-position": "center"});
            $(".left-col").css({"background-image": backgroundimg,"background-size": "cover","background-position": "center"});
        })
    </script>





<div class="scroll" id="scroll">
    <a href="#"><i class="fa fa-arrow-up"></i></a>
    <a href="#comments"><i class="fa fa-comments-o"></i></a>
    <a href="#footer"><i class="fa fa-arrow-down"></i></a>
</div>
<script>
    $(document).ready(function() {
        if ($("#comments").length < 1) {
            $("#scroll > a:nth-child(2)").hide();
        };
    })
</script>

<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>

  <script language="javascript">
    $(function() {
        $("a[title]").each(function() {
            var a = $(this);
            var title = a.attr('title');
            if (title == undefined || title == "") return;
            a.data('title', title).removeAttr('title').hover(

            function() {
                var offset = a.offset();
                $("<div id=\"anchortitlecontainer\"></div>").appendTo($("body")).html(title).css({
                    top: offset.top - a.outerHeight() - 15,
                    left: offset.left + a.outerWidth()/2 + 1
                }).fadeIn(function() {
                    var pop = $(this);
                    setTimeout(function() {
                        pop.remove();
                    }, pop.text().length * 800);
                });
            }, function() {
                $("#anchortitlecontainer").remove();
            });
        });
    });
</script>


    <script type="text/javascript">
      window.onload = function(){
        document.getElementById("search").onclick = function(){
            console.log("search")
            search();
        }
      }
      function search(){
        (function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){
        (w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);
        e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);
        })(window,document,'script','//s.swiftypecdn.com/install/v2/st.js','_st');

        _st('install','A1Pz-LKMXbrzcFg2FWi6','2.0.0');
      }
    </script>

  </div>
</body>
</html>