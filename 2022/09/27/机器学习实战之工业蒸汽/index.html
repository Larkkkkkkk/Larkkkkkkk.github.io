<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>机器学习实战之工业蒸汽 | Larkkkkkkk</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="题目基本情况数据集121.数据集:https:&#x2F;&#x2F;tianchi.aliyun.com&#x2F;dataset&#x2F;dataDetail?dataId&#x3D;130516  数据探索理论知识 赛题数据探索导入工具包123456789101112import numpy as npimport pandas as pdimport matplotlib.pyplot">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习实战之工业蒸汽">
<meta property="og:url" content="https://larkkkkkkk.github.io/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/index.html">
<meta property="og:site_name" content="Larkkkkkkk">
<meta property="og:description" content="题目基本情况数据集121.数据集:https:&#x2F;&#x2F;tianchi.aliyun.com&#x2F;dataset&#x2F;dataDetail?dataId&#x3D;130516  数据探索理论知识 赛题数据探索导入工具包123456789101112import numpy as npimport pandas as pdimport matplotlib.pyplot">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/1.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/2.1.1.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/2.1.2.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/2.2.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/2.3.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/2.4.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/2.5.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/2.6.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/2.7.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/2.8.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.1.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.5.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.1.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.4.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.3.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.2.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.6.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.8.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.9.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.10.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.11.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.12.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.13.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.14.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.15.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.16.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.17.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.18.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.19.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.20.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.21.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.22.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.23.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.24.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.25.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.26.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.27.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.28.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.29.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.30.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.31.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.32.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.33.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.34.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.35.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.36.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.37.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.38.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.39.png">
<meta property="og:image" content="https://larkkkkkkk.github.io/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.40.png">
<meta property="article:published_time" content="2022-09-27T12:44:48.000Z">
<meta property="article:modified_time" content="2022-10-25T03:28:46.000Z">
<meta property="article:author" content="Larkkkkkkk">
<meta property="article:tag" content="机器学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://larkkkkkkk.github.io/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/1.png">
  
    <link rel="alternative" href="/atom.xml" title="Larkkkkkkk" type="application/atom+xml">
  
  
    <link rel="icon" href="/http://oayoilchh.bkt.clouddn.com/2016/07/27/18:05:26%20">
  
  
      
<link rel="stylesheet" href="//cdn.bootcss.com/animate.css/3.5.0/animate.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  <link rel="stylesheet" href="/font-awesome/css/font-awesome.min.css">
  <link rel="apple-touch-icon" href="/apple-touch-icon.png">
  
  
      <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  
  <!-- 加载特效 -->
    <script src="/js/pace.js"></script>
    <link href="/css/pace/pace-theme-flash.css" rel="stylesheet" />
  <script>
      var yiliaConfig = {
          rootUrl: '/',
          fancybox: true,
          animate: true,
          isHome: false,
          isPost: true,
          isArchive: false,
          isTag: false,
          isCategory: false,
          open_in_new: false
      }
  </script>
<meta name="generator" content="Hexo 4.2.1"></head>
<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
    <header id="header" class="inner">
        <script src="http://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js"></script>
        <a href="/" class="profilepic">
            
            <img lazy-src="img/head.jpg" class="js-avatar">
            
        </a>
        <hgroup>
          <h1 class="header-author"><a href="/">Larkkkkkkk</a></h1>
        </hgroup>
        
        
            <form>
                <input type="text" class="st-default-search-input search" id="local-search-input" placeholder="搜索一下" autocomplete="off">
            </form>
            <div id="local-search-result"></div>
        
        
            <script type="text/javascript">
                (function() {
                    'use strict';
                    function getMatchData(keyword, data) {
                        var matchData = [];
                        for(var i =0;i<data.length;i++){
                            if(data[i].title.toLowerCase().indexOf(keyword)>=0) 
                                matchData.push(data[i])
                        }
                        return matchData;
                    }
                    var $input = $('#local-search-input');
                    var $resultContent = $('#local-search-result');
                    $input.keyup(function(){
                        $.ajax({
                            url: '/search.json',
                            dataType: "json",
                            success: function( json ) {
                                var str='<ul class=\"search-result-list\">';                
                                var keyword = $input.val().trim().toLowerCase();
                                $resultContent.innerHTML = "";
                                if ($input.val().trim().length <= 0) {
                                    $resultContent.empty();
                                    $('#switch-area').show();
                                    return;
                                }
                                var results = getMatchData(keyword, json);
                                if(results.length === 0){
                                    $resultContent.empty();
                                    $('#switch-area').show();
                                    return;
                                } 
                                for(var i =0; i<results.length; i++){
                                    str += "<li><a href='"+ results[i].url +"' class='search-result-title'>"+ results[i].title +"</a></li>";
                                }
                                str += "</ul>";
                                $resultContent.empty();
                                $resultContent.append(str);
                                $('#switch-area').hide();
                            }
                        });
                    });
                })();
            </script>
        
        
            <div id="switch-btn" class="switch-btn">
                <div class="icon">
                    <div class="icon-ctn">
                        <div class="icon-wrap icon-house" data-idx="0">
                            <div class="birdhouse"></div>
                            <div class="birdhouse_holes"></div>
                        </div>
                        <div class="icon-wrap icon-ribbon hide" data-idx="1">
                            <div class="ribbon"></div>
                        </div>
                        
                        <div class="icon-wrap icon-link hide" data-idx="2">
                            <div class="loopback_l"></div>
                            <div class="loopback_r"></div>
                        </div>
                        
                        
                        <div class="icon-wrap icon-me hide" data-idx="3">
                            <div class="user"></div>
                            <div class="shoulder"></div>
                        </div>
                        
                    </div>
                </div>
                <div class="tips-box hide">
                    <div class="tips-arrow"></div>
                    <ul class="tips-inner">
                        <li>菜单</li>
                        <li>标签</li>
                        
                        <li>友情链接</li>
                        
                        
                        <li>关于我</li>
                        
                    </ul>
                </div>
            </div>
        
        <div id="switch-area" class="switch-area">
            <div class="switch-wrap">
                <section class="switch-part switch-part1">
                    <nav class="header-menu">
                        <ul>
                        
                            <li><a  href="https://github.com/Larkkkkkkk" target="_blank" rel="noopener">博客首页</a></li>
                        
                            <li><a  href="/archives">文章归档</a></li>
                        
                            <li><a  href="/CTFStudy">学习导航</a></li>
                        
                            <li><a  href="/PWNABLE">PWNABLE</a></li>
                        
                            <li><a  href="/resume">个人简历</a></li>
                        
                        </ul>
                    </nav>
                    <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fl mail"  target="_blank" href="http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&email=U2JgZ2ZlY2VmamATIiJ9MDw_" title="mail">mail</a>
                            
                                <a class="fl github"  target="_blank" href="https://github.com/Larkkkkkkk" title="github">github</a>
                            
                                <a class="fl zhihu"  target="_blank" href="https://www.zhihu.com/people/plain-3-78/activities" title="zhihu">zhihu</a>
                            
                                <a class="fl weibo"  target="_blank" href="https://weibo.com/5304208276/profile?topnav=1&wvr=6" title="weibo">weibo</a>
                            
                                <a class="fl rss"  target="_blank" href="/atom.xml" title="rss">rss</a>
                            
                        </ul>
                    </nav>
                </section>
                
                <section class="switch-part switch-part2">
                    <div class="widget tagcloud" id="js-tagcloud">
                        <a href="/tags/Ajax/" style="font-size: 12px;">Ajax</a> <a href="/tags/Cookie%E5%92%8CSession/" style="font-size: 14px;">Cookie和Session</a> <a href="/tags/DBUtils/" style="font-size: 11px;">DBUtils</a> <a href="/tags/Docker/" style="font-size: 10px;">Docker</a> <a href="/tags/EL%E8%A1%A8%E8%BE%BE%E5%BC%8F/" style="font-size: 10px;">EL表达式</a> <a href="/tags/Elasticsearch/" style="font-size: 10px;">Elasticsearch</a> <a href="/tags/Filter/" style="font-size: 11px;">Filter</a> <a href="/tags/HTTP/" style="font-size: 10px;">HTTP</a> <a href="/tags/HTTPServletReauest%E5%92%8CHTTPServletResponse/" style="font-size: 10px;">HTTPServletReauest和HTTPServletResponse</a> <a href="/tags/Hexo%E5%8D%9A%E5%AE%A2/" style="font-size: 10px;">Hexo博客</a> <a href="/tags/IDEA%E5%AE%89%E8%A3%85%E5%92%8C%E7%A0%B4%E8%A7%A3/" style="font-size: 10px;">IDEA安装和破解</a> <a href="/tags/JAVA/" style="font-size: 19px;">JAVA</a> <a href="/tags/JAVA-Lambda%E8%A1%A8%E8%BE%BE%E5%BC%8F/" style="font-size: 10px;">JAVA-Lambda表达式</a> <a href="/tags/JAVA-Set%E9%9B%86%E5%90%88/" style="font-size: 10px;">JAVA-Set集合</a> <a href="/tags/JAVA-%E5%8F%8D%E5%B0%84/" style="font-size: 10px;">JAVA-反射</a> <a href="/tags/JAVA-%E5%A4%9A%E7%BA%BF%E7%A8%8B/" style="font-size: 12px;">JAVA-多线程</a> <a href="/tags/JAVA-%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/" style="font-size: 10px;">JAVA-正则表达式</a> <a href="/tags/JAVA-%E6%B3%9B%E5%9E%8B/" style="font-size: 10px;">JAVA-泛型</a> <a href="/tags/JAVA-%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/" style="font-size: 12px;">JAVA-网络编程</a> <a href="/tags/JAVA-%E9%9B%86%E5%90%88/" style="font-size: 12px;">JAVA-集合</a> <a href="/tags/JAVA%E7%BB%83%E4%B9%A0/" style="font-size: 11px;">JAVA练习</a> <a href="/tags/JAVA%E7%BB%83%E4%B9%A0-%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/" style="font-size: 10px;">JAVA练习-动态规划</a> <a href="/tags/JQuery/" style="font-size: 13px;">JQuery</a> <a href="/tags/JSP/" style="font-size: 10px;">JSP</a> <a href="/tags/JVM/" style="font-size: 10px;">JVM</a> <a href="/tags/LeetCode/" style="font-size: 17px;">LeetCode</a> <a href="/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/tags/Listener/" style="font-size: 10px;">Listener</a> <a href="/tags/Mybatis/" style="font-size: 18px;">Mybatis</a> <a href="/tags/MybatisPlus/" style="font-size: 10px;">MybatisPlus</a> <a href="/tags/Mysql/" style="font-size: 10px;">Mysql</a> <a href="/tags/Mysql%E6%95%B0%E6%8D%AE%E5%BA%93%E5%92%8CJDBC/" style="font-size: 15px;">Mysql数据库和JDBC</a> <a href="/tags/RabbitMQ/" style="font-size: 10px;">RabbitMQ</a> <a href="/tags/Redis/" style="font-size: 10px;">Redis</a> <a href="/tags/Servlet/" style="font-size: 11px;">Servlet</a> <a href="/tags/Spring/" style="font-size: 16px;">Spring</a> <a href="/tags/SpringMVC/" style="font-size: 15px;">SpringMVC</a> <a href="/tags/Tomcat/" style="font-size: 10px;">Tomcat</a> <a href="/tags/Web%E5%89%8D%E7%AB%AF%E7%9F%A5%E8%AF%86%E7%82%B9/" style="font-size: 20px;">Web前端知识点</a> <a href="/tags/XML/" style="font-size: 11px;">XML</a> <a href="/tags/Zookeeper/" style="font-size: 10px;">Zookeeper</a> <a href="/tags/django/" style="font-size: 10px;">django</a> <a href="/tags/flask%E6%A1%86%E6%9E%B6/" style="font-size: 10px;">flask框架</a> <a href="/tags/git/" style="font-size: 10px;">git</a> <a href="/tags/jsp%E6%A0%87%E5%87%86%E6%A0%87%E7%AD%BE%E5%BA%93/" style="font-size: 10px;">jsp标准标签库</a> <a href="/tags/maven/" style="font-size: 10px;">maven</a> <a href="/tags/picture/" style="font-size: 10px;">picture</a> <a href="/tags/python/" style="font-size: 12px;">python</a> <a href="/tags/pytorch/" style="font-size: 10px;">pytorch</a> <a href="/tags/ssm%E6%A1%86%E6%9E%B6%E6%A8%A1%E6%9D%BF/" style="font-size: 10px;">ssm框架模板</a> <a href="/tags/webserver%E7%BC%96%E7%A8%8B/" style="font-size: 10px;">webserver编程</a> <a href="/tags/%E4%BA%8B%E5%8A%A1/" style="font-size: 10px;">事务</a> <a href="/tags/%E4%BA%AC%E4%B8%9C/" style="font-size: 11px;">京东</a> <a href="/tags/%E5%89%8D%E7%AB%AF/" style="font-size: 10px;">前端</a> <a href="/tags/%E5%90%8E%E7%BC%80%E6%A0%91/" style="font-size: 10px;">后缀树</a> <a href="/tags/%E5%93%88%E5%B8%8C%E8%A1%A8/" style="font-size: 10px;">哈希表</a> <a href="/tags/%E5%9B%BE/" style="font-size: 10px;">图</a> <a href="/tags/%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%88%86%E6%9E%90/" style="font-size: 10px;">复杂度分析</a> <a href="/tags/%E5%AD%A6%E7%94%9F%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/" style="font-size: 10px;">学生管理系统</a> <a href="/tags/%E5%AD%A6%E7%94%9F%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F2-0/" style="font-size: 12px;">学生管理系统2.0</a> <a href="/tags/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F/" style="font-size: 10px;">微信小程序</a> <a href="/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/" style="font-size: 13px;">微服务</a> <a href="/tags/%E6%8B%BC%E5%A4%9A%E5%A4%9A/" style="font-size: 10px;">拼多多</a> <a href="/tags/%E6%8E%92%E5%BA%8F/" style="font-size: 10px;">排序</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/" style="font-size: 10px;">数据分析</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0/" style="font-size: 10px;">数据库连接池</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%A8%80%E7%96%8F%E6%95%B0%E7%BB%84/" style="font-size: 10px;">数据结构-稀疏数组</a> <a href="/tags/%E6%96%87%E5%AD%97%E7%AF%87-%E8%AE%B0%E5%BD%95/" style="font-size: 10px;">文字篇-记录</a> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="font-size: 12px;">机器学习</a> <a href="/tags/%E6%A0%88/" style="font-size: 10px;">栈</a> <a href="/tags/%E6%A0%91/" style="font-size: 12px;">树</a> <a href="/tags/%E6%B3%A8%E8%A7%A3/" style="font-size: 10px;">注解</a> <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" style="font-size: 14px;">深度学习</a> <a href="/tags/%E7%88%AC%E8%99%AB/" style="font-size: 11px;">爬虫</a> <a href="/tags/%E7%94%9F%E7%89%A9%E4%BF%A1%E6%81%AF%E5%AD%A6/" style="font-size: 10px;">生物信息学</a> <a href="/tags/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/" style="font-size: 12px;">知识图谱</a> <a href="/tags/%E7%A0%94%E7%A9%B6%E7%94%9F%E5%88%9D%E8%AF%95/" style="font-size: 12px;">研究生初试</a> <a href="/tags/%E7%A7%8B%E6%8B%9B/" style="font-size: 10px;">秋招</a> <a href="/tags/%E7%AE%97%E6%B3%95-%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/" style="font-size: 10px;">算法-动态规划</a> <a href="/tags/%E7%AE%97%E6%B3%95-%E5%9B%9E%E6%BA%AF%E6%B3%95/" style="font-size: 10px;">算法-回溯法</a> <a href="/tags/%E7%AE%97%E6%B3%95-%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95/" style="font-size: 10px;">算法-贪心算法</a> <a href="/tags/%E8%80%83%E7%A0%94/" style="font-size: 10px;">考研</a> <a href="/tags/%E8%93%9D%E6%A1%A5%E6%9D%AF/" style="font-size: 13px;">蓝桥杯</a> <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/" style="font-size: 11px;">计算机网络</a> <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E8%AF%BE%E8%AE%BE-%E8%BD%AF%E4%BB%B6%E4%B8%93%E4%B8%9A%E9%A2%98%E7%9B%AE/" style="font-size: 10px;">计算机网络课设(软件专业题目)</a> <a href="/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/" style="font-size: 12px;">设计模式</a> <a href="/tags/%E8%BD%AF%E4%BB%B6%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/" style="font-size: 10px;">软件体系结构</a> <a href="/tags/%E9%80%92%E5%BD%92/" style="font-size: 10px;">递归</a> <a href="/tags/%E9%87%8D%E6%96%B0%E9%83%A8%E7%BD%B2/" style="font-size: 10px;">重新部署</a> <a href="/tags/%E9%93%BE%E8%A1%A8/" style="font-size: 10px;">链表</a> <a href="/tags/%E9%98%9F%E5%88%97/" style="font-size: 10px;">队列</a> <a href="/tags/%E9%9D%A2%E8%AF%95/" style="font-size: 10px;">面试</a> <a href="/tags/%E9%A1%B5%E9%9D%A2%EF%BC%88H5-CSS%EF%BC%89/" style="font-size: 10px;">页面（H5+CSS）</a> <a href="/tags/%E9%A1%B9%E7%9B%AE%E4%B8%8A%E4%BC%A0/" style="font-size: 10px;">项目上传</a>
                    </div>
                </section>
                
                
                <section class="switch-part switch-part3">
                    <div id="js-friends">
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://ring3.xyz/">Yllen</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://mxny.org/">麦香浓郁</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://whereisk0shl.top/">K0sh1</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://www.ycjcl.cc/">信鑫</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://bystudent.com/">ByStundet表哥</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="https://www.jarviswang.me/">汪神_Jarvis</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://sh3ll.me/">Chu</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="https://www.hackfun.org/">4ido10n</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://www.cnblogs.com/iamstudy">L3m0n</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://o0xmuhe.me/">muhe</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://blog.nuptzj.cn/">_画船听雨</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://www.virzz.com/index.html">Virink</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://www.sqlsec.com/">国光</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://www.bodkin.ren/">老锥</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://www.cizel.cn/">C1zel</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://1phan.cc">1phan</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="https://www.liuil.top/">liuil</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://www.cnblogs.com/Ox9A82/">Ox9A82</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://burnegg.com/">burnegg</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="https://jwrsec.cn/">jwr-sec</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://sudalover.cn/">苏打</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://blog.binklac.com">VeroFess</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://www.bendawang.site/">bendawang</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://weeklyalgo.codes/">hook</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://www.flier.net.cn/">Flier&#39;blog</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://www.mutepig.club">mutepig</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="https://blog.iret.xyz/list.aspx">Silver</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://simp1e.leanote.com/">Simple</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://processor.pub/">Processor</a>
                    
                    </div>
                </section>
                
                
                
                <section class="switch-part switch-part4">
                
                    <div id="js-aboutme">一只淹死在二进制海洋里的二进制狗!</div>
                </section>
                
            </div>
        </div>
    </header>
</div>

    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
      <div class="overlay">
          <div class="slider-trigger"></div>
          <h1 class="header-author js-mobile-header hide"><a href="/" title="Me">Larkkkkkkk</a></h1>
      </div>
    <div class="intrude-less">
        <header id="header" class="inner">
            <a href="/" class="profilepic">
                
                    <img lazy-src="/img/head.jpg" class="js-avatar">
                
            </a>
            <hgroup>
              <h1 class="header-author"><a href="/" title="Me">Larkkkkkkk</a></h1>
            </hgroup>
            
            <nav class="header-menu">
                <ul>
                
                    <li><a href="https://github.com/Larkkkkkkk" target="_blank" rel="noopener">博客首页</a></li>
                
                    <li><a href="/archives">文章归档</a></li>
                
                    <li><a href="/CTFStudy">学习导航</a></li>
                
                    <li><a href="/PWNABLE">PWNABLE</a></li>
                
                    <li><a href="/resume">个人简历</a></li>
                
                <div class="clearfix"></div>
                </ul>
            </nav>
            <nav class="header-nav">
                <div class="social">
                    
                        <a class="mail" target="_blank" href="http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&email=U2JgZ2ZlY2VmamATIiJ9MDw_" title="mail">mail</a>
                    
                        <a class="github" target="_blank" href="https://github.com/Larkkkkkkk" title="github">github</a>
                    
                        <a class="zhihu" target="_blank" href="https://www.zhihu.com/people/plain-3-78/activities" title="zhihu">zhihu</a>
                    
                        <a class="weibo" target="_blank" href="https://weibo.com/5304208276/profile?topnav=1&wvr=6" title="weibo">weibo</a>
                    
                        <a class="rss" target="_blank" href="/atom.xml" title="rss">rss</a>
                    
                </div>
            </nav>
        </header>                
    </div>
</nav>
      <div class="body-wrap"><article id="post-机器学习实战之工业蒸汽" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/" class="article-date">
      <time datetime="2022-09-27T12:44:48.000Z" itemprop="datePublished">2022-09-27</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      机器学习实战之工业蒸汽
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        

        
    <div class="article-tag tagcloud">
        <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a></li></ul>
    </div>

        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h1 id="题目基本情况"><a href="#题目基本情况" class="headerlink" title="题目基本情况"></a>题目基本情况</h1><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1.数据集:</span><br><span class="line">https:&#x2F;&#x2F;tianchi.aliyun.com&#x2F;dataset&#x2F;dataDetail?dataId&#x3D;130516</span><br></pre></td></tr></table></figure>

<h1 id="数据探索"><a href="#数据探索" class="headerlink" title="数据探索"></a>数据探索</h1><h2 id="理论知识"><a href="#理论知识" class="headerlink" title="理论知识"></a>理论知识</h2><p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/1.png" alt></p>
<h2 id="赛题数据探索"><a href="#赛题数据探索" class="headerlink" title="赛题数据探索"></a>赛题数据探索</h2><h3 id="导入工具包"><a href="#导入工具包" class="headerlink" title="导入工具包"></a>导入工具包</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import seaborn as sns</span><br><span class="line">import warnings</span><br><span class="line">from scipy import stats</span><br><span class="line">#1.读取数据</span><br><span class="line">train_data_file &#x3D; &quot;zhengqi_train.txt&quot;</span><br><span class="line">test_data_file &#x3D;  &quot;zhengqi_test.txt&quot;</span><br><span class="line">train_data &#x3D; pd.read_csv(train_data_file, sep&#x3D;&#39;\t&#39;, encoding&#x3D;&#39;utf-8&#39;) #训练集数据共有2888个样本(V0-V37共38个特征变量)  -- 有target字段</span><br><span class="line">test_data &#x3D; pd.read_csv(test_data_file, sep&#x3D;&#39;\t&#39;, encoding&#x3D;&#39;utf-8&#39;) #测试集数据共有1925个样本(V0-V37共有38个特征变量)  -- 无target字段</span><br></pre></td></tr></table></figure>

<h3 id="可视化数据分布"><a href="#可视化数据分布" class="headerlink" title="可视化数据分布"></a>可视化数据分布</h3><h4 id="箱型图-boxplot"><a href="#箱型图-boxplot" class="headerlink" title="箱型图(boxplot)"></a>箱型图(boxplot)</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">##2.1 箱型图boxplot(所有特征变量)</span><br><span class="line">columns&#x3D;train_data.columns.tolist()[:39]  #前39列</span><br><span class="line">fig&#x3D;plt.figure(figsize&#x3D;(20,40)) #指定绘图对象宽度和高度</span><br><span class="line">for i in range(38):</span><br><span class="line">    plt.subplot(8,5,i+1) #指定8行5列子图</span><br><span class="line">    sns.boxplot(train_data[columns[i]],orient&#x3D;&quot;h&quot;,width&#x3D;0.5)  #orient是v(垂直)&#x2F;h(水平)</span><br></pre></td></tr></table></figure>

<p><strong>整体的箱型图:</strong></p>
<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/2.1.1.png" alt></p>
<p><strong>V0一个的箱型图:</strong></p>
<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/2.1.2.png" alt></p>
<h4 id="直方图-distplot-和Q-Q图-probplot"><a href="#直方图-distplot-和Q-Q图-probplot" class="headerlink" title="直方图(distplot)和Q-Q图(probplot)"></a>直方图(distplot)和Q-Q图(probplot)</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">##2.3 直方图distplot和Q-Q图probplot(数据的分位数和正态分布的分位数对比参照) -- 如果数据符合正态分布 会在qq图内两条线重合</span><br><span class="line">train_cols&#x3D;6 #列</span><br><span class="line">train_rows&#x3D;len(train_data.columns)  #行</span><br><span class="line">plt.figure(figsize&#x3D;(train_cols,train_rows)) #指定绘图对象宽度和高度</span><br><span class="line">i&#x3D;0</span><br><span class="line">for col in train_data.columns:</span><br><span class="line">    i+&#x3D;1</span><br><span class="line">    ax&#x3D;plt.subplot(train_rows,train_cols,i) #指定r行c列子图第i个位置</span><br><span class="line">    sns.distplot(train_data[col],fit&#x3D;stats.norm)  #fit设置函数图像(与原图进行比较)</span><br><span class="line">    i+&#x3D;1</span><br><span class="line">    ax&#x3D;plt.subplot(train_rows,train_cols,i)  # 指定r行c列子图第i+1个位置</span><br><span class="line">    res&#x3D;stats.probplot(train_data[col],plot&#x3D;plt)  # fit设置函数图像(与原图进行比较)</span><br></pre></td></tr></table></figure>

<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/2.2.png" alt></p>
<h4 id="KDE分布图-核密度估计kdeplot"><a href="#KDE分布图-核密度估计kdeplot" class="headerlink" title="KDE分布图(核密度估计kdeplot)"></a>KDE分布图(核密度估计kdeplot)</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">##2.4 KDE分布图kdeplot(核密度估计) --对直方图的加窗平滑(可以查看对比训练集和测试集中特征变量的分布情况)</span><br><span class="line">dist_cols&#x3D;6 #列</span><br><span class="line">dist_rows&#x3D;len(test_data.columns)  #行</span><br><span class="line">plt.figure(figsize&#x3D;(train_cols,train_rows)) #指定绘图对象宽度和高度</span><br><span class="line">i&#x3D;1</span><br><span class="line">for col in test_data.columns:</span><br><span class="line">    ax&#x3D;plt.subplot(dist_rows,dist_cols,i) #指定r行c列子图第i个位置</span><br><span class="line">    ax&#x3D;sns.kdeplot(train_data[col],color&#x3D;&quot;Red&quot;,shade&#x3D;True)</span><br><span class="line">    ax&#x3D;sns.kdeplot(test_data[col], color&#x3D;&quot;Blue&quot;, shade&#x3D;True)</span><br><span class="line">    ax.set_xlabel(col)  #横坐标名称</span><br><span class="line">    ax.set_ylabel(&quot;Frequency&quot;)  #纵坐标名称</span><br><span class="line">    ax&#x3D;ax.legend([&quot;训练集&quot;,&quot;测试集&quot;])  #两条曲线的名称</span><br><span class="line">    i&#x3D;i+1</span><br></pre></td></tr></table></figure>

<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/2.3.png" alt></p>
<h4 id="线性回归关系图-regplot"><a href="#线性回归关系图-regplot" class="headerlink" title="线性回归关系图(regplot)"></a>线性回归关系图(regplot)</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">##2.5 线性回归关系图regplot(分析变量之间的线性回归关系)</span><br><span class="line">fcols&#x3D;6 #列</span><br><span class="line">frows&#x3D;len(test_data.columns)  #行</span><br><span class="line">plt.figure(figsize&#x3D;(fcols,frows)) #指定绘图对象宽度和高度</span><br><span class="line">i&#x3D;0</span><br><span class="line">for col in test_data.columns:</span><br><span class="line">    i&#x3D;i+1</span><br><span class="line">    ax&#x3D;plt.subplot(frows,fcols,i) #指定r行c列子图第i个位置</span><br><span class="line">    sns.regplot(x&#x3D;col,y&#x3D;&#39;target&#39;,data&#x3D;train_data,ax&#x3D;ax,scatter_kws&#x3D;&#123;&#39;marker&#39;:&#39;.&#39;,&#39;s&#39;:3,&#39;alpha&#39;:0.3&#125;,line_kws&#x3D;&#123;&#39;color&#39;:&#39;k&#39;&#125;)</span><br><span class="line">    plt.xlabel(col)</span><br><span class="line">    plt.ylabel(&#39;target&#39;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/2.4.png" alt></p>
<h3 id="查看特征变量的相关性"><a href="#查看特征变量的相关性" class="headerlink" title="查看特征变量的相关性"></a>查看特征变量的相关性</h3><h4 id="计算相关性系数-data-corr"><a href="#计算相关性系数-data-corr" class="headerlink" title="计算相关性系数(data.corr)"></a>计算相关性系数(data.corr)</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#3.查看特征变量的相关性</span><br><span class="line">##3.1 计算相关性系数corr --&gt; KDE图中拿训练集和测试集中分布不一致的特征变量进行删除(V5,V9,V11,V17,V22,V28) --&gt; 计算剩余特征变量和target变量的相关性系数</span><br><span class="line">pd.set_option(&#39;display.max_columns&#39;,10)  #显示10列 默认none就是最多</span><br><span class="line">pd.set_option(&#39;display.max_rows&#39;,10) #显示10行</span><br><span class="line">data_train1&#x3D;train_data.drop([&#39;V5&#39;,&#39;V9&#39;,&#39;V11&#39;,&#39;V17&#39;,&#39;V22&#39;,&#39;V28&#39;],axis&#x3D;1)  #删除那些测试集和训练集分布不一致的特征向量</span><br><span class="line">train_corr&#x3D;data_train1.corr() #corr给出任意两个变量之间的相关系数</span><br><span class="line">print(train_corr)</span><br></pre></td></tr></table></figure>

<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/2.5.png" alt></p>
<h4 id="相关热力图-sns-heatmap"><a href="#相关热力图-sns-heatmap" class="headerlink" title="相关热力图(sns.heatmap)"></a>相关热力图(sns.heatmap)</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">##3.2 热力图heatmap</span><br><span class="line">ax&#x3D;plt.subplots(figsize&#x3D;(20,16)) #调整画布大小</span><br><span class="line">ax&#x3D;sns.heatmap(train_corr,vmax&#x3D;.8,square&#x3D;True,annot&#x3D;True)  #vmax和vmin是图例中最大值和最小值的显示值 square为热力图矩阵小块形状(T以列名为标签名)  annot为T表示每个方格写入数据</span><br></pre></td></tr></table></figure>

<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/2.6.png" alt></p>
<h4 id="根据相关系数筛选特征变量-相关性选择-树模型"><a href="#根据相关系数筛选特征变量-相关性选择-树模型" class="headerlink" title="根据相关系数筛选特征变量(相关性选择/树模型)"></a>根据相关系数筛选特征变量(相关性选择/树模型)</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">###3.3.1 寻找k个与target变量最相关的特征变量(K&#x3D;10)</span><br><span class="line">columns&#x3D;train_corr.nlargest(10,&#39;target&#39;)  #利用相关系数.nlargest()获取</span><br><span class="line">columnsindex&#x3D;columns[&#39;target&#39;].index   # 获取符合的下标&#39;V0&#39;&#x2F;&#39;V1&#39;&#x2F;&#39;V8&#39;&#x2F;&#39;V27&#39;&#x2F;&#39;V31&#39;&#x2F;&#39;V2&#39;&#x2F;&#39;V4&#39;&#x2F;&#39;V12&#39;&#x2F;&#39;V16&#39;</span><br><span class="line">columnsvalue&#x3D;train_data[columnsindex].values  #找到k个特征变量在训练集中的值</span><br><span class="line">cm&#x3D;np.corrcoef(columnsvalue) #皮尔逊积矩相关系数--计算两个变量x和y之间的线性相关(-1到1)</span><br><span class="line">ax&#x3D;plt.subplots(figsize&#x3D;(10,10)) #调整画布大小</span><br><span class="line">ax&#x3D;sns.heatmap(train_data[columnsindex].corr(),annot&#x3D;True,square&#x3D;True) #k个相关值画热力图</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/2.7.png" alt></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">###3.3.2 找出与target变量的相关系数大于0.5的特征变量</span><br><span class="line">corrs&#x3D;train_data.corr() #获取训练数据集的相关系数</span><br><span class="line">corrres&#x3D;corrs.index[abs(corrs[&#39;target&#39;])&gt;0.5] # 获取符合的下标 V0&#39;&#x2F;&#39;V1&#39;&#x2F;&#39;V2&#39;&#x2F;&#39;V3&#39;&#x2F;&#39;V4&#39;&#x2F;&#39;V8&#39;&#x2F;&#39;V12&#39;&#x2F;&#39;V16&#39;&#x2F;&#39;V27&#39;&#x2F;&#39;V31&#39;&#x2F;&#39;V37&#39;</span><br><span class="line">ax&#x3D;plt.figure(figsize&#x3D;(10,10))</span><br><span class="line">ax&#x3D;sns.heatmap(train_data[corrres].corr(),annot&#x3D;True,cmap&#x3D;&quot;RdYlGn&quot;) #cmap设置颜色</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/2.8.png" alt></p>
<h4 id="Box-Cox变换"><a href="#Box-Cox变换" class="headerlink" title="Box-Cox变换"></a>Box-Cox变换</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">###3.3.3 Box-Cox变换(线性回归基于正态分布 --&gt; 统计分析将数据转换为符合正态分布)</span><br><span class="line">####1. 合并数据</span><br><span class="line">drop_columns &#x3D; [&#39;V5&#39;,&#39;V9&#39;,&#39;V11&#39;,&#39;V17&#39;,&#39;V22&#39;,&#39;V28&#39;] #KDE图发现训练集和测试集中这几个特征变量不一致 需要删除</span><br><span class="line">train_droptarget&#x3D;train_data.drop([&#39;target&#39;],axis&#x3D;1)  #按照axis&#x3D;1列删除了target的行和列(因为train里面比test多了target列)</span><br><span class="line">data_all&#x3D;pd.concat([train_droptarget,test_data])  #默认纵向拼接train和test两个训练集(列不变 行数会变多)</span><br><span class="line">data_all.drop(drop_columns,axis&#x3D;1,inplace&#x3D;True)  #按照axis&#x3D;1列删除那些列</span><br><span class="line">####2. 归一化(1.MinMaxScaler函数&#x2F;2.min-max离差标准化)</span><br><span class="line">colunms_list&#x3D;list(data_all.columns)  #对合并后的每列数据合成一个list列表</span><br><span class="line">def scale_minmax(col):  #定义一个标准化的函数用于apply方法的第一个参数</span><br><span class="line">    return (col-col.min())&#x2F;(col.max()-col.min())</span><br><span class="line">data_all[colunms_list]&#x3D;data_all[colunms_list].apply(scale_minmax,axis&#x3D;0) # axis&#x3D;0对每一列数据应用函数</span><br><span class="line"></span><br><span class="line">####3. Box-Cox变换</span><br><span class="line">data_all, lambda0 &#x3D; boxcox1p(data_all)</span><br><span class="line"></span><br><span class="line">####4. 重新画Q-Q图</span><br><span class="line">data_all_cols&#x3D;6 #列</span><br><span class="line">data_all_rows&#x3D;len(data_all.columns)  #行</span><br><span class="line">plt.figure(figsize&#x3D;(data_all_cols,data_all_rows)) #指定绘图对象宽度和高度</span><br><span class="line">i&#x3D;0</span><br><span class="line">for col in data_all.columns:</span><br><span class="line">    i+&#x3D;1</span><br><span class="line">    ax&#x3D;plt.subplot(data_all_rows,data_all_cols,i) #指定r行c列子图第i个位置</span><br><span class="line">    sns.distplot(data_all[col],fit&#x3D;stats.norm)  #fit设置函数图像(与原图进行比较)</span><br><span class="line">    i+&#x3D;1</span><br><span class="line">    ax&#x3D;plt.subplot(data_all_rows,data_all_cols,i)  # 指定r行c列子图第i+1个位置</span><br><span class="line">    res&#x3D;stats.probplot(data_all[col],plot&#x3D;plt)  # fit设置函数图像(与原图进行比较)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h1 id="特征工程"><a href="#特征工程" class="headerlink" title="特征工程"></a>特征工程</h1><h2 id="特征工程的重要性和处理"><a href="#特征工程的重要性和处理" class="headerlink" title="特征工程的重要性和处理"></a>特征工程的重要性和处理</h2><p><strong>特征工程的重要性:</strong></p>
<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.1.png" alt></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"> 1.特征工程处理流程:</span><br><span class="line">1.1 去掉无用特征</span><br><span class="line">1.2 去掉冗余特征(如共线特征)</span><br><span class="line">   1.3 生成新特征(利用存在的特征、转换特征、内容中的特征、其他数据源)</span><br><span class="line">1.4 特征转换(数值化、类别转换、归一化等)</span><br><span class="line">1.5 特征处理(异常值、最大值、最小值、缺失值)</span><br></pre></td></tr></table></figure>

<h2 id="数据预处理和特征处理"><a href="#数据预处理和特征处理" class="headerlink" title="数据预处理和特征处理"></a>数据预处理和特征处理</h2><h3 id="数据预处理-数据采集-数据清洗-数据采样"><a href="#数据预处理-数据采集-数据清洗-数据采样" class="headerlink" title="数据预处理(数据采集+数据清洗+数据采样)"></a>数据预处理(数据采集+数据清洗+数据采样)</h3><h4 id="数据采集"><a href="#数据采集" class="headerlink" title="数据采集"></a>数据采集</h4><h4 id="数据清洗"><a href="#数据清洗" class="headerlink" title="数据清洗"></a>数据清洗</h4><h4 id="数据采样"><a href="#数据采样" class="headerlink" title="数据采样"></a>数据采样</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1.数据采样的原因:经过采集和清洗之后正负样本是不均衡的 --&gt; 数据采样</span><br><span class="line">2.数据采样的方法:</span><br><span class="line">  2.1 随机采样: 可能随机采样得到的数据很不均匀</span><br><span class="line">  2.2 分层采样: </span><br><span class="line">3.正负样本不均衡的处理办法:</span><br><span class="line">  3.1 正样本&gt;负样本 + 量特别大 : 下采样(downsampling)的方法</span><br><span class="line">  3.2 正样本&gt;负样本 + 量不大 : 上采样(oversampling)的方法(图像识别的镜像和旋转&#x2F;修改损失函数设置样本权重)</span><br></pre></td></tr></table></figure>

<h3 id="特征处理"><a href="#特征处理" class="headerlink" title="特征处理"></a>特征处理</h3><p><strong>特征处理小结:</strong></p>
<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.5.png" alt></p>
<h4 id="标准化-StandardScaler类"><a href="#标准化-StandardScaler类" class="headerlink" title="标准化(StandardScaler类)"></a>标准化(StandardScaler类)</h4><p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.1.png" alt></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1.标准化: 依照特征矩阵的列去处理数据[通过求标准分数的方法将特征--&gt;标准正态分布]</span><br><span class="line">2.使用场景:</span><br><span class="line">	2.1 数据存在异常值和较多噪声</span><br></pre></td></tr></table></figure>

<h4 id="区间缩放法-MinMaxScaler类"><a href="#区间缩放法-MinMaxScaler类" class="headerlink" title="区间缩放法(MinMaxScaler类)"></a>区间缩放法(MinMaxScaler类)</h4><p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.4.png" alt></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1.区间缩放法: 利用两个最值(最大值和最小值)进行缩放 [归一化的一种]</span><br></pre></td></tr></table></figure>

<h4 id="归一化-Normalizer类"><a href="#归一化-Normalizer类" class="headerlink" title="归一化(Normalizer类)"></a>归一化(Normalizer类)</h4><p><strong>公式:</strong></p>
<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.3.png" alt></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1.归一化: 样本的特征值--&gt;同一量纲，数据--&gt;[0,1]&#x2F;[a,b]区间内</span><br><span class="line">2.使用场景:</span><br><span class="line">	2.1 输出结果范围有要求</span><br><span class="line">    2.2 数据较为稳定，不存在极端的最大值&#x2F;最小值</span><br></pre></td></tr></table></figure>

<h4 id="定量特征二值化-Binarizer类"><a href="#定量特征二值化-Binarizer类" class="headerlink" title="定量特征二值化(Binarizer类)"></a>定量特征二值化(Binarizer类)</h4><p><strong>公式:</strong></p>
<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.2.png" alt></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1. 定量特征二值化: 核心在于设定一个阈值(&gt;阈值的赋值为1,≤阈值的赋值为0)</span><br></pre></td></tr></table></figure>

<h4 id="定性特征哑编码-OneHotEncoder类"><a href="#定性特征哑编码-OneHotEncoder类" class="headerlink" title="定性特征哑编码(OneHotEncoder类)"></a>定性特征哑编码(OneHotEncoder类)</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1.哑变量&#x2F;虚拟变量(Dummy Variable):通常是认为虚设的变量(0&#x2F;1),用来反映某个变量的不同属性。</span><br><span class="line">2.哑变量目的: 原本不能定量处理的变量进行量化，从而评估定性因素对因变量的影响</span><br><span class="line">	2.1 例如: 变量&quot;职业&quot;取值分别为工人、农民、学生、企业职员、其他(5种选项) --&gt; 工人定义为(0,0,0,1) 那么农民就是(0,0,1,0) 学生就是(0,1,0,0) 企业职工就是(1,0,0,0)</span><br><span class="line"></span><br><span class="line">2.哑编码: 类别变量 --&gt; 哑变量</span><br><span class="line">3.哑编码规则:对于有n个类别属性的变量,通常以1个类别特征为参照，产生n-1个哑变量</span><br></pre></td></tr></table></figure>

<h4 id="缺失值处理-impute库的SimpleImputer类"><a href="#缺失值处理-impute库的SimpleImputer类" class="headerlink" title="缺失值处理(impute库的SimpleImputer类)"></a>缺失值处理(impute库的SimpleImputer类)</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1.用Pandas读取后特征均为NaN(数据缺失)</span><br><span class="line">2.使用impute库的SimpleImputer类</span><br></pre></td></tr></table></figure>

<h4 id="数据转换"><a href="#数据转换" class="headerlink" title="数据转换"></a>数据转换</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1.基于多项式的多项式转换(PolynomialFeatures类):参数degree为度(默认值为2)</span><br><span class="line">2.基于对数函数的对数变换:基于单变元函数的数据转换可以使用统一的方法完成(FunctionTransformer类)</span><br><span class="line">3.基于指数函数:</span><br></pre></td></tr></table></figure>

<h2 id="特征降维"><a href="#特征降维" class="headerlink" title="特征降维"></a>特征降维</h2><h3 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h3><p><strong>特征选择三类方法:</strong></p>
<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.6.png" alt></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1.特征选择概念:比较简单粗暴，就是映射函数直接将不重要的特征(×)，不过会造成特征信息的丢失，不利用模型精度</span><br><span class="line">2.特征选择方法:</span><br><span class="line">  2.1 过滤法(Filter):按照发散性&#x2F;相关性对各个特征进行评分,通过设定阈值&#x2F;待选择阈值的个数来选择特征</span><br><span class="line">  2.2 包装法(Wrapper):按照目标函数(AUC&#x2F;MSE)每次选择&#x2F;排除若干特征</span><br><span class="line">	  2.3 嵌入法(Embedded):使用某些算法和模型进行训练,得到各个特征的权值系数，根据系数从大到小选择特征</span><br></pre></td></tr></table></figure>

<h3 id="线性降维"><a href="#线性降维" class="headerlink" title="线性降维"></a>线性降维</h3><p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.8.png" alt></p>
<h2 id="赛题特征工程"><a href="#赛题特征工程" class="headerlink" title="赛题特征工程"></a>赛题特征工程</h2><h3 id="异常值分析-箱线图找出异常删除异常"><a href="#异常值分析-箱线图找出异常删除异常" class="headerlink" title="异常值分析(箱线图找出异常删除异常)"></a>异常值分析(箱线图找出异常删除异常)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">##箱型图</span><br><span class="line">plt.figure(figsize&#x3D;(18,10))</span><br><span class="line">plt.boxplot(x&#x3D;train_data.values,labels&#x3D;train_data.columns) #标签就是训练集的各个列</span><br><span class="line">plt.hlines([-7.5,7.5],0,40,colors&#x3D;&#39;r&#39;)  #从-7.5到7.5绘制水平线 0和40就是这条线从第几个Vx开始画到第Vx个特征</span><br><span class="line">plt.show()</span><br><span class="line">##删除异常值(通过箱型图可以查看到明显的异常值【比如V9变量】)</span><br><span class="line">train_data&#x3D;train_data[train_data[&#39;V9&#39;]&gt;-7.5]</span><br><span class="line">test_data&#x3D;test_data[test_data[&#39;V9&#39;]&gt;-7.5]</span><br><span class="line">print(train_data.describe())</span><br><span class="line">print(test_data.describe())</span><br></pre></td></tr></table></figure>

<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.9.png" alt></p>
<h3 id="归一化-最大值和最小值"><a href="#归一化-最大值和最小值" class="headerlink" title="归一化(最大值和最小值)"></a>归一化(最大值和最小值)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">##归一化(最大值和最小值)  --放缩到(0,1区间)</span><br><span class="line">features_columns&#x3D;[col for col in train_data.columns if col not in [&#39;target&#39;]]   #从V0到V37</span><br><span class="line">min_max_scaler&#x3D;preprocessing.MinMaxScaler().fit(train_data[features_columns])</span><br><span class="line"></span><br><span class="line">train_data_scaler&#x3D;min_max_scaler.transform(train_data[features_columns])</span><br><span class="line">test_data_scaler&#x3D;min_max_scaler.transform(test_data[features_columns])</span><br><span class="line"></span><br><span class="line">train_data_scaler&#x3D;pd.DataFrame(train_data_scaler) #将训练集数据弄成DF格式</span><br><span class="line">train_data_scaler.columns&#x3D;features_columns</span><br><span class="line"></span><br><span class="line">test_data_scaler&#x3D;pd.DataFrame(test_data_scaler) #将测试集数据弄成DF格式</span><br><span class="line">test_data_scaler.columns&#x3D;features_columns</span><br><span class="line"></span><br><span class="line">train_data_scaler[&#39;target&#39;] &#x3D; train_data[&#39;target&#39;]</span><br><span class="line"></span><br><span class="line">print(train_data_scaler.describe())</span><br><span class="line">print(test_data_scaler.describe())</span><br></pre></td></tr></table></figure>

<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.10.png" alt></p>
<h3 id="查看数据分布-KDE差异较大删除特征"><a href="#查看数据分布-KDE差异较大删除特征" class="headerlink" title="查看数据分布(KDE差异较大删除特征)"></a>查看数据分布(KDE差异较大删除特征)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">##查看数据分布  --通过KDE分布对比了特征变量在两个数据集中的分布情况(V5&#x2F;V9&#x2F;V11&#x2F;V17&#x2F;V22&#x2F;V28在训练集和测试集分布差异较大，会影响模型的泛化能力，故删除这些特征)</span><br><span class="line">drop_col&#x3D;6 #6列</span><br><span class="line">drop_row&#x3D;1 #1行</span><br><span class="line">plt.figure(figsize&#x3D;(5*drop_col,5*drop_row))</span><br><span class="line">for i,col in enumerate([&quot;V5&quot;,&quot;V9&quot;,&quot;V11&quot;,&quot;V17&quot;,&quot;V22&quot;,&quot;V28&quot;]): #enumerate函数用于将一个可遍历的数据对象</span><br><span class="line">    ax&#x3D;plt.subplot(1,6,i+1)</span><br><span class="line">    ax&#x3D;sns.kdeplot(train_data_scaler[col],color&#x3D;&quot;Red&quot;,shade&#x3D;True) #画KDE图</span><br><span class="line">    ax&#x3D;sns.kdeplot(test_data_scaler[col],color&#x3D;&quot;Blue&quot;,shade&#x3D;True) #画KDE图</span><br><span class="line">    ax.set_xlabel(col) #设置x标签为col</span><br><span class="line">    ax.set_ylabel(&quot;Frequency&quot;) #设置y标签为Frequency</span><br><span class="line">    ax&#x3D;ax.legend([&quot;train&quot;, &quot;test&quot;])  #设置两条曲线分别叫train和test</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.11.png" alt></p>
<h3 id="特征相关性-用热力图可视化"><a href="#特征相关性-用热力图可视化" class="headerlink" title="特征相关性(用热力图可视化)"></a>特征相关性(用热力图可视化)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">##特征相关性(热力图可视化显示)</span><br><span class="line">plt.figure(figsize&#x3D;(20,16))</span><br><span class="line">column&#x3D;train_data_scaler.columns.tolist() # 整出来一个列表list表示从V0-V39-target</span><br><span class="line">mcorr&#x3D;train_data_scaler[column].corr(method&#x3D;&quot;spearman&quot;)  # spearman表示非线性的 pearson表示相关系数 kendall反映分类变量相关性的指标(无序序列的相关系数)</span><br><span class="line"># zeros_like()函数: 创建一个和mcorr同维度的数组(初始化全为False)</span><br><span class="line">mask&#x3D;np.zeros_like(mcorr,dtype&#x3D;np.bool)</span><br><span class="line"># triu_indices_from()函数: 返回矩阵的上三角(上三角全为True)</span><br><span class="line">mask[np.triu_indices_from(mask)]&#x3D;True</span><br><span class="line">g&#x3D;sns.heatmap(mcorr,mask&#x3D;mask,square&#x3D;True,annot&#x3D;True,fmt&#x3D;&#39;0.2f&#39;) # square为热力图矩阵小块形状(T以列名为标签名)  annot为True表示每个方格写入数据 fmt表示小数点后两位</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.12.png" alt></p>
<h3 id="特征降维-1"><a href="#特征降维-1" class="headerlink" title="特征降维"></a>特征降维</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">##特征降维(特征相关性的初筛--计算相关性系数并筛选&gt;0.1的特征变量)</span><br><span class="line">mcorr&#x3D;mcorr.abs() #将所有取绝对值</span><br><span class="line">numberical_corr&#x3D;mcorr[mcorr[&#39;target&#39;]&gt;0.1][&#39;target&#39;]</span><br><span class="line">print(numberical_corr.sort_values(ascending&#x3D;False))  # VX和系数值 (按照系数值进行排序)</span><br></pre></td></tr></table></figure>

<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.13.png" alt></p>
<h3 id="多重共线性分析-statsmodels-stats-outliers-influence-variance-inflation-factor"><a href="#多重共线性分析-statsmodels-stats-outliers-influence-variance-inflation-factor" class="headerlink" title="多重共线性分析(statsmodels.stats.outliers_influence.variance_inflation_factor)"></a>多重共线性分析(statsmodels.stats.outliers_influence.variance_inflation_factor)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">##多重共线性分析(特征组之间的相关性系数较大) -- 每个特征变量与其他特征变量之间的相关性系数较大所以存在较大的共线性影响 --&gt; 使用PCA进行处理(去除多重共线性)</span><br><span class="line">###statsmodels.stats.outliers_influence.variance_inflation_factor  多重共线性方差膨胀因子</span><br><span class="line">new_numberical&#x3D;[&#39;V0&#39;, &#39;V2&#39;, &#39;V3&#39;, &#39;V4&#39;, &#39;V5&#39;, &#39;V6&#39;, &#39;V10&#39;,&#39;V11&#39;, &#39;V13&#39;, &#39;V15&#39;, &#39;V16&#39;, &#39;V18&#39;, &#39;V19&#39;, &#39;V20&#39;, &#39;V22&#39;,&#39;V24&#39;,&#39;V30&#39;, &#39;V31&#39;, &#39;V37&#39;]</span><br><span class="line">X&#x3D;np.matrix(train_data_scaler[new_numberical]) #根据new_numberical来构成一个二维数组</span><br><span class="line">VIF_list&#x3D;[variance_inflation_factor(X,i) for i in range(X.shape[1])] # 获得多重共线性方差膨胀因子</span><br><span class="line">print(VIF_list)</span><br></pre></td></tr></table></figure>

<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.14.png" alt></p>
<h3 id="PCA处理-去除数据的多重共线性-并进行降维"><a href="#PCA处理-去除数据的多重共线性-并进行降维" class="headerlink" title="PCA处理(去除数据的多重共线性,并进行降维)"></a>PCA处理(去除数据的多重共线性,并进行降维)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">##PCA处理</span><br><span class="line">### sklearn.decomposition.PCA PCA处理之后可保持90%的信息数据</span><br><span class="line">pca&#x3D;PCA(n_components&#x3D;0.9) # 整数表示保留几个特征 小数表示百分之多少的信息</span><br><span class="line">#获得转换器</span><br><span class="line">new_train_pca_90&#x3D;pca.fit_transform(train_data_scaler.iloc[:,0:-1])</span><br><span class="line">new_test_pca_90&#x3D;pca.transform(test_data_scaler)</span><br><span class="line">#转移为DF格式</span><br><span class="line">new_train_pca_90&#x3D;pd.DataFrame(new_train_pca_90)</span><br><span class="line">new_test_pca_90&#x3D;pd.DataFrame(new_test_pca_90)</span><br><span class="line">new_train_pca_90[&#39;target&#39;]&#x3D;train_data_scaler[&#39;target&#39;]  # PCA处理之后保留了16个主成分</span><br><span class="line">print(new_train_pca_90.describe())</span><br><span class="line">print(&quot;----------------------------------------------&quot;)</span><br><span class="line">print(train_data_scaler.describe())</span><br></pre></td></tr></table></figure>

<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.15.png" alt></p>
<h1 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h1><h2 id="回归和相关模型"><a href="#回归和相关模型" class="headerlink" title="回归和相关模型"></a>回归和相关模型</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import seaborn as sns</span><br><span class="line">from sklearn import preprocessing</span><br><span class="line">from sklearn.preprocessing import MinMaxScaler</span><br><span class="line">from scipy import stats</span><br><span class="line">from sklearn.decomposition import PCA</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.linear_model import LinearRegression  #线性回归</span><br><span class="line">from sklearn.neighbors import KNeighborsRegressor  #K近邻回归</span><br><span class="line">from sklearn.tree import DecisionTreeRegressor     #决策树回归</span><br><span class="line">from sklearn.ensemble import RandomForestRegressor #随机森林回归</span><br><span class="line">from sklearn.svm import SVR  # 支持向量回归</span><br><span class="line">from sklearn.model_selection import train_test_split # 切分数据</span><br><span class="line">from sklearn.metrics import mean_squared_error #评价指标</span><br><span class="line">from sklearn.model_selection import learning_curve</span><br><span class="line">from sklearn.model_selection import ShuffleSplit</span><br><span class="line">#1.读取数据</span><br><span class="line">train_data_file &#x3D; &quot;zhengqi_train.txt&quot;</span><br><span class="line">test_data_file &#x3D;  &quot;zhengqi_test.txt&quot;</span><br><span class="line">train_data &#x3D; pd.read_csv(train_data_file, sep&#x3D;&#39;\t&#39;, encoding&#x3D;&#39;utf-8&#39;) #训练集数据共有2888个样本(V0-V37共38个特征变量)  -- 有target字段</span><br><span class="line">test_data &#x3D; pd.read_csv(test_data_file, sep&#x3D;&#39;\t&#39;, encoding&#x3D;&#39;utf-8&#39;) #测试集数据共有1925个样本(V0-V37共有38个特征变量)  -- 无target字段</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#3.归一化(最大值和最小值)  --放缩到(0,1区间)</span><br><span class="line">features_columns&#x3D;[col for col in train_data.columns if col not in [&#39;target&#39;]]   #从V0到V37</span><br><span class="line">min_max_scaler&#x3D;preprocessing.MinMaxScaler().fit(train_data[features_columns])</span><br><span class="line"></span><br><span class="line">train_data_scaler&#x3D;min_max_scaler.transform(train_data[features_columns])</span><br><span class="line">test_data_scaler&#x3D;min_max_scaler.transform(test_data[features_columns])</span><br><span class="line"></span><br><span class="line">train_data_scaler&#x3D;pd.DataFrame(train_data_scaler) #将训练集数据弄成DF格式</span><br><span class="line">train_data_scaler.columns&#x3D;features_columns</span><br><span class="line"></span><br><span class="line">test_data_scaler&#x3D;pd.DataFrame(test_data_scaler) #将测试集数据弄成DF格式</span><br><span class="line">test_data_scaler.columns&#x3D;features_columns</span><br><span class="line"></span><br><span class="line">train_data_scaler[&#39;target&#39;] &#x3D; train_data[&#39;target&#39;]</span><br><span class="line"></span><br><span class="line">#3.PCA处理</span><br><span class="line">### 1.sklearn.decomposition.PCA PCA处理之后可保持90%的信息数据</span><br><span class="line">pca&#x3D;PCA(n_components&#x3D;0.9) # 整数表示保留几个特征 小数表示百分之多少的信息</span><br><span class="line">#获得转换器</span><br><span class="line">new_train_pca_90&#x3D;pca.fit_transform(train_data_scaler.iloc[:,0:-1])</span><br><span class="line">new_test_pca_90&#x3D;pca.transform(test_data_scaler)</span><br><span class="line">#转移为DF格式</span><br><span class="line">new_train_pca_90&#x3D;pd.DataFrame(new_train_pca_90)</span><br><span class="line">new_test_pca_90&#x3D;pd.DataFrame(new_test_pca_90)</span><br><span class="line">new_train_pca_90[&#39;target&#39;]&#x3D;train_data_scaler[&#39;target&#39;]  # PCA处理之后保留了16个主成分</span><br><span class="line">### 2.sklearn.decomposition.PCA PCA处理之后可保持95%的信息数据</span><br><span class="line">pca &#x3D; PCA(n_components&#x3D;0.95)</span><br><span class="line">#获得转换器</span><br><span class="line">new_train_pca_16 &#x3D; pca.fit_transform(train_data_scaler.iloc[:,0:-1])</span><br><span class="line">new_test_pca_16 &#x3D; pca.transform(test_data_scaler)</span><br><span class="line">#转移为DF格式</span><br><span class="line">new_train_pca_16 &#x3D; pd.DataFrame(new_train_pca_16)</span><br><span class="line">new_test_pca_16 &#x3D; pd.DataFrame(new_test_pca_16)</span><br><span class="line">new_train_pca_16[&#39;target&#39;] &#x3D; train_data_scaler[&#39;target&#39;] # PCA处理之后保留了16个主成分</span><br><span class="line"></span><br><span class="line">#2.切分数据(训练集--&gt; 80%训练集和20%验证数据)</span><br><span class="line">new_train_pca_16&#x3D;new_train_pca_16.fillna(0) #采用PCA保留16维特征的数据</span><br><span class="line">train&#x3D;new_train_pca_16[new_test_pca_16.columns]</span><br><span class="line">target&#x3D;new_train_pca_16[&#39;target&#39;]</span><br><span class="line">##切分数据 训练数据80% 验证数据20%</span><br><span class="line">train_data,test_data,train_target,test_target&#x3D;train_test_split(train,target,test_size&#x3D;0.2,random_state&#x3D;0)</span><br><span class="line"></span><br><span class="line">#4.线性回归</span><br><span class="line">clf&#x3D;LinearRegression()  #实例化</span><br><span class="line">clf.fit(train_data,train_target) #创建训练集的转换器</span><br><span class="line">test_pred&#x3D;clf.predict(test_data) #获得测试集的预测</span><br><span class="line">score&#x3D;mean_squared_error(test_target,test_pred) #判断测试集的目标值和测试集的预测值</span><br><span class="line">print(&quot;线性回归预测结果:&quot;,score)  # 结果为0.13468236081062834</span><br><span class="line"></span><br><span class="line">#5.K近邻</span><br><span class="line">clf&#x3D;KNeighborsRegressor(n_neighbors&#x3D;3) # k取3</span><br><span class="line">clf.fit(train_data,train_target)</span><br><span class="line">test_pred&#x3D;clf.predict(test_data)</span><br><span class="line">score&#x3D;mean_squared_error(test_target,test_pred)</span><br><span class="line">print(&quot;K近邻回归预测结果:&quot;,score) # 结果为0.22391053287197232</span><br><span class="line"></span><br><span class="line">#6.决策树回归</span><br><span class="line">clf&#x3D;DecisionTreeRegressor()</span><br><span class="line">clf.fit(train_data,train_target)</span><br><span class="line">test_pred&#x3D;clf.predict(test_data)</span><br><span class="line">score&#x3D;mean_squared_error(test_target,test_pred)</span><br><span class="line">print(&quot;决策树回归预测结果:&quot;,score) # 结果为0.33070805190311414</span><br><span class="line"></span><br><span class="line">#7.随机森林回归</span><br><span class="line">clf&#x3D;RandomForestRegressor(n_estimators&#x3D;200)  #创建200课树的模型</span><br><span class="line">clf.fit(train_data,train_target)</span><br><span class="line">test_pred&#x3D;clf.predict(test_data)</span><br><span class="line">score&#x3D;mean_squared_error(test_target,test_pred)</span><br><span class="line">print(&quot;随机森林回归预测结果:&quot;,score) # 结果为</span><br><span class="line"></span><br><span class="line">#8.LightGBM回归(微软开发的一个GBDT算法框架--更快的训练速度，更低的内存消耗，更好的准确率，处理海量数据)</span><br><span class="line">##(1)连续的浮点特征值 --&gt; k个整数 + (2)构造一个宽度为k的直方图   [遍历时，将离散化后的值作为索引在直方图中积累统计量]</span><br></pre></td></tr></table></figure>

<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.16.png" alt></p>
<h2 id="赛题模型训练"><a href="#赛题模型训练" class="headerlink" title="赛题模型训练"></a>赛题模型训练</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import seaborn as sns</span><br><span class="line">from sklearn import preprocessing</span><br><span class="line">from sklearn.preprocessing import MinMaxScaler</span><br><span class="line">from scipy import stats</span><br><span class="line">from sklearn.decomposition import PCA</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.linear_model import LinearRegression  #线性回归</span><br><span class="line">from sklearn.neighbors import KNeighborsRegressor  #K近邻回归</span><br><span class="line">from sklearn.tree import DecisionTreeRegressor     #决策树回归</span><br><span class="line">from sklearn.ensemble import RandomForestRegressor #随机森林回归</span><br><span class="line">from sklearn.svm import SVR  # 支持向量回归</span><br><span class="line">import lightgbm as lgb # LightGBM模型</span><br><span class="line">from sklearn.model_selection import train_test_split # 切分数据</span><br><span class="line">from sklearn.metrics import mean_squared_error #评价指标</span><br><span class="line">from sklearn.model_selection import learning_curve</span><br><span class="line">from sklearn.model_selection import ShuffleSplit</span><br><span class="line">#1.读取数据</span><br><span class="line">train_data_file &#x3D; &quot;zhengqi_train.txt&quot;</span><br><span class="line">test_data_file &#x3D;  &quot;zhengqi_test.txt&quot;</span><br><span class="line">train_data &#x3D; pd.read_csv(train_data_file, sep&#x3D;&#39;\t&#39;, encoding&#x3D;&#39;utf-8&#39;) #训练集数据共有2888个样本(V0-V37共38个特征变量)  -- 有target字段</span><br><span class="line">test_data &#x3D; pd.read_csv(test_data_file, sep&#x3D;&#39;\t&#39;, encoding&#x3D;&#39;utf-8&#39;) #测试集数据共有1925个样本(V0-V37共有38个特征变量)  -- 无target字段</span><br><span class="line"></span><br><span class="line">#3归一化(最大值和最小值)  --放缩到(0,1区间)</span><br><span class="line">features_columns&#x3D;[col for col in train_data.columns if col not in [&#39;target&#39;]]   #从V0到V37</span><br><span class="line">min_max_scaler&#x3D;preprocessing.MinMaxScaler().fit(train_data[features_columns])</span><br><span class="line"></span><br><span class="line">train_data_scaler&#x3D;min_max_scaler.transform(train_data[features_columns])</span><br><span class="line">test_data_scaler&#x3D;min_max_scaler.transform(test_data[features_columns])</span><br><span class="line"></span><br><span class="line">train_data_scaler&#x3D;pd.DataFrame(train_data_scaler) #将训练集数据弄成DF格式</span><br><span class="line">train_data_scaler.columns&#x3D;features_columns</span><br><span class="line"></span><br><span class="line">test_data_scaler&#x3D;pd.DataFrame(test_data_scaler) #将测试集数据弄成DF格式</span><br><span class="line">test_data_scaler.columns&#x3D;features_columns</span><br><span class="line"></span><br><span class="line">train_data_scaler[&#39;target&#39;] &#x3D; train_data[&#39;target&#39;]</span><br><span class="line"></span><br><span class="line">#3.PCA处理</span><br><span class="line">### 1.sklearn.decomposition.PCA PCA处理之后可保持90%的信息数据</span><br><span class="line">pca&#x3D;PCA(n_components&#x3D;0.9) # 整数表示保留几个特征 小数表示百分之多少的信息</span><br><span class="line">#获得转换器</span><br><span class="line">new_train_pca_90&#x3D;pca.fit_transform(train_data_scaler.iloc[:,0:-1])</span><br><span class="line">new_test_pca_90&#x3D;pca.transform(test_data_scaler)</span><br><span class="line">#转移为DF格式</span><br><span class="line">new_train_pca_90&#x3D;pd.DataFrame(new_train_pca_90)</span><br><span class="line">new_test_pca_90&#x3D;pd.DataFrame(new_test_pca_90)</span><br><span class="line">new_train_pca_90[&#39;target&#39;]&#x3D;train_data_scaler[&#39;target&#39;]  # PCA处理之后保留了16个主成分</span><br><span class="line">### 2.sklearn.decomposition.PCA PCA处理之后可保持95%的信息数据</span><br><span class="line">pca &#x3D; PCA(n_components&#x3D;0.95)</span><br><span class="line">#获得转换器</span><br><span class="line">new_train_pca_16 &#x3D; pca.fit_transform(train_data_scaler.iloc[:,0:-1])</span><br><span class="line">new_test_pca_16 &#x3D; pca.transform(test_data_scaler)</span><br><span class="line">#转移为DF格式</span><br><span class="line">new_train_pca_16 &#x3D; pd.DataFrame(new_train_pca_16)</span><br><span class="line">new_test_pca_16 &#x3D; pd.DataFrame(new_test_pca_16)</span><br><span class="line">new_train_pca_16[&#39;target&#39;] &#x3D; train_data_scaler[&#39;target&#39;] # PCA处理之后保留了16个主成分</span><br><span class="line"></span><br><span class="line">#2.切分数据(训练集--&gt; 80%训练集和20%验证数据)</span><br><span class="line">new_train_pca_16&#x3D;new_train_pca_16.fillna(0) #采用PCA保留16维特征的数据</span><br><span class="line">train&#x3D;new_train_pca_16[new_test_pca_16.columns]</span><br><span class="line">target&#x3D;new_train_pca_16[&#39;target&#39;]</span><br><span class="line">##切分数据 训练数据80% 验证数据20%</span><br><span class="line">train_data,test_data,train_target,test_target&#x3D;train_test_split(train,target,test_size&#x3D;0.2,random_state&#x3D;0)</span><br><span class="line"></span><br><span class="line">#4.线性回归(效果一般，适合分析使用)</span><br><span class="line">clf&#x3D;LinearRegression()  #实例化</span><br><span class="line">clf.fit(train_data,train_target) #创建训练集的转换器</span><br><span class="line">test_pred&#x3D;clf.predict(test_data) #获得测试集的预测</span><br><span class="line">score&#x3D;mean_squared_error(test_target,test_pred) #判断测试集的目标值和测试集的预测值</span><br><span class="line">print(&quot;线性回归预测结果:&quot;,score)  # 结果为0.13468236081062834</span><br><span class="line"></span><br><span class="line">#5.K近邻(效果一般)</span><br><span class="line">clf&#x3D;KNeighborsRegressor(n_neighbors&#x3D;8) # k取8 最近8个</span><br><span class="line">clf.fit(train_data,train_target)</span><br><span class="line">test_pred&#x3D;clf.predict(test_data)</span><br><span class="line">score&#x3D;mean_squared_error(test_target,test_pred)</span><br><span class="line">print(&quot;K近邻回归预测结果:&quot;,score) # 结果为0.22391053287197232</span><br><span class="line"></span><br><span class="line">#6.决策树回归</span><br><span class="line">clf&#x3D;DecisionTreeRegressor()</span><br><span class="line">clf.fit(train_data,train_target)</span><br><span class="line">test_pred&#x3D;clf.predict(test_data)</span><br><span class="line">score&#x3D;mean_squared_error(test_target,test_pred)</span><br><span class="line">print(&quot;决策树回归预测结果:&quot;,score) # 结果为0.33070805190311414</span><br><span class="line"></span><br><span class="line">#7.随机森林回归(比较合适)</span><br><span class="line">clf&#x3D;RandomForestRegressor(n_estimators&#x3D;200)  #创建200课树的模型</span><br><span class="line">clf.fit(train_data,train_target)</span><br><span class="line">test_pred&#x3D;clf.predict(test_data)</span><br><span class="line">score&#x3D;mean_squared_error(test_target,test_pred)</span><br><span class="line">print(&quot;随机森林回归预测结果:&quot;,score) # 结果为</span><br><span class="line"></span><br><span class="line">#8.LightGBM回归(微软开发的一个GBDT算法框架--更快的训练速度，更低的内存消耗，更好的准确率，处理海量数据)</span><br><span class="line">##(1)连续的浮点特征值 --&gt; k个整数 + (2)构造一个宽度为k的直方图   [遍历时，将离散化后的值作为索引在直方图中积累统计量]</span><br><span class="line">clf&#x3D;lgb.LGBMRegressor(</span><br><span class="line">    learning_rate&#x3D;0.01, # 学习率 推荐的候选值为：[0.01, 0.015, 0.025, 0.05, 0.1]</span><br><span class="line">    max_depth&#x3D;-1, # 指定树的最大深度(防止过拟合)</span><br><span class="line">    n_estimators&#x3D;5000, # 树的数量</span><br><span class="line">    boosting_type&#x3D;&#39;gbdt&#39;, # 指定弱学习器的类型 -- gbdt表示使用基于树的模型进行计算(默认)&#x2F;gblinear表示使用线性模型&#x2F;rf使用随机森林</span><br><span class="line">    random_state&#x3D;2019,</span><br><span class="line">    objective&#x3D;&#39;regression&#39; # regression是使用L2正则项的回归模型(默认) &#x2F;regression_l1是使用L1正则项的回归模型 &#x2F;mape平均绝对百分比误差 &#x2F;binary二分类 &#x2F;multiclass多分类</span><br><span class="line">)</span><br><span class="line">##训练模型</span><br><span class="line">clf.fit(X&#x3D;train_data,y&#x3D;train_target,eval_metric&#x3D;&#39;MSE&#39;) #eval_metric表示评价指标(默认是logloss) MSE是均方误差</span><br><span class="line">test_pred&#x3D;clf.predict(test_data)</span><br><span class="line">score&#x3D;mean_squared_error(test_target,test_pred)</span><br><span class="line">print(&quot;lightGbm回归预测结果:&quot;,score)</span><br></pre></td></tr></table></figure>

<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.17.png" alt></p>
<h1 id="模型验证"><a href="#模型验证" class="headerlink" title="模型验证"></a>模型验证</h1><h2 id="模型评估的概念和方法"><a href="#模型评估的概念和方法" class="headerlink" title="模型评估的概念和方法"></a>模型评估的概念和方法</h2><h3 id="欠拟合和过拟合"><a href="#欠拟合和过拟合" class="headerlink" title="欠拟合和过拟合"></a>欠拟合和过拟合</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import seaborn as sns</span><br><span class="line">from sklearn import preprocessing</span><br><span class="line">from sklearn.preprocessing import MinMaxScaler</span><br><span class="line">from scipy import stats</span><br><span class="line">from sklearn.decomposition import PCA</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.linear_model import LinearRegression  #线性回归</span><br><span class="line">from sklearn.neighbors import KNeighborsRegressor  #K近邻回归</span><br><span class="line">from sklearn.tree import DecisionTreeRegressor     #决策树回归</span><br><span class="line">from sklearn.ensemble import RandomForestRegressor #随机森林回归</span><br><span class="line">from sklearn.svm import SVR  # 支持向量回归</span><br><span class="line">import lightgbm as lgb # LightGBM模型</span><br><span class="line">from sklearn.model_selection import train_test_split # 切分数据</span><br><span class="line">from sklearn.metrics import mean_squared_error #评价指标</span><br><span class="line">from sklearn.model_selection import learning_curve</span><br><span class="line">from sklearn.model_selection import ShuffleSplit</span><br><span class="line">from sklearn.pipeline import Pipeline</span><br><span class="line">from sklearn.preprocessing import PolynomialFeatures</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line">#1.读取数据</span><br><span class="line">train_data_file &#x3D; &quot;zhengqi_train.txt&quot;</span><br><span class="line">test_data_file &#x3D;  &quot;zhengqi_test.txt&quot;</span><br><span class="line">train_data &#x3D; pd.read_csv(train_data_file, sep&#x3D;&#39;\t&#39;, encoding&#x3D;&#39;utf-8&#39;) #训练集数据共有2888个样本(V0-V37共38个特征变量)  -- 有target字段</span><br><span class="line">test_data &#x3D; pd.read_csv(test_data_file, sep&#x3D;&#39;\t&#39;, encoding&#x3D;&#39;utf-8&#39;) #测试集数据共有1925个样本(V0-V37共有38个特征变量)  -- 无target字段</span><br><span class="line"></span><br><span class="line">#生成数据集并可视化显示</span><br><span class="line">np.random.seed(666)  #随机生成666个种子</span><br><span class="line">x&#x3D;np.random.uniform(-3.0,3.0,size&#x3D;100) #随机数的最小值是-3.0 最大值是3.0</span><br><span class="line">X&#x3D;x.reshape(-1,1) #reshape更改数据的行列数目</span><br><span class="line">y&#x3D;0.5*x**2+x+2+np.random.normal(0,1,size&#x3D;100)</span><br><span class="line">plt.scatter(x,y) #生成散点图</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">#1.使用线性回归模型对数据进行拟合</span><br><span class="line">lin_reg&#x3D;LinearRegression()</span><br><span class="line">lin_reg.fit(X,y)</span><br><span class="line">print(&quot;准确率为:&quot;,lin_reg.score(X,y)) #准确率约为0.495(比较低) --可见直线拟合数据的程度较低</span><br><span class="line">##使用均方误差来评价拟合程度</span><br><span class="line">y_predict&#x3D;lin_reg.predict(X)</span><br><span class="line">print(&quot;均方误差为:&quot;,mean_squared_error(y,y_predict)) # 均方误差为3.0750025765636577</span><br><span class="line">##绘制拟合结果</span><br><span class="line">plt.scatter(x,y)</span><br><span class="line">plt.plot(np.sort(x),y_predict[np.argsort(x)],color&#x3D;&#39;r&#39;)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">#2.使用多项式回归拟合(2.1封装Pipeline管道 2.2使用Pipeline拟合数据，多项式参数设置为degree&#x3D;x)</span><br><span class="line">##2.1 封装Pipeline管道(以便于下一步灵活调整多项式回归模型参数)</span><br><span class="line">def PolynomialRegression(degree):</span><br><span class="line">    return Pipeline(</span><br><span class="line">        [(&#39;poly&#39;,PolynomialFeatures(degree&#x3D;degree)),</span><br><span class="line">        (&#39;std_scaler&#39;,StandardScaler()),</span><br><span class="line">        (&#39;lin_reg&#39;,LinearRegression())])</span><br><span class="line"></span><br><span class="line">##2.2使用Pipeline拟合数据(多项式参数设置为degree&#x3D;2)</span><br><span class="line">poly2_reg&#x3D;PolynomialRegression(degree&#x3D;2) #使用degree&#x3D;2</span><br><span class="line">poly2_reg.fit(X,y)</span><br><span class="line">y2_predict&#x3D;poly2_reg.predict(X)</span><br><span class="line">print(&quot;degree为2时候的均方误差为:&quot;,mean_squared_error(y,y2_predict)) # 均方误差为1.0987392142417858</span><br><span class="line">##绘制拟合结果</span><br><span class="line">plt.scatter(x,y)</span><br><span class="line">plt.plot(np.sort(x),y2_predict[np.argsort(x)],color&#x3D;&#39;r&#39;)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">##2.2使用Pipeline拟合数据(多项式参数设置为degree&#x3D;10)</span><br><span class="line">poly10_reg&#x3D;PolynomialRegression(degree&#x3D;10) #使用degree&#x3D;10</span><br><span class="line">poly10_reg.fit(X,y)</span><br><span class="line">y10_predict&#x3D;poly10_reg.predict(X)</span><br><span class="line">print(&quot;degree为10时候的均方误差为:&quot;,mean_squared_error(y,y10_predict)) # 均方误差为1.050846676376416</span><br><span class="line">##绘制拟合结果</span><br><span class="line">plt.scatter(x,y)</span><br><span class="line">plt.plot(np.sort(x),y10_predict[np.argsort(x)],color&#x3D;&#39;r&#39;)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">##2.3使用Pipeline拟合数据(多项式参数设置为degree&#x3D;100)</span><br><span class="line">poly100_reg&#x3D;PolynomialRegression(degree&#x3D;100) #使用degree&#x3D;100</span><br><span class="line">poly100_reg.fit(X,y)</span><br><span class="line">y100_predict&#x3D;poly100_reg.predict(X)</span><br><span class="line">print(&quot;degree为100时候的均方误差为:&quot;,mean_squared_error(y,y100_predict)) # 均方误差为0.6831833931625624</span><br><span class="line">##绘制拟合结果</span><br><span class="line">plt.scatter(x,y)</span><br><span class="line">plt.plot(np.sort(x),y100_predict[np.argsort(x)],color&#x3D;&#39;r&#39;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.18.png" alt></p>
<h3 id="模型的泛化与正则化"><a href="#模型的泛化与正则化" class="headerlink" title="模型的泛化与正则化"></a>模型的泛化与正则化</h3><p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.19.png" alt></p>
<h3 id="回归模型的评估指标和调用方法"><a href="#回归模型的评估指标和调用方法" class="headerlink" title="回归模型的评估指标和调用方法"></a>回归模型的评估指标和调用方法</h3><p><strong>四种回归模型评估方法:</strong></p>
<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.20.png" alt></p>
<p><strong>四种回归模型评估的公式:</strong></p>
<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.21.png" alt></p>
<h3 id="交叉验证"><a href="#交叉验证" class="headerlink" title="交叉验证"></a>交叉验证</h3><p><strong>1.简单交叉验证</strong></p>
<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.22.png" alt></p>
<p><strong>2.K折交叉验证</strong></p>
<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.23.png" alt></p>
<p><strong>3.留一法交叉验证</strong></p>
<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.24.png" alt></p>
<p><strong>4.留P法交叉验证</strong></p>
<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.25.png" alt></p>
<p><strong>5.其他交叉验证</strong></p>
<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.26.png" alt></p>
<h2 id="模型调参"><a href="#模型调参" class="headerlink" title="模型调参"></a>模型调参</h2><h3 id="调参的概念"><a href="#调参的概念" class="headerlink" title="调参的概念"></a>调参的概念</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"> 1.参数分类:</span><br><span class="line">   1.1 过程影响类参数: 子模型不变的前提下，调整&quot;子模型数(n_estimators)和学习率(learning_rate)&quot; --&gt; 改变训练过程，提高整体模型的性能</span><br><span class="line">   1.2 子模型影响类参数: 调整&quot;最大树深度(max_depth)和分裂条件(criterion)&quot; --&gt; 改变子模型的性能，提高整体模型的性能</span><br><span class="line">1.3 bagging: 降低方差</span><br><span class="line">1.4 boosting: 降低偏差</span><br></pre></td></tr></table></figure>

<h3 id="参数的影响"><a href="#参数的影响" class="headerlink" title="参数的影响"></a>参数的影响</h3><p><strong>参数对Random Forest的影响</strong></p>
<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.27.png" alt></p>
<p><strong>参数对Gradient Tree Boosting的影响</strong></p>
<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.28.png" alt></p>
<h3 id="网格搜索-Grid-Search"><a href="#网格搜索-Grid-Search" class="headerlink" title="网格搜索(Grid Search)"></a>网格搜索(Grid Search)</h3><p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.29.png" alt></p>
<h3 id="学习曲线"><a href="#学习曲线" class="headerlink" title="学习曲线"></a>学习曲线</h3><p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.30.png" alt></p>
<h3 id="验证曲线"><a href="#验证曲线" class="headerlink" title="验证曲线"></a>验证曲线</h3><p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.31.png" alt></p>
<h2 id="赛题模型验证和调参"><a href="#赛题模型验证和调参" class="headerlink" title="赛题模型验证和调参"></a>赛题模型验证和调参</h2><h3 id="模型过拟合与欠拟合"><a href="#模型过拟合与欠拟合" class="headerlink" title="模型过拟合与欠拟合"></a>模型过拟合与欠拟合</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import seaborn as sns</span><br><span class="line">from sklearn import preprocessing</span><br><span class="line">from sklearn.preprocessing import MinMaxScaler</span><br><span class="line">from scipy import stats</span><br><span class="line">from sklearn.decomposition import PCA</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.linear_model import LinearRegression  #线性回归</span><br><span class="line">from sklearn.neighbors import KNeighborsRegressor  #K近邻回归</span><br><span class="line">from sklearn.tree import DecisionTreeRegressor     #决策树回归</span><br><span class="line">from sklearn.ensemble import RandomForestRegressor #随机森林回归</span><br><span class="line">from sklearn.svm import SVR  # 支持向量回归</span><br><span class="line">import lightgbm as lgb # LightGBM模型</span><br><span class="line">from sklearn.model_selection import train_test_split # 切分数据</span><br><span class="line">from sklearn.metrics import mean_squared_error #均方误差</span><br><span class="line">from sklearn.metrics import mean_absolute_error #平均绝对值误差</span><br><span class="line">from math import sqrt #平方根</span><br><span class="line">from sklearn.metrics import r2_score #R平方值</span><br><span class="line">from sklearn.model_selection import learning_curve</span><br><span class="line">from sklearn.model_selection import ShuffleSplit</span><br><span class="line">from sklearn.pipeline import Pipeline</span><br><span class="line">from sklearn.preprocessing import PolynomialFeatures</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line">from sklearn.linear_model import SGDRegressor</span><br><span class="line">#1.读取数据</span><br><span class="line">train_data_file &#x3D; &quot;zhengqi_train.txt&quot;</span><br><span class="line">test_data_file &#x3D;  &quot;zhengqi_test.txt&quot;</span><br><span class="line">train_data &#x3D; pd.read_csv(train_data_file, sep&#x3D;&#39;\t&#39;, encoding&#x3D;&#39;utf-8&#39;) #训练集数据共有2888个样本(V0-V37共38个特征变量)  -- 有target字段</span><br><span class="line">test_data &#x3D; pd.read_csv(test_data_file, sep&#x3D;&#39;\t&#39;, encoding&#x3D;&#39;utf-8&#39;) #测试集数据共有1925个样本(V0-V37共有38个特征变量)  -- 无target字段</span><br><span class="line"></span><br><span class="line">#2.归一化(最大值和最小值)  --放缩到(0,1区间)</span><br><span class="line">features_columns&#x3D;[col for col in train_data.columns if col not in [&#39;target&#39;]]   #从V0到V37</span><br><span class="line">min_max_scaler&#x3D;preprocessing.MinMaxScaler().fit(train_data[features_columns])</span><br><span class="line"></span><br><span class="line">train_data_scaler&#x3D;min_max_scaler.transform(train_data[features_columns])</span><br><span class="line">test_data_scaler&#x3D;min_max_scaler.transform(test_data[features_columns])</span><br><span class="line"></span><br><span class="line">train_data_scaler&#x3D;pd.DataFrame(train_data_scaler) #将训练集数据弄成DF格式</span><br><span class="line">train_data_scaler.columns&#x3D;features_columns</span><br><span class="line"></span><br><span class="line">test_data_scaler&#x3D;pd.DataFrame(test_data_scaler) #将测试集数据弄成DF格式</span><br><span class="line">test_data_scaler.columns&#x3D;features_columns</span><br><span class="line"></span><br><span class="line">train_data_scaler[&#39;target&#39;] &#x3D; train_data[&#39;target&#39;]</span><br><span class="line"></span><br><span class="line">#3.PCA处理</span><br><span class="line">### 1.sklearn.decomposition.PCA PCA处理之后可保持90%的信息数据</span><br><span class="line">pca&#x3D;PCA(n_components&#x3D;16) # 整数表示保留几个特征 小数表示百分之多少的信息</span><br><span class="line">#获得转换器</span><br><span class="line">new_train_pca_16&#x3D;pca.fit_transform(train_data_scaler.iloc[:,0:-1])</span><br><span class="line">new_test_pca_16&#x3D;pca.transform(test_data_scaler)</span><br><span class="line">#转移为DF格式</span><br><span class="line">new_train_pca_16&#x3D;pd.DataFrame(new_train_pca_16)</span><br><span class="line">new_test_pca_16&#x3D;pd.DataFrame(new_test_pca_16)</span><br><span class="line">new_train_pca_16[&#39;target&#39;]&#x3D;train_data_scaler[&#39;target&#39;]  # PCA处理之后保留了16个主成分</span><br><span class="line"></span><br><span class="line">#4.切分数据(训练集--&gt; 80%训练集和20%验证数据)</span><br><span class="line">new_train_pca_16&#x3D;new_train_pca_16.fillna(0) #采用PCA保留16维特征的数据</span><br><span class="line">train&#x3D;new_train_pca_16[new_test_pca_16.columns]</span><br><span class="line">target&#x3D;new_train_pca_16[&#39;target&#39;]</span><br><span class="line">##切分数据 训练数据80% 验证数据20%</span><br><span class="line">train_data,test_data,train_target,test_target&#x3D;train_test_split(train,target,test_size&#x3D;0.2,random_state&#x3D;0)</span><br><span class="line"></span><br><span class="line">#5.欠拟合(没有多项式转换)</span><br><span class="line">clf&#x3D;SGDRegressor(max_iter&#x3D;500,tol&#x3D;1e-2) # max_iter表示是训练数据的最大传递次数  tol是停止标准</span><br><span class="line">clf.fit(train_data,train_target)</span><br><span class="line">score_train&#x3D;mean_squared_error(train_target,clf.predict(train_data)) # 训练集的均方误差</span><br><span class="line">score_test&#x3D;mean_squared_error(test_target,clf.predict(test_data)) # 测试集的均方误差</span><br><span class="line">print(&quot;SGDRegressor train MSE:&quot;,score_train) # SGDRegressor train MSE:0.14152723650374396</span><br><span class="line">print(&quot;SGDRegressor test MSE:&quot;,score_test) # SGDRegressor test MSE:0.1470304756084494</span><br><span class="line"></span><br><span class="line">#6.过拟合(多项式转换系数过大)</span><br><span class="line">poly&#x3D;PolynomialFeatures(5)  #多项式转换 写5</span><br><span class="line">train_data_poly&#x3D;poly.fit_transform(train_data)</span><br><span class="line">test_data_poly&#x3D;poly.transform(test_data)</span><br><span class="line">clf&#x3D;SGDRegressor(max_iter&#x3D;1000,tol&#x3D;1e-3) # max_iter表示是训练数据的最大传递次数  tol是停止标准</span><br><span class="line">clf.fit(train_data_poly, train_target)  #装在转换器</span><br><span class="line">score_train &#x3D; mean_squared_error(train_target, clf.predict(train_data_poly))</span><br><span class="line">score_test &#x3D; mean_squared_error(test_target, clf.predict(test_data_poly))</span><br><span class="line">print(&quot;SGDRegressor train MSE:&quot;,score_train) # SGDRegressor train MSE: 0.1332651075687169</span><br><span class="line">print(&quot;SGDRegressor test MSE:&quot;,score_test) # SGDRegressor test MSE:  0.14544120121194679</span><br><span class="line"></span><br><span class="line">#7.正常拟合</span><br><span class="line">poly&#x3D;PolynomialFeatures(3)  #多项式转换 写3</span><br><span class="line">train_data_poly&#x3D;poly.fit_transform(train_data)</span><br><span class="line">test_data_poly&#x3D;poly.transform(test_data)</span><br><span class="line">clf&#x3D;SGDRegressor(max_iter&#x3D;1000,tol&#x3D;1e-3) # max_iter表示是训练数据的最大传递次数  tol是停止标准</span><br><span class="line">clf.fit(train_data_poly, train_target)  #装在转换器</span><br><span class="line">score_train &#x3D; mean_squared_error(train_target, clf.predict(train_data_poly))</span><br><span class="line">score_test &#x3D; mean_squared_error(test_target, clf.predict(test_data_poly))</span><br><span class="line">print(&quot;SGDRegressor train MSE:&quot;,score_train) # SGDRegressor train MSE: 0.13343001175858962</span><br><span class="line">print(&quot;SGDRegressor test MSE:&quot;,score_test) # SGDRegressor test MSE: 0.14179907981584394</span><br></pre></td></tr></table></figure>

<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.32.png" alt></p>
<h3 id="模型正则化"><a href="#模型正则化" class="headerlink" title="模型正则化"></a>模型正则化</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import seaborn as sns</span><br><span class="line">from sklearn import preprocessing</span><br><span class="line">from sklearn.preprocessing import MinMaxScaler</span><br><span class="line">from scipy import stats</span><br><span class="line">from sklearn.decomposition import PCA</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.linear_model import LinearRegression  #线性回归</span><br><span class="line">from sklearn.neighbors import KNeighborsRegressor  #K近邻回归</span><br><span class="line">from sklearn.tree import DecisionTreeRegressor     #决策树回归</span><br><span class="line">from sklearn.ensemble import RandomForestRegressor #随机森林回归</span><br><span class="line">from sklearn.svm import SVR  # 支持向量回归</span><br><span class="line">import lightgbm as lgb # LightGBM模型</span><br><span class="line">from sklearn.model_selection import train_test_split # 切分数据</span><br><span class="line">from sklearn.metrics import mean_squared_error #均方误差</span><br><span class="line">from sklearn.metrics import mean_absolute_error #平均绝对值误差</span><br><span class="line">from math import sqrt #平方根</span><br><span class="line">from sklearn.metrics import r2_score #R平方值</span><br><span class="line">from sklearn.model_selection import learning_curve</span><br><span class="line">from sklearn.model_selection import ShuffleSplit</span><br><span class="line">from sklearn.pipeline import Pipeline</span><br><span class="line">from sklearn.preprocessing import PolynomialFeatures</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line">from sklearn.linear_model import SGDRegressor</span><br><span class="line">#1.读取数据</span><br><span class="line">train_data_file &#x3D; &quot;zhengqi_train.txt&quot;</span><br><span class="line">test_data_file &#x3D;  &quot;zhengqi_test.txt&quot;</span><br><span class="line">train_data &#x3D; pd.read_csv(train_data_file, sep&#x3D;&#39;\t&#39;, encoding&#x3D;&#39;utf-8&#39;) #训练集数据共有2888个样本(V0-V37共38个特征变量)  -- 有target字段</span><br><span class="line">test_data &#x3D; pd.read_csv(test_data_file, sep&#x3D;&#39;\t&#39;, encoding&#x3D;&#39;utf-8&#39;) #测试集数据共有1925个样本(V0-V37共有38个特征变量)  -- 无target字段</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#2.归一化(最大值和最小值)  --放缩到(0,1区间)</span><br><span class="line">features_columns&#x3D;[col for col in train_data.columns if col not in [&#39;target&#39;]]   #从V0到V37</span><br><span class="line">min_max_scaler&#x3D;preprocessing.MinMaxScaler().fit(train_data[features_columns])</span><br><span class="line"></span><br><span class="line">train_data_scaler&#x3D;min_max_scaler.transform(train_data[features_columns])</span><br><span class="line">test_data_scaler&#x3D;min_max_scaler.transform(test_data[features_columns])</span><br><span class="line"></span><br><span class="line">train_data_scaler&#x3D;pd.DataFrame(train_data_scaler) #将训练集数据弄成DF格式</span><br><span class="line">train_data_scaler.columns&#x3D;features_columns</span><br><span class="line"></span><br><span class="line">test_data_scaler&#x3D;pd.DataFrame(test_data_scaler) #将测试集数据弄成DF格式</span><br><span class="line">test_data_scaler.columns&#x3D;features_columns</span><br><span class="line"></span><br><span class="line">train_data_scaler[&#39;target&#39;] &#x3D; train_data[&#39;target&#39;]</span><br><span class="line"></span><br><span class="line">#3.PCA处理</span><br><span class="line">### 1.sklearn.decomposition.PCA PCA处理之后可保持90%的信息数据</span><br><span class="line">pca&#x3D;PCA(n_components&#x3D;16) # 整数表示保留几个特征 小数表示百分之多少的信息</span><br><span class="line">#获得转换器</span><br><span class="line">new_train_pca_16&#x3D;pca.fit_transform(train_data_scaler.iloc[:,0:-1])</span><br><span class="line">new_test_pca_16&#x3D;pca.transform(test_data_scaler)</span><br><span class="line">#转移为DF格式</span><br><span class="line">new_train_pca_16&#x3D;pd.DataFrame(new_train_pca_16)</span><br><span class="line">new_test_pca_16&#x3D;pd.DataFrame(new_test_pca_16)</span><br><span class="line">new_train_pca_16[&#39;target&#39;]&#x3D;train_data_scaler[&#39;target&#39;]  # PCA处理之后保留了16个主成分</span><br><span class="line"></span><br><span class="line">#4.切分数据(训练集--&gt; 80%训练集和20%验证数据)</span><br><span class="line">new_train_pca_16&#x3D;new_train_pca_16.fillna(0) #采用PCA保留16维特征的数据</span><br><span class="line">train&#x3D;new_train_pca_16[new_test_pca_16.columns]</span><br><span class="line">target&#x3D;new_train_pca_16[&#39;target&#39;]</span><br><span class="line">##切分数据 训练数据80% 验证数据20%</span><br><span class="line">train_data,test_data,train_target,test_target&#x3D;train_test_split(train,target,test_size&#x3D;0.2,random_state&#x3D;0)</span><br><span class="line"></span><br><span class="line">#8.模型正则化</span><br><span class="line">##8.1 L2范数正则化</span><br><span class="line">poly&#x3D;PolynomialFeatures(3)  #多项式转换 写3</span><br><span class="line">train_data_poly&#x3D;poly.fit_transform(train_data)</span><br><span class="line">test_data_poly&#x3D;poly.transform(test_data)</span><br><span class="line">clf&#x3D;SGDRegressor(max_iter&#x3D;1000,tol&#x3D;1e-3,penalty&#x3D;&#39;L2&#39;,alpha&#x3D;0.0001) # max_iter表示是训练数据的最大传递次数  tol是停止标准</span><br><span class="line">clf.fit(train_data_poly, train_target)  #装在转换器</span><br><span class="line">score_train &#x3D; mean_squared_error(train_target, clf.predict(train_data_poly))</span><br><span class="line">score_test &#x3D; mean_squared_error(test_target, clf.predict(test_data_poly))</span><br><span class="line">print(&quot;SGDRegressor train MSE:&quot;,score_train) # SGDRegressor train MSE: 0.13343001175858962</span><br><span class="line">print(&quot;SGDRegressor test MSE:&quot;,score_test) # SGDRegressor test MSE: 0.14179907981584394</span><br><span class="line"></span><br><span class="line">##8.2 L1范数正则化</span><br><span class="line">poly&#x3D;PolynomialFeatures(3)  #多项式转换 写3</span><br><span class="line">train_data_poly&#x3D;poly.fit_transform(train_data)</span><br><span class="line">test_data_poly&#x3D;poly.transform(test_data)</span><br><span class="line">clf&#x3D;SGDRegressor(max_iter&#x3D;1000,tol&#x3D;1e-3,penalty&#x3D;&#39;L1&#39;,alpha&#x3D;0.0001) # max_iter表示是训练数据的最大传递次数  tol是停止标准</span><br><span class="line">clf.fit(train_data_poly, train_target)  #装在转换器</span><br><span class="line">score_train &#x3D; mean_squared_error(train_target, clf.predict(train_data_poly))</span><br><span class="line">score_test &#x3D; mean_squared_error(test_target, clf.predict(test_data_poly))</span><br><span class="line">print(&quot;SGDRegressor train MSE:&quot;,score_train) # SGDRegressor train MSE: 0.1347595438689653</span><br><span class="line">print(&quot;SGDRegressor test MSE:&quot;,score_test) # SGDRegressor test MSE: 0.14295179346699013</span><br><span class="line"></span><br><span class="line">##8.3 ElasticNet联合L1和L2范数加权正则化</span><br><span class="line">poly&#x3D;PolynomialFeatures(3)  #多项式转换 写3</span><br><span class="line">train_data_poly&#x3D;poly.fit_transform(train_data)</span><br><span class="line">test_data_poly&#x3D;poly.transform(test_data)</span><br><span class="line">clf&#x3D;SGDRegressor(max_iter&#x3D;1000,tol&#x3D;1e-3,penalty&#x3D;&#39;elasticnet&#39;,l1_ratio&#x3D;0.9,alpha&#x3D;0.0001) # max_iter表示是训练数据的最大传递次数  tol是停止标准</span><br><span class="line">clf.fit(train_data_poly, train_target)  #装在转换器</span><br><span class="line">score_train &#x3D; mean_squared_error(train_target, clf.predict(train_data_poly))</span><br><span class="line">score_test &#x3D; mean_squared_error(test_target, clf.predict(test_data_poly))</span><br><span class="line">print(&quot;SGDRegressor train MSE:&quot;,score_train) # SGDRegressor train MSE: 0.13501686392085374</span><br><span class="line">print(&quot;SGDRegressor test MSE:&quot;,score_test) # SGDRegressor test MSE: 0.14315710816572816</span><br></pre></td></tr></table></figure>

<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.33.png" alt></p>
<h3 id="模型交叉验证-四种"><a href="#模型交叉验证-四种" class="headerlink" title="模型交叉验证(四种)"></a>模型交叉验证(四种)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import seaborn as sns</span><br><span class="line">from sklearn import preprocessing</span><br><span class="line">from sklearn.preprocessing import MinMaxScaler  #归一化</span><br><span class="line">from scipy import stats</span><br><span class="line">from sklearn.decomposition import PCA  #PCA主成分降维</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.linear_model import LinearRegression  #线性回归</span><br><span class="line">from sklearn.neighbors import KNeighborsRegressor  #K近邻回归</span><br><span class="line">from sklearn.tree import DecisionTreeRegressor     #决策树回归</span><br><span class="line">from sklearn.ensemble import RandomForestRegressor #随机森林回归</span><br><span class="line">from sklearn.svm import SVR  # 支持向量回归</span><br><span class="line">import lightgbm as lgb # LightGBM模型</span><br><span class="line">from sklearn.model_selection import train_test_split # 切分数据</span><br><span class="line">from sklearn.metrics import mean_squared_error #均方误差</span><br><span class="line">from sklearn.metrics import mean_absolute_error #平均绝对值误差</span><br><span class="line">from math import sqrt #平方根</span><br><span class="line">from sklearn.metrics import r2_score #R平方值</span><br><span class="line">from sklearn.model_selection import learning_curve</span><br><span class="line">from sklearn.model_selection import ShuffleSplit</span><br><span class="line">from sklearn.pipeline import Pipeline  #管道</span><br><span class="line">from sklearn.preprocessing import PolynomialFeatures  #多项式转变</span><br><span class="line">from sklearn.preprocessing import StandardScaler #标准化</span><br><span class="line">from sklearn.linear_model import SGDRegressor  #随机递推下降</span><br><span class="line">from sklearn.model_selection import KFold #KFold是K折交叉验证</span><br><span class="line">from sklearn.model_selection import LeaveOneOut #留一法</span><br><span class="line">from sklearn.model_selection import LeavePOut #留P法</span><br><span class="line">#1.读取数据</span><br><span class="line">train_data_file &#x3D; &quot;zhengqi_train.txt&quot;</span><br><span class="line">test_data_file &#x3D;  &quot;zhengqi_test.txt&quot;</span><br><span class="line">train_data &#x3D; pd.read_csv(train_data_file, sep&#x3D;&#39;\t&#39;, encoding&#x3D;&#39;utf-8&#39;) #训练集数据共有2888个样本(V0-V37共38个特征变量)  -- 有target字段</span><br><span class="line">test_data &#x3D; pd.read_csv(test_data_file, sep&#x3D;&#39;\t&#39;, encoding&#x3D;&#39;utf-8&#39;) #测试集数据共有1925个样本(V0-V37共有38个特征变量)  -- 无target字段</span><br><span class="line"></span><br><span class="line">#2.归一化(最大值和最小值)  --放缩到(0,1区间)</span><br><span class="line">features_columns&#x3D;[col for col in train_data.columns if col not in [&#39;target&#39;]]   #从V0到V37</span><br><span class="line">min_max_scaler&#x3D;preprocessing.MinMaxScaler().fit(train_data[features_columns])</span><br><span class="line"></span><br><span class="line">train_data_scaler&#x3D;min_max_scaler.transform(train_data[features_columns])</span><br><span class="line">test_data_scaler&#x3D;min_max_scaler.transform(test_data[features_columns])</span><br><span class="line"></span><br><span class="line">train_data_scaler&#x3D;pd.DataFrame(train_data_scaler) #将训练集数据弄成DF格式</span><br><span class="line">train_data_scaler.columns&#x3D;features_columns</span><br><span class="line"></span><br><span class="line">test_data_scaler&#x3D;pd.DataFrame(test_data_scaler) #将测试集数据弄成DF格式</span><br><span class="line">test_data_scaler.columns&#x3D;features_columns</span><br><span class="line"></span><br><span class="line">train_data_scaler[&#39;target&#39;] &#x3D; train_data[&#39;target&#39;]</span><br><span class="line"></span><br><span class="line">#3.PCA处理</span><br><span class="line">### 1.sklearn.decomposition.PCA PCA处理之后可保持90%的信息数据</span><br><span class="line">pca&#x3D;PCA(n_components&#x3D;16) # 整数表示保留几个特征 小数表示百分之多少的信息</span><br><span class="line">#获得转换器</span><br><span class="line">new_train_pca_16&#x3D;pca.fit_transform(train_data_scaler.iloc[:,0:-1])</span><br><span class="line">new_test_pca_16&#x3D;pca.transform(test_data_scaler)</span><br><span class="line">#转移为DF格式</span><br><span class="line">new_train_pca_16&#x3D;pd.DataFrame(new_train_pca_16)</span><br><span class="line">new_test_pca_16&#x3D;pd.DataFrame(new_test_pca_16)</span><br><span class="line">new_train_pca_16[&#39;target&#39;]&#x3D;train_data_scaler[&#39;target&#39;]  # PCA处理之后保留了16个主成分</span><br><span class="line"></span><br><span class="line">#4.切分数据(训练集--&gt; 80%训练集和20%验证数据)</span><br><span class="line">new_train_pca_16&#x3D;new_train_pca_16.fillna(0) #采用PCA保留16维特征的数据</span><br><span class="line">train&#x3D;new_train_pca_16[new_test_pca_16.columns]</span><br><span class="line">target&#x3D;new_train_pca_16[&#39;target&#39;]</span><br><span class="line">##切分数据 训练数据80% 验证数据20%</span><br><span class="line">train_data,test_data,train_target,test_target&#x3D;train_test_split(train,target,test_size&#x3D;0.2,random_state&#x3D;0)</span><br><span class="line"></span><br><span class="line">#5.模型交叉验证</span><br><span class="line">##5.1 简单交叉验证</span><br><span class="line">clf&#x3D;SGDRegressor(max_iter&#x3D;1000,tol&#x3D;1e-3) # max_iter表示是训练数据的最大传递次数  tol是停止标准</span><br><span class="line">clf.fit(train_data,train_target)  #装在转换器</span><br><span class="line">score_train &#x3D; mean_squared_error(train_target, clf.predict(train_data))</span><br><span class="line">score_test &#x3D; mean_squared_error(test_target, clf.predict(test_data))</span><br><span class="line">#print(&quot;SGDRegressor train MSE:&quot;,score_train) # SGDRegressor train MSE: 0.1415415271798254</span><br><span class="line">#print(&quot;SGDRegressor test MSE:&quot;,score_test) # SGDRegressor test MSE: 0.147046507243961</span><br><span class="line"></span><br><span class="line">##5.2 k折交叉验证</span><br><span class="line">kf&#x3D;KFold(n_splits&#x3D;5)</span><br><span class="line">for k,(train_index,test_index) in enumerate(kf.split(train)):</span><br><span class="line">    train_data,test_data,train_target,test_target&#x3D;train.values[train_index],train.values[test_index],target[train_index],target[test_index]</span><br><span class="line">    clf &#x3D; SGDRegressor(max_iter&#x3D;1000,tol&#x3D;1e-3)  # max_iter表示是训练数据的最大传递次数  tol是停止标准</span><br><span class="line">    clf.fit(train_data,train_target)</span><br><span class="line">    score_train &#x3D; mean_squared_error(train_target, clf.predict(train_data))</span><br><span class="line">    score_test &#x3D; mean_squared_error(test_target, clf.predict(test_data))</span><br><span class="line">    print(k,&quot;折&quot;,&quot;SGDRegressor train MSE:&quot;,score_train) # x 折 SGDRegressor train MSE: 0.1415415271798254</span><br><span class="line">    print(k,&quot;折&quot;,&quot;SGDRegressor test MSE:&quot;,score_test) # x 折 SGDRegressor train MSE: 0.1415415271798254</span><br><span class="line"></span><br><span class="line">##5.3 留一法 LOO CV</span><br><span class="line">loo&#x3D;LeaveOneOut()</span><br><span class="line">num&#x3D;100</span><br><span class="line">for k,(train_index,test_index) in enumerate(loo.split(train)):</span><br><span class="line">    train_data,test_data,train_target,test_target &#x3D; train.values[train_index],train.values[test_index],target[train_index],target[test_index]</span><br><span class="line">    clf &#x3D; SGDRegressor(max_iter&#x3D;1000,tol&#x3D;1e-3)  # max_iter表示是训练数据的最大传递次数  tol是停止标准</span><br><span class="line">    clf.fit(train_data,train_target)</span><br><span class="line">    score_train &#x3D; mean_squared_error(train_target, clf.predict(train_data))</span><br><span class="line">    score_test &#x3D; mean_squared_error(test_target, clf.predict(test_data))</span><br><span class="line">    print(k,&quot;个&quot;,&quot;SGDRegressor train MSE:&quot;,score_train)</span><br><span class="line">    print(k,&quot;个&quot;,&quot;SGDRegressor test MSE:&quot;,score_test)</span><br><span class="line">    if k &gt;&#x3D; 9:</span><br><span class="line">        break</span><br><span class="line"></span><br><span class="line">##5.4 留P法 LPO CV</span><br><span class="line">lpo&#x3D;LeavePOut(p&#x3D;10)</span><br><span class="line">num&#x3D;100</span><br><span class="line">for k,(train_index, test_index) in enumerate(lpo.split(train)):</span><br><span class="line">    train_data,test_data,train_target,test_target &#x3D; train.values[train_index],train.values[test_index],target[train_index],target[test_index]</span><br><span class="line">    clf &#x3D; SGDRegressor(max_iter&#x3D;1000,tol&#x3D;1e-3)  # max_iter表示是训练数据的最大传递次数  tol是停止标准</span><br><span class="line">    clf.fit(train_data, train_target)</span><br><span class="line">    score_train &#x3D; mean_squared_error(train_target, clf.predict(train_data))</span><br><span class="line">    score_test &#x3D; mean_squared_error(test_target, clf.predict(test_data))</span><br><span class="line">    print(k,&quot;10个&quot;,&quot;SGDRegressor train MSE:&quot;,score_train)</span><br><span class="line">    print(k,&quot;10个&quot;,&quot;SGDRegressor test MSE:&quot;,score_test)</span><br><span class="line">    if k &gt;&#x3D; 9:</span><br><span class="line">        break</span><br></pre></td></tr></table></figure>

<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.34.png" alt></p>
<h3 id="模型超参空间及调参"><a href="#模型超参空间及调参" class="headerlink" title="模型超参空间及调参"></a>模型超参空间及调参</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import seaborn as sns</span><br><span class="line">from sklearn import preprocessing</span><br><span class="line">from sklearn.preprocessing import MinMaxScaler  #归一化</span><br><span class="line">from scipy import stats</span><br><span class="line">from sklearn.decomposition import PCA  #PCA主成分降维</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.linear_model import LinearRegression  #线性回归</span><br><span class="line">from sklearn.neighbors import KNeighborsRegressor  #K近邻回归</span><br><span class="line">from sklearn.tree import DecisionTreeRegressor     #决策树回归</span><br><span class="line">from sklearn.ensemble import RandomForestRegressor #随机森林回归</span><br><span class="line">from sklearn.svm import SVR  # 支持向量回归</span><br><span class="line">import lightgbm as lgb # LightGBM模型</span><br><span class="line">from sklearn.model_selection import train_test_split # 切分数据</span><br><span class="line">from sklearn.metrics import mean_squared_error #均方误差</span><br><span class="line">from sklearn.metrics import mean_absolute_error #平均绝对值误差</span><br><span class="line">from math import sqrt #平方根</span><br><span class="line">from sklearn.metrics import r2_score #R平方值</span><br><span class="line">from sklearn.model_selection import learning_curve</span><br><span class="line">from sklearn.model_selection import ShuffleSplit</span><br><span class="line">from sklearn.pipeline import Pipeline  #管道</span><br><span class="line">from sklearn.preprocessing import PolynomialFeatures  #多项式转变</span><br><span class="line">from sklearn.preprocessing import StandardScaler #标准化</span><br><span class="line">from sklearn.linear_model import SGDRegressor  #随机递推下降</span><br><span class="line">from sklearn.model_selection import KFold #KFold是K折交叉验证</span><br><span class="line">from sklearn.model_selection import LeaveOneOut #留一法</span><br><span class="line">from sklearn.model_selection import LeavePOut #留P法</span><br><span class="line">from sklearn.model_selection import GridSearchCV #网格搜索</span><br><span class="line">from sklearn.model_selection import RandomizedSearchCV</span><br><span class="line">#1.读取数据</span><br><span class="line">train_data_file &#x3D; &quot;zhengqi_train.txt&quot;</span><br><span class="line">test_data_file &#x3D;  &quot;zhengqi_test.txt&quot;</span><br><span class="line">train_data &#x3D; pd.read_csv(train_data_file, sep&#x3D;&#39;\t&#39;, encoding&#x3D;&#39;utf-8&#39;) #训练集数据共有2888个样本(V0-V37共38个特征变量)  -- 有target字段</span><br><span class="line">test_data &#x3D; pd.read_csv(test_data_file, sep&#x3D;&#39;\t&#39;, encoding&#x3D;&#39;utf-8&#39;) #测试集数据共有1925个样本(V0-V37共有38个特征变量)  -- 无target字段</span><br><span class="line"></span><br><span class="line">#2.归一化(最大值和最小值)  --放缩到(0,1区间)</span><br><span class="line">features_columns&#x3D;[col for col in train_data.columns if col not in [&#39;target&#39;]]   #从V0到V37</span><br><span class="line">min_max_scaler&#x3D;preprocessing.MinMaxScaler().fit(train_data[features_columns])</span><br><span class="line"></span><br><span class="line">train_data_scaler&#x3D;min_max_scaler.transform(train_data[features_columns])</span><br><span class="line">test_data_scaler&#x3D;min_max_scaler.transform(test_data[features_columns])</span><br><span class="line"></span><br><span class="line">train_data_scaler&#x3D;pd.DataFrame(train_data_scaler) #将训练集数据弄成DF格式</span><br><span class="line">train_data_scaler.columns&#x3D;features_columns</span><br><span class="line"></span><br><span class="line">test_data_scaler&#x3D;pd.DataFrame(test_data_scaler) #将测试集数据弄成DF格式</span><br><span class="line">test_data_scaler.columns&#x3D;features_columns</span><br><span class="line"></span><br><span class="line">train_data_scaler[&#39;target&#39;] &#x3D; train_data[&#39;target&#39;]</span><br><span class="line"></span><br><span class="line">#3.PCA处理</span><br><span class="line">### 1.sklearn.decomposition.PCA PCA处理之后可保持90%的信息数据</span><br><span class="line">pca&#x3D;PCA(n_components&#x3D;16) # 整数表示保留几个特征 小数表示百分之多少的信息</span><br><span class="line">#获得转换器</span><br><span class="line">new_train_pca_16&#x3D;pca.fit_transform(train_data_scaler.iloc[:,0:-1])</span><br><span class="line">new_test_pca_16&#x3D;pca.transform(test_data_scaler)</span><br><span class="line">#转移为DF格式</span><br><span class="line">new_train_pca_16&#x3D;pd.DataFrame(new_train_pca_16)</span><br><span class="line">new_test_pca_16&#x3D;pd.DataFrame(new_test_pca_16)</span><br><span class="line">new_train_pca_16[&#39;target&#39;]&#x3D;train_data_scaler[&#39;target&#39;]  # PCA处理之后保留了16个主成分</span><br><span class="line"></span><br><span class="line">#4.切分数据(训练集--&gt; 80%训练集和20%验证数据)</span><br><span class="line">new_train_pca_16&#x3D;new_train_pca_16.fillna(0) #采用PCA保留16维特征的数据</span><br><span class="line">train&#x3D;new_train_pca_16[new_test_pca_16.columns]</span><br><span class="line">target&#x3D;new_train_pca_16[&#39;target&#39;]</span><br><span class="line">##切分数据 训练数据80% 验证数据20%</span><br><span class="line">train_data,test_data,train_target,test_target&#x3D;train_test_split(train,target,test_size&#x3D;0.2,random_state&#x3D;0)</span><br><span class="line"></span><br><span class="line">#5.模型超参空间及调参</span><br><span class="line">##5.1 穷举网格搜索</span><br><span class="line">randomForestRegressor&#x3D;RandomForestRegressor()</span><br><span class="line">parameters&#x3D;&#123;</span><br><span class="line">    &#39;n_estimators&#39;:[50,100,200], #预测器数量</span><br><span class="line">    &#39;max_depth&#39;:[1,2,3] #最大深度</span><br><span class="line">&#125;</span><br><span class="line">clf&#x3D;GridSearchCV(randomForestRegressor,parameters,cv&#x3D;5) # cv指定几折交叉验证(训练集中训练集和验证集的划分有几次，然后得出平均值)</span><br><span class="line">clf.fit(train_data,train_target)</span><br><span class="line">score_test &#x3D; mean_squared_error(test_target, clf.predict(test_data)) #均方误差</span><br><span class="line">print(&quot;RandomForestRegressor GridSearchCV test MSE:&quot;,score_test) # 0.25522816178256824</span><br><span class="line">##5.2 随机参数优化</span><br><span class="line">randomForestRegressor &#x3D; RandomForestRegressor()</span><br><span class="line">parameters &#x3D; &#123;</span><br><span class="line">              &#39;n_estimators&#39;:[50, 100, 200, 300], #预测器数量</span><br><span class="line">              &#39;max_depth&#39;:[1, 2, 3, 4, 5] #最大深度</span><br><span class="line">&#125;</span><br><span class="line">clf&#x3D;RandomizedSearchCV(randomForestRegressor,parameters,cv&#x3D;5)</span><br><span class="line">clf.fit(train_data,train_target)</span><br><span class="line">score_test &#x3D; mean_squared_error(test_target, clf.predict(test_data)) #均方误差</span><br><span class="line">print(&quot;RandomForestRegressor RandomizedSearchCV test MSE:&quot;,score_test) #</span><br><span class="line">print(sorted(clf.cv_results_))</span><br><span class="line">##5.3 LGB调参(使用数据训练LGB模型，采用网格搜索方法调参)</span><br><span class="line">clf&#x3D;lgb.LGBMRegressor(num_leaves&#x3D;31)</span><br><span class="line">parameters &#x3D; &#123;</span><br><span class="line">    &#39;learning_rate&#39;: [0.01, 0.1, 1], #学习率</span><br><span class="line">    &#39;n_estimators&#39;: [20, 40] #预测器数量</span><br><span class="line">&#125;</span><br><span class="line">clf&#x3D;GridSearchCV(clf,parameters,cv&#x3D;5)</span><br><span class="line">clf.fit(train_data,train_target)</span><br><span class="line">print(&#39;Best parameters found by grid search are:&#39;,clf.best_params_)   #最好的学习率和预测器个数</span><br><span class="line">score_test&#x3D;mean_squared_error(test_target,clf.predict(test_data))</span><br><span class="line">print(&quot;LGBMRegressor RandomizedSearchCV test MSE:&quot;,score_test)  # LGBMRegressor RandomizedSearchCV test MSE: 0.15175110081465454</span><br></pre></td></tr></table></figure>

<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.35.png" alt></p>
<h1 id="特征优化"><a href="#特征优化" class="headerlink" title="特征优化"></a>特征优化</h1><h2 id="特征优化的方法"><a href="#特征优化的方法" class="headerlink" title="特征优化的方法"></a>特征优化的方法</h2><p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.36.png" alt></p>
<h2 id="赛题特征优化"><a href="#赛题特征优化" class="headerlink" title="赛题特征优化"></a>赛题特征优化</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import seaborn as sns</span><br><span class="line">from sklearn import preprocessing</span><br><span class="line">from sklearn.preprocessing import MinMaxScaler  #归一化</span><br><span class="line">from scipy import stats</span><br><span class="line">from sklearn.decomposition import PCA  #PCA主成分降维</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.linear_model import LinearRegression  #线性回归</span><br><span class="line">from sklearn.neighbors import KNeighborsRegressor  #K近邻回归</span><br><span class="line">from sklearn.tree import DecisionTreeRegressor     #决策树回归</span><br><span class="line">from sklearn.ensemble import RandomForestRegressor #随机森林回归</span><br><span class="line">from sklearn.svm import SVR  # 支持向量回归</span><br><span class="line">import lightgbm as lgb # LightGBM模型</span><br><span class="line">from sklearn.model_selection import train_test_split # 切分数据</span><br><span class="line">from sklearn.metrics import mean_squared_error #均方误差</span><br><span class="line">from sklearn.metrics import mean_absolute_error #平均绝对值误差</span><br><span class="line">from math import sqrt #平方根</span><br><span class="line">from sklearn.metrics import r2_score #R平方值</span><br><span class="line">from sklearn.model_selection import learning_curve</span><br><span class="line">from sklearn.model_selection import ShuffleSplit</span><br><span class="line">from sklearn.pipeline import Pipeline  #管道</span><br><span class="line">from sklearn.preprocessing import PolynomialFeatures  #多项式转变</span><br><span class="line">from sklearn.preprocessing import StandardScaler #标准化</span><br><span class="line">from sklearn.linear_model import SGDRegressor  #随机递推下降</span><br><span class="line">from sklearn.model_selection import KFold #KFold是K折交叉验证</span><br><span class="line">from sklearn.model_selection import LeaveOneOut #留一法</span><br><span class="line">from sklearn.model_selection import LeavePOut #留P法</span><br><span class="line">from sklearn.model_selection import GridSearchCV #网格搜索</span><br><span class="line">from sklearn.model_selection import RandomizedSearchCV</span><br><span class="line">#1.读取数据</span><br><span class="line">train_data_file &#x3D; &quot;zhengqi_train.txt&quot;</span><br><span class="line">test_data_file &#x3D;  &quot;zhengqi_test.txt&quot;</span><br><span class="line">train_data &#x3D; pd.read_csv(train_data_file, sep&#x3D;&#39;\t&#39;, encoding&#x3D;&#39;utf-8&#39;) #训练集数据共有2888个样本(V0-V37共38个特征变量)  -- 有target字段</span><br><span class="line">test_data &#x3D; pd.read_csv(test_data_file, sep&#x3D;&#39;\t&#39;, encoding&#x3D;&#39;utf-8&#39;) #测试集数据共有1925个样本(V0-V37共有38个特征变量)  -- 无target字段</span><br><span class="line"></span><br><span class="line">#2.特征构造方法</span><br><span class="line">epsilon&#x3D;1e-5</span><br><span class="line">#组合交叉特征(自行定义) --增加x*x&#x2F;y log(x)&#x2F;y等</span><br><span class="line">function_dict &#x3D; &#123;</span><br><span class="line">            &#39;add&#39;: lambda x,y: x+y,    #加法</span><br><span class="line">            &#39;mins&#39;: lambda x,y: x-y,   #减法</span><br><span class="line">            &#39;div&#39;: lambda x,y: x&#x2F;(y+epsilon),  #除法</span><br><span class="line">            &#39;multi&#39;: lambda x,y: x*y  #乘法</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">#3.特征构造函数</span><br><span class="line">def auto_features_make(train_data,test_data,function_dict,col_list):  #传入训练集、测试集、特征构造方法、list集合</span><br><span class="line">    train_data,test_data&#x3D;train_data.copy(),test_data.copy()  #获取训练集和测试集</span><br><span class="line">    for i in col_list:</span><br><span class="line">        for j in col_list:</span><br><span class="line">            for function_name,function in function_dict.items(): #获取四个函数的函数名和函数</span><br><span class="line">                for data in [train_data,test_data]:  #从训练集和测试集获取数据</span><br><span class="line">                    function_features&#x3D;function(data[i],data[j])  # data[i]就是x data[j]就是y</span><br><span class="line">                    col_function_features&#x3D;&#39;-&#39;.join([i,function_name,j])</span><br><span class="line">                    data[col_function_features]&#x3D;function_features</span><br><span class="line">    return train_data,test_data</span><br><span class="line"></span><br><span class="line">#4.特征降维处理 --- 先构造新特征，然后使用PCA方法对特征进行降维处理</span><br><span class="line">train_data2,test_data2&#x3D;auto_features_make(train_data,test_data,function_dict,col_list&#x3D;test_data.columns)</span><br><span class="line">pca&#x3D;PCA(n_components&#x3D;500) # 整数表示保留几个特征 小数表示百分之多少的信息</span><br><span class="line">#获得转换器</span><br><span class="line">train_data2_pca&#x3D;pca.fit_transform(train_data2.iloc[:,0:-1])</span><br><span class="line">test_data2_pca&#x3D;pca.transform(test_data2)</span><br><span class="line">#转移为DF格式</span><br><span class="line">train_data2_pca&#x3D;pd.DataFrame(train_data2_pca)</span><br><span class="line">test_data2_pca&#x3D;pd.DataFrame(test_data2_pca)</span><br><span class="line">train_data2_pca[&#39;target&#39;]&#x3D;train_data2[&#39;target&#39;]  # PCA处理之后保留了16个主成分</span><br><span class="line">X_train2&#x3D;train_data2[test_data2.columns].values</span><br><span class="line">y_train&#x3D;train_data2[&#39;target&#39;]</span><br><span class="line"></span><br><span class="line">#5.使用LightGBM模型对新构造的特征进行模型训练和评估</span><br></pre></td></tr></table></figure>

<h1 id="模型融合"><a href="#模型融合" class="headerlink" title="模型融合"></a>模型融合</h1><h2 id="模型优化"><a href="#模型优化" class="headerlink" title="模型优化"></a>模型优化</h2><h3 id="模型学习曲线"><a href="#模型学习曲线" class="headerlink" title="模型学习曲线"></a>模型学习曲线</h3><p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.37.png" alt></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1.欠拟合(高偏差): 模型太简单(没能力学习到样本的底层规律) -- 训练集和测试集的准确率很低</span><br><span class="line">2.过拟合(高方差): 模型太复杂(学习太过) -- 训练集准确率较好 测试集的准确率很低(相差较大)</span><br><span class="line">3.正常拟合</span><br></pre></td></tr></table></figure>

<h3 id="模型融合提升技术"><a href="#模型融合提升技术" class="headerlink" title="模型融合提升技术"></a>模型融合提升技术</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1.概念:产生一组个体学习器 --根据某种策略 --&gt; 结合个体学习器，加强模型效果</span><br><span class="line">2.分类:</span><br><span class="line">  2.1 个体学习器之间不存在(×)强依赖关系 可以同时生成的并行化方法 --&gt; Bagging方法和随机森林</span><br><span class="line">  2.2 个体学习器之间存在(√)强依赖关系 必须串行的序列化方法 --&gt; Boosting方法</span><br></pre></td></tr></table></figure>

<h4 id="Bagging方法"><a href="#Bagging方法" class="headerlink" title="Bagging方法"></a>Bagging方法</h4><p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.38.png" alt></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1.概念:从训练集中抽样得到每个基模型所需要的子训练集 --&gt; 对所有基模型预测的结果进行综合，产生最终的预测结果</span><br><span class="line">2.Bagging方法采用 --&gt; 自助采样法(Bootstrap sampling)</span><br><span class="line">  2.1 m个样本的原始训练集,每次先随机采集一个样本放入采样集，然后将该样本放回</span><br><span class="line">  2.2 m个样本(随机采样),所以会得到m个样本的采样集(可以得到多个不同的弱学习器)</span><br></pre></td></tr></table></figure>

<h4 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1.概念:(对Bagging方法改进)</span><br><span class="line">2.改进之处:</span><br><span class="line">  2.1 基本学习器限定为决策树</span><br><span class="line">  2.2 决策树学习过程中引入了随机属性选择</span><br><span class="line">  2.3 对基决策树的每个结点，先从该结点的属性集合中随机选择一个包含k个属性的子集，然后从这个子集中选择一个最优属性进行划分(就是划分很多小块然后小块里面选个最优属性划分，然后慢慢更新)</span><br></pre></td></tr></table></figure>

<h4 id="Boosting方法"><a href="#Boosting方法" class="headerlink" title="Boosting方法"></a>Boosting方法</h4><p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.39.png" alt></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">1.概念:(阶梯状)基模型按照次序一一进行训练</span><br><span class="line">2.基模型的训练集按照某种策略进行一定的转换 --&gt; 所有基模型预测的结果进行线性综合,产生最终预测结果</span><br><span class="line">3.Boosting方法中著名的算法</span><br><span class="line">  3.1 AdaBoost算法 :加法模型、损失函数为指数函数、学习算法为前向分布算法</span><br><span class="line">  3.2 提升树(Boosting Tree) : 加法模型、基本学习器为决策树、学习算法为前向分布算法 的二分类算法</span><br><span class="line">	3.2.1 对于二分类问题: 损失函数为指数函数 </span><br><span class="line">    3.2.2 对于回归问题:  损失函数为平方误差</span><br><span class="line">  3.3 梯度提升树 : (对提升树算法的改进) 可以将损失函数的负梯度在当前模型的值 &lt;--&gt; 残差的近似值</span><br></pre></td></tr></table></figure>

<h3 id="预测结果融合策略"><a href="#预测结果融合策略" class="headerlink" title="预测结果融合策略"></a>预测结果融合策略</h3><p><strong>Stacking示意:</strong></p>
<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.40.png" alt></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">1.Voting(投票机制): 采用少数服从多数的原则</span><br><span class="line"> 1.1 硬投票:对多个模型直接进行投票，投票数最多的类 --&gt; 最终被预测的类</span><br><span class="line">	 1.2 软投票:不同模型设置不同权重，对多个模型直接进行投票，投票数最多的类 --&gt; 最终被预测的类</span><br><span class="line">2.Averaging:将模型结果的平均值 --&gt; 最终的预测值(不同回归方法预测结果波动幅度相差比较大)</span><br><span class="line">3.Ranking:排名平均的方法(如果有权重，就求出n个模型权重比排名之和)</span><br><span class="line">4.Blending:</span><br><span class="line"> 4.1 先将原始的训练集分为两个部分(训练集 -&gt; 训练集+测试集)</span><br><span class="line"> 4.2 在第一层中,用70%的数据训练多个模型，然后去预测剩余30%数据的label</span><br><span class="line"> 4.3 在第二层中,用30%的数据在第一层预测的结果作为新特征继续训练即可</span><br><span class="line">5.Stacking: 用训练好的所有基模型对训练集进行预测</span><br><span class="line">    5.1 第j个基模型对第i个训练样本的预测值作为新的训练集中第i个样本的第j个特征值(最后基于新的训练集进行训练)</span><br><span class="line">    5.2 同理，预测的过程也要先经过所有基模型的预测形成新的测试集，最后对测试集进行测试	</span><br><span class="line"> 5.3 Stacking是一种分层模型集成框架 -- 第一层由多个基学习器组成(输入为原始训练集) 第二层由第一层基学习器的输出作为训练集进行训练</span><br></pre></td></tr></table></figure>

<h1 id="最终导包汇总"><a href="#最终导包汇总" class="headerlink" title="最终导包汇总"></a>最终导包汇总</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import seaborn as sns</span><br><span class="line">from sklearn import preprocessing</span><br><span class="line">from sklearn.preprocessing import MinMaxScaler  #归一化</span><br><span class="line">from scipy import stats</span><br><span class="line">from sklearn.decomposition import PCA  #PCA主成分降维</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.linear_model import LinearRegression  #线性回归</span><br><span class="line">from sklearn.neighbors import KNeighborsRegressor  #K近邻回归</span><br><span class="line">from sklearn.tree import DecisionTreeRegressor     #决策树回归</span><br><span class="line">from sklearn.ensemble import RandomForestRegressor #随机森林回归</span><br><span class="line">from sklearn.svm import SVR  # 支持向量回归</span><br><span class="line">import lightgbm as lgb # LightGBM模型</span><br><span class="line">from sklearn.model_selection import train_test_split # 切分数据</span><br><span class="line">from sklearn.metrics import mean_squared_error #均方误差</span><br><span class="line">from sklearn.metrics import mean_absolute_error #平均绝对值误差</span><br><span class="line">from math import sqrt #平方根</span><br><span class="line">from sklearn.metrics import r2_score #R平方值</span><br><span class="line">from sklearn.model_selection import learning_curve</span><br><span class="line">from sklearn.model_selection import ShuffleSplit</span><br><span class="line">from sklearn.pipeline import Pipeline  #管道</span><br><span class="line">from sklearn.preprocessing import PolynomialFeatures  #多项式转变</span><br><span class="line">from sklearn.preprocessing import StandardScaler #标准化</span><br><span class="line">from sklearn.linear_model import SGDRegressor  #随机递推下降</span><br><span class="line">from sklearn.model_selection import KFold #KFold是K折交叉验证</span><br><span class="line">from sklearn.model_selection import LeaveOneOut #留一法</span><br><span class="line">from sklearn.model_selection import LeavePOut #留P法</span><br><span class="line">from sklearn.model_selection import GridSearchCV #网格搜索</span><br><span class="line">from sklearn.model_selection import RandomizedSearchCV</span><br></pre></td></tr></table></figure>
      
      
        <div class="page-reward">
          <p><a href="javascript:void(0)" onclick="dashangToggle()" class="dashang">赏</a></p>
          <div class="hide_box"></div>
          <div class="shang_box">
            <a class="shang_close" href="javascript:void(0)" onclick="dashangToggle()">×</a>
            <div class="shang_tit">
              <p>纯属好玩</p>
            </div>
            <div class="shang_payimg">
              <img src="/img/alipayimg.jpg" alt="扫码支持" title="扫一扫" />
            </div>
              <div class="pay_explain">扫码打赏，你说多少就多少</div>
            <div class="shang_payselect">
              
                <div class="pay_item checked" data-id="alipay">
                  <span class="radiobox"></span>
                  <span class="pay_logo"><img src="/img/alipay.png" alt="支付宝" /></span>
                </div>
              
              
                <div class="pay_item" data-id="wechat">
                  <span class="radiobox"></span>
                  <span class="pay_logo"><img src="/img/weixin.png" alt="微信" /></span>
                </div>
              
            </div>
            <div class="shang_info">
              <p>打开<span id="shang_pay_txt">支付宝</span>扫一扫，即可进行扫码打赏哦</p>
            </div>
          </div>
        </div>
        <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/zepto/1.2.0/zepto.min.js"></script>
        <script type="text/javascript">
          $(".pay_item").click(function(){
            $(this).addClass('checked').siblings('.pay_item').removeClass('checked');
            var dataid=$(this).attr('data-id');
            $(".shang_payimg img").attr("src","/img/"+dataid+"img.jpg");
            $("#shang_pay_txt").text(dataid=="alipay"?"支付宝":"微信");
          });
          function dashangToggle(){
            
            $(".hide_box").fadeToggle();
            $(".shang_box").fadeToggle();
          }
        </script>
      
    </div>
    
  </div>
  
    
    <div class="copyright">
        <p><span>本文标题:</span><a href="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/">机器学习实战之工业蒸汽</a></p>
        <p><span>文章作者:</span><a href="/" title="访问 Larkkkkkkk 的个人博客">Larkkkkkkk</a></p>
        <p><span>发布时间:</span>2022年09月27日 - 20时44分</p>
        <p><span>最后更新:</span>2022年10月25日 - 11时28分</p>
        <p>
            <span>原始链接:</span><a class="post-url" href="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/" title="机器学习实战之工业蒸汽">https://larkkkkkkk.github.io/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/</a>
            <span class="copy-path" data-clipboard-text="原文: https://larkkkkkkk.github.io/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/　　作者: Larkkkkkkk" title="点击复制文章链接"><i class="fa fa-clipboard"></i></span>
            <script src="/js/clipboard.min.js"></script>
            <script> var clipboard = new Clipboard('.copy-path'); </script>
        </p>
        <p>
            <span>许可协议:</span><i class="fa fa-creative-commons"></i> <a rel="license noopener" href="http://creativecommons.org/licenses/by-nc-sa/3.0/cn/" target="_blank" title="中国大陆 (CC BY-NC-SA 3.0 CN)" target = "_blank">"署名-非商用-相同方式共享 3.0"</a> 转载请保留原文链接及作者。
        </p>
    </div>



<nav id="article-nav">
  
    <a href="/2022/10/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption"><</strong>
      <div class="article-nav-title">
        
          深度学习
        
      </div>
    </a>
  
  
    <a href="/2022/09/17/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">统计学习方法</div>
      <strong class="article-nav-caption">></strong>
    </a>
  
</nav>

  
</article>

    <div id="toc" class="toc-article">
    <strong class="toc-title">文章目录</strong>
    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#题目基本情况"><span class="toc-number">1.</span> <span class="toc-text">题目基本情况</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#数据集"><span class="toc-number">1.1.</span> <span class="toc-text">数据集</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#数据探索"><span class="toc-number">2.</span> <span class="toc-text">数据探索</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#理论知识"><span class="toc-number">2.1.</span> <span class="toc-text">理论知识</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#赛题数据探索"><span class="toc-number">2.2.</span> <span class="toc-text">赛题数据探索</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#导入工具包"><span class="toc-number">2.2.1.</span> <span class="toc-text">导入工具包</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#可视化数据分布"><span class="toc-number">2.2.2.</span> <span class="toc-text">可视化数据分布</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#箱型图-boxplot"><span class="toc-number">2.2.2.1.</span> <span class="toc-text">箱型图(boxplot)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#直方图-distplot-和Q-Q图-probplot"><span class="toc-number">2.2.2.2.</span> <span class="toc-text">直方图(distplot)和Q-Q图(probplot)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#KDE分布图-核密度估计kdeplot"><span class="toc-number">2.2.2.3.</span> <span class="toc-text">KDE分布图(核密度估计kdeplot)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#线性回归关系图-regplot"><span class="toc-number">2.2.2.4.</span> <span class="toc-text">线性回归关系图(regplot)</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#查看特征变量的相关性"><span class="toc-number">2.2.3.</span> <span class="toc-text">查看特征变量的相关性</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#计算相关性系数-data-corr"><span class="toc-number">2.2.3.1.</span> <span class="toc-text">计算相关性系数(data.corr)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#相关热力图-sns-heatmap"><span class="toc-number">2.2.3.2.</span> <span class="toc-text">相关热力图(sns.heatmap)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#根据相关系数筛选特征变量-相关性选择-树模型"><span class="toc-number">2.2.3.3.</span> <span class="toc-text">根据相关系数筛选特征变量(相关性选择&#x2F;树模型)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Box-Cox变换"><span class="toc-number">2.2.3.4.</span> <span class="toc-text">Box-Cox变换</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#特征工程"><span class="toc-number">3.</span> <span class="toc-text">特征工程</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#特征工程的重要性和处理"><span class="toc-number">3.1.</span> <span class="toc-text">特征工程的重要性和处理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#数据预处理和特征处理"><span class="toc-number">3.2.</span> <span class="toc-text">数据预处理和特征处理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#数据预处理-数据采集-数据清洗-数据采样"><span class="toc-number">3.2.1.</span> <span class="toc-text">数据预处理(数据采集+数据清洗+数据采样)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#数据采集"><span class="toc-number">3.2.1.1.</span> <span class="toc-text">数据采集</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#数据清洗"><span class="toc-number">3.2.1.2.</span> <span class="toc-text">数据清洗</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#数据采样"><span class="toc-number">3.2.1.3.</span> <span class="toc-text">数据采样</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#特征处理"><span class="toc-number">3.2.2.</span> <span class="toc-text">特征处理</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#标准化-StandardScaler类"><span class="toc-number">3.2.2.1.</span> <span class="toc-text">标准化(StandardScaler类)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#区间缩放法-MinMaxScaler类"><span class="toc-number">3.2.2.2.</span> <span class="toc-text">区间缩放法(MinMaxScaler类)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#归一化-Normalizer类"><span class="toc-number">3.2.2.3.</span> <span class="toc-text">归一化(Normalizer类)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#定量特征二值化-Binarizer类"><span class="toc-number">3.2.2.4.</span> <span class="toc-text">定量特征二值化(Binarizer类)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#定性特征哑编码-OneHotEncoder类"><span class="toc-number">3.2.2.5.</span> <span class="toc-text">定性特征哑编码(OneHotEncoder类)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#缺失值处理-impute库的SimpleImputer类"><span class="toc-number">3.2.2.6.</span> <span class="toc-text">缺失值处理(impute库的SimpleImputer类)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#数据转换"><span class="toc-number">3.2.2.7.</span> <span class="toc-text">数据转换</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#特征降维"><span class="toc-number">3.3.</span> <span class="toc-text">特征降维</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#特征选择"><span class="toc-number">3.3.1.</span> <span class="toc-text">特征选择</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#线性降维"><span class="toc-number">3.3.2.</span> <span class="toc-text">线性降维</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#赛题特征工程"><span class="toc-number">3.4.</span> <span class="toc-text">赛题特征工程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#异常值分析-箱线图找出异常删除异常"><span class="toc-number">3.4.1.</span> <span class="toc-text">异常值分析(箱线图找出异常删除异常)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#归一化-最大值和最小值"><span class="toc-number">3.4.2.</span> <span class="toc-text">归一化(最大值和最小值)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#查看数据分布-KDE差异较大删除特征"><span class="toc-number">3.4.3.</span> <span class="toc-text">查看数据分布(KDE差异较大删除特征)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#特征相关性-用热力图可视化"><span class="toc-number">3.4.4.</span> <span class="toc-text">特征相关性(用热力图可视化)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#特征降维-1"><span class="toc-number">3.4.5.</span> <span class="toc-text">特征降维</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#多重共线性分析-statsmodels-stats-outliers-influence-variance-inflation-factor"><span class="toc-number">3.4.6.</span> <span class="toc-text">多重共线性分析(statsmodels.stats.outliers_influence.variance_inflation_factor)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#PCA处理-去除数据的多重共线性-并进行降维"><span class="toc-number">3.4.7.</span> <span class="toc-text">PCA处理(去除数据的多重共线性,并进行降维)</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#模型训练"><span class="toc-number">4.</span> <span class="toc-text">模型训练</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#回归和相关模型"><span class="toc-number">4.1.</span> <span class="toc-text">回归和相关模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#赛题模型训练"><span class="toc-number">4.2.</span> <span class="toc-text">赛题模型训练</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#模型验证"><span class="toc-number">5.</span> <span class="toc-text">模型验证</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#模型评估的概念和方法"><span class="toc-number">5.1.</span> <span class="toc-text">模型评估的概念和方法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#欠拟合和过拟合"><span class="toc-number">5.1.1.</span> <span class="toc-text">欠拟合和过拟合</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#模型的泛化与正则化"><span class="toc-number">5.1.2.</span> <span class="toc-text">模型的泛化与正则化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#回归模型的评估指标和调用方法"><span class="toc-number">5.1.3.</span> <span class="toc-text">回归模型的评估指标和调用方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#交叉验证"><span class="toc-number">5.1.4.</span> <span class="toc-text">交叉验证</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#模型调参"><span class="toc-number">5.2.</span> <span class="toc-text">模型调参</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#调参的概念"><span class="toc-number">5.2.1.</span> <span class="toc-text">调参的概念</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#参数的影响"><span class="toc-number">5.2.2.</span> <span class="toc-text">参数的影响</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#网格搜索-Grid-Search"><span class="toc-number">5.2.3.</span> <span class="toc-text">网格搜索(Grid Search)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#学习曲线"><span class="toc-number">5.2.4.</span> <span class="toc-text">学习曲线</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#验证曲线"><span class="toc-number">5.2.5.</span> <span class="toc-text">验证曲线</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#赛题模型验证和调参"><span class="toc-number">5.3.</span> <span class="toc-text">赛题模型验证和调参</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#模型过拟合与欠拟合"><span class="toc-number">5.3.1.</span> <span class="toc-text">模型过拟合与欠拟合</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#模型正则化"><span class="toc-number">5.3.2.</span> <span class="toc-text">模型正则化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#模型交叉验证-四种"><span class="toc-number">5.3.3.</span> <span class="toc-text">模型交叉验证(四种)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#模型超参空间及调参"><span class="toc-number">5.3.4.</span> <span class="toc-text">模型超参空间及调参</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#特征优化"><span class="toc-number">6.</span> <span class="toc-text">特征优化</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#特征优化的方法"><span class="toc-number">6.1.</span> <span class="toc-text">特征优化的方法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#赛题特征优化"><span class="toc-number">6.2.</span> <span class="toc-text">赛题特征优化</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#模型融合"><span class="toc-number">7.</span> <span class="toc-text">模型融合</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#模型优化"><span class="toc-number">7.1.</span> <span class="toc-text">模型优化</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#模型学习曲线"><span class="toc-number">7.1.1.</span> <span class="toc-text">模型学习曲线</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#模型融合提升技术"><span class="toc-number">7.1.2.</span> <span class="toc-text">模型融合提升技术</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Bagging方法"><span class="toc-number">7.1.2.1.</span> <span class="toc-text">Bagging方法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#随机森林"><span class="toc-number">7.1.2.2.</span> <span class="toc-text">随机森林</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Boosting方法"><span class="toc-number">7.1.2.3.</span> <span class="toc-text">Boosting方法</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#预测结果融合策略"><span class="toc-number">7.1.3.</span> <span class="toc-text">预测结果融合策略</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#最终导包汇总"><span class="toc-number">8.</span> <span class="toc-text">最终导包汇总</span></a></li></ol>
</div>
<input type="button" id="tocButton" value="隐藏目录"  title="点击按钮隐藏或者显示文章目录">


<script src="https://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js"></script>

<script>
    var valueHide = "隐藏目录";
    var valueShow = "显示目录";

    if ($(".left-col").is(":hidden")) {
        $("#tocButton").attr("value", valueShow);
    }
    $("#tocButton").click(function() {
        if ($("#toc").is(":hidden")) {
            $("#tocButton").attr("value", valueHide);
            $("#toc").slideDown(320);
        }
        else {
            $("#tocButton").attr("value", valueShow);
            $("#toc").slideUp(350);
        }
    })
    if ($(".toc").length < 1) {
        $("#toc, #tocButton").hide();
    }
</script>





<div class="bdsharebuttonbox">
	<a href="#" class="fx fa-weibo bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a>
	<a href="#" class="fx fa-weixin bds_weixin" data-cmd="weixin" title="分享到微信"></a>
	<a href="#" class="fx fa-qq bds_sqq" data-cmd="sqq" title="分享到QQ好友"></a>
	<a href="#" class="fx fa-facebook-official bds_fbook" data-cmd="fbook" title="分享到Facebook"></a>
	<a href="#" class="fx fa-twitter bds_twi" data-cmd="twi" title="分享到Twitter"></a>
	<a href="#" class="fx fa-linkedin bds_linkedin" data-cmd="linkedin" title="分享到linkedin"></a>
	<a href="#" class="fx fa-files-o bds_copy" data-cmd="copy" title="分享到复制网址"></a>
</div>
<script>window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"2","bdSize":"24"},"share":{}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];</script>




    
        <section id="comments">
  <div id="disqus_thread"></div>
    <script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'swing'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" target="_blank" rel="noopener">comments powered by Disqus.</a></noscript>
</section>
    



    <div class="scroll" id="post-nav-button">
        
            <a href="/2022/10/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" title="上一篇: 深度学习">
                <i class="fa fa-angle-left"></i>
            </a>
        
        <a title="文章列表"><i class="fa fa-bars"></i><i class="fa fa-times"></i></a>
        
            <a href="/2022/09/17/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/" title="下一篇: 统计学习方法">
                <i class="fa fa-angle-right"></i>
            </a>
        
    </div>
    <ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2024/05/28/%E5%BE%AE%E6%9C%8D%E5%8A%A1-%E9%BB%91%E9%A9%AC%E5%95%86%E5%9F%8E%E4%B8%BA%E4%BE%8B/">微服务-黑马商城为例</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/05/28/Hexo%E5%8D%9A%E5%AE%A2%E6%8A%A5%E9%94%99github%E4%BC%A0%E8%BE%93%E5%A4%A7%E6%96%87%E4%BB%B6GH001%E5%BC%82%E5%B8%B8/">Hexo博客报错github传输大文件GH001异常</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/05/27/%E5%BE%AE%E6%9C%8D%E5%8A%A1-%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/">微服务-分布式事务</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/05/27/%E5%BE%AE%E6%9C%8D%E5%8A%A1-%E6%9C%8D%E5%8A%A1%E4%BF%9D%E6%8A%A4/">微服务-服务保护</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/04/25/MybatisPlus/">MybatisPlus</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/04/17/Elasticsearch/">Elasticsearch</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/04/01/Zookeeper/">Zookeeper</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/03/18/RabbitMQ-0/">RabbitMQ</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/03/15/SpringCloud/">SpringCloud</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/02/02/JUC/">JUC</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/01/09/Apache-Echarts/">Apache-Echarts</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/01/06/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E5%BC%80%E5%8F%91/">微信小程序开发</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/01/05/%E5%85%AB%E8%82%A1%E6%96%87%E6%95%B4%E7%90%86/">八股文整理</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/01/02/Springboot-takeout/">Springboot-takeout</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/12/24/JAVAWeb-tlias%E6%99%BA%E8%83%BD%E5%AD%A6%E4%B9%A0%E8%BE%85%E5%8A%A9%E7%B3%BB%E7%BB%9F/">JAVAWeb-tlias智能学习辅助系统</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/12/23/Mybatis/">Mybatis</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/12/22/SpringBootWeb%E8%AF%B7%E6%B1%82/">SpringBootWeb请求</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/11/10/%E5%9B%BE%E8%A7%A3HTTP/">图解HTTP</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/11/06/JAVA-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/">JAVA-数据结构与算法</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/11/03/JAVA-%E5%8F%8D%E5%B0%84/">JAVA-反射</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/11/02/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/">计算机网络</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/11/02/JAVA-%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/">JAVA-网络编程</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/10/31/JAVA-File%E7%B1%BB%E5%92%8CIO%E6%B5%81/">JAVA-File类和IO流</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/10/30/JAVA-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E9%9B%86%E5%90%88%E6%BA%90%E7%A0%81/">JAVA-数据结构与集合源码</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/10/28/JAVA-%E6%B3%9B%E5%9E%8B/">JAVA-泛型</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/10/24/JAVA-%E9%9B%86%E5%90%88%E6%A1%86%E6%9E%B6/">JAVA-集合框架</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/10/21/picgo/">picgo</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/10/20/JAVA-%E4%BB%A3%E7%A0%81%E9%9A%8F%E6%83%B3%E5%BD%95/">JAVA-代码随想录</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/10/20/JAVA-%E5%B8%B8%E7%94%A8%E7%B1%BB%E5%92%8C%E5%9F%BA%E7%A1%80API/">JAVA-常用类和基础API</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/10/20/JAVA-%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/">JAVA-异常处理</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/10/20/JAVA-%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/">JAVA-面向对象</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/10/20/JAVA-%E5%9F%BA%E7%A1%80%E7%AF%87/">JAVA-基础篇</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/09/19/%E5%B0%9A%E7%A1%85%E8%B0%B7java/">尚硅谷JAVA基础</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/07/18/pytorch%E5%B0%8F%E5%9C%9F%E5%A0%86/">pytorch小土堆</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/06/04/python%E6%89%93%E5%8C%85/">python打包</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/25/pytorch/">pytorch</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/23/django/">django</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/22/flask%E6%8E%A5%E5%8F%A3/">flask接口</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/22/Docker/">Docker</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/22/JQ%E5%AE%9E%E7%8E%B0%E8%A1%A8%E5%8D%95%E6%A0%A1%E9%AA%8C/style/">JQ实现表单校验/style</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/22/JQ%E5%AE%9E%E7%8E%B0%E8%A1%A8%E5%8D%95%E6%A0%A1%E9%AA%8C/jquery-1.11.0/">JQ实现表单校验/jquery-1.11.0</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/22/JQ%E5%AE%9E%E7%8E%B0%E8%80%81%E9%BB%84%E5%8E%86/style/">JQ实现老黄历/style</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/22/JQ%E5%AE%9E%E7%8E%B0%E8%80%81%E9%BB%84%E5%8E%86/laohuangli/">JQ实现老黄历/laohuangli</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/22/JQ%E5%AE%9E%E7%8E%B0%E8%80%81%E9%BB%84%E5%8E%86/jquery-1.11.0/">JQ实现老黄历/jquery-1.11.0</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/22/JQ%E5%AE%9E%E7%8E%B0%E8%80%81%E9%BB%84%E5%8E%86/data/">JQ实现老黄历/data</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/22/JQuery%E9%80%89%E6%8B%A9%E5%99%A8/style/">JQuery选择器/style</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/22/JQuery%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/jquery-1.11.3.min/">JQuery基本用法/jquery-1.11.3.min</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/22/JQuery/jquery-1.11.0/">JQuery/jquery-1.11.0</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/22/Bootstrap/bootstrap-3.3.5-dist/js/npm/">Bootstrap/bootstrap-3.3.5-dist/js/npm</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/22/Bootstrap/bootstrap-3.3.5-dist/js/bootstrap.min/">Bootstrap/bootstrap-3.3.5-dist/js/bootstrap.min</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/22/Bootstrap/bootstrap-3.3.5-dist/js/bootstrap/">Bootstrap/bootstrap-3.3.5-dist/js/bootstrap</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/22/Bootstrap/bootstrap-3.3.5-dist/css/bootstrap.min/">Bootstrap/bootstrap-3.3.5-dist/css/bootstrap.min</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/22/Bootstrap/bootstrap-3.3.5-dist/css/bootstrap/">Bootstrap/bootstrap-3.3.5-dist/css/bootstrap</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/22/Bootstrap/bootstrap-3.3.5-dist/css/bootstrap-theme.min/">Bootstrap/bootstrap-3.3.5-dist/css/bootstrap-theme.min</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/22/Bootstrap/bootstrap-3.3.5-dist/css/bootstrap-theme/">Bootstrap/bootstrap-3.3.5-dist/css/bootstrap-theme</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/05/22/Larkkkkkkk/">Larkkkkkkk</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/04/17/py2neo/">py2neo</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/04/17/neo4j/">neo4j</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/04/16/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/">知识图谱</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/11/22/%E5%90%8E%E7%BC%80%E6%A0%91/">后缀树</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/11/11/%E7%94%9F%E7%89%A9%E4%BF%A1%E6%81%AF%E5%AD%A6/">生物信息学</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/11/02/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">动手学深度学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/11/01/Scrapy%E7%88%AC%E8%99%AB%E8%BF%9B%E9%98%B6/">Scrapy爬虫进阶</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/10/28/%E7%88%AC%E8%99%AB/">爬虫基础</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/10/26/%E7%AE%97%E6%B3%95%E6%B1%87%E6%80%BB%EF%BC%88Python%EF%BC%89/">算法汇总（Python）</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/10/15/CS224n%E6%96%AF%E5%9D%A6%E7%A6%8F%E6%B7%B1%E5%BA%A6%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E8%AF%BE/">CS224n斯坦福深度自然语言处理课</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/10/11/%E8%BD%AF%E4%BB%B6%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/">软件体系结构</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/10/10/%E5%8F%8C%E7%A2%B3%E5%A4%A7%E8%B5%9B-%E5%9E%83%E5%9C%BE%E5%88%86%E7%B1%BB/">双碳大赛-垃圾分类</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/10/07/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5/">PyTorch深度学习实践</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/10/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/">机器学习实战之工业蒸汽</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/09/17/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/">统计学习方法</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/09/06/%E5%88%A9%E7%94%A8python%E8%BF%9B%E8%A1%8C%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/">利用python进行数据分析</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/04/07/python%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E5%AE%9E%E8%B7%B5%E8%AF%BE%E6%9C%AC%E8%AF%BE%E5%90%8E%E9%A2%98/">python从入门到实践课本课后题</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/12/31/python/">python</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/06/28/B%E5%86%8C%E7%BC%96%E7%A8%8B%E9%A2%98/">B册编程题</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/06/23/c%E8%AF%AD%E8%A8%80%E8%AF%BE%E6%9C%AC%E9%A2%98%E7%9B%AE/">c语言课本题目</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/04/07/%E5%88%9D%E8%AF%95code/">初试code</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/25/%E7%A2%8E%E7%A2%8E%E5%BF%B5/">碎碎念</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/07/%E8%93%9D%E6%A1%A5%E6%9D%AF%E5%9B%BD%E8%B5%9B/">蓝桥杯国赛</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/10/23/Linux%E7%B3%BB%E7%BB%9F%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/">Linux系统目录结构</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/10/04/LeetCode%E9%93%BE%E8%A1%A8/">LeetCode链表</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/08/21/%E6%9C%AC%E5%9C%B0%E9%A1%B9%E7%9B%AE%E4%B8%8A%E4%BC%A0Github/">本地项目上传Github</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/08/13/JVM/">JVM</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/08/05/Mysql%E5%A4%8D%E4%B9%A0/">Mysql复习</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/08/02/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E6%80%BB%E7%BB%93/">设计模式总结</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/07/31/%E4%BA%AC%E4%B8%9C2019%E6%A0%A1%E6%8B%9B%E7%AC%94%E8%AF%95Java%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88%E7%AC%94%E8%AF%95%E9%A2%98/">京东2019校招笔试Java开发工程师笔试题</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/07/30/%E4%BA%AC%E4%B8%9C2019%E6%98%A5%E6%8B%9B%E4%BA%AC%E4%B8%9CJava%E5%BC%80%E5%8F%91%E8%AF%95%E5%8D%B7/">京东2019春招京东Java开发试卷</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/07/29/%E6%8B%BC%E5%A4%9A%E5%A4%9A2020%E6%A0%A1%E6%8B%9B%E9%83%A8%E5%88%86%E7%BC%96%E7%A8%8B%E9%A2%98%E5%90%88%E9%9B%86/">拼多多2020校招部分编程题合集</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/07/21/Git%E5%A4%8D%E4%B9%A0/">Git复习</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/07/16/leetcode%E5%89%91%E6%8C%87offer/">leetcode剑指offer</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/07/12/Hexo%E5%8D%9A%E5%AE%A2%E9%87%8D%E8%A3%85%E7%B3%BB%E7%BB%9F%E9%87%8D%E6%96%B0%E9%83%A8%E7%BD%B2/">Hexo博客重装系统重新部署</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/07/08/%E5%B0%9A%E5%AD%A6%E5%A0%82CRUD%E6%A8%A1%E6%9D%BF/">尚学堂CRUD模板</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/06/19/LeetCode%E7%B2%BE%E9%80%89TOP%E9%9D%A2%E8%AF%95%E9%A2%98/">LeetCode精选TOP面试题</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/06/16/LeetCode%E5%93%88%E5%B8%8C%E8%A1%A8/">LeetCode哈希表</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/06/16/LeetCode%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95/">LeetCode贪心算法</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/06/15/LeetCode%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/">LeetCode二分查找</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/06/14/LeetCode%E5%8F%8C%E6%8C%87%E9%92%88/">LeetCode双指针</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/06/13/LeetCode%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/">LeetCode动态规划</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/06/12/LeetCode%E6%95%B0%E5%AD%A6%E9%97%AE%E9%A2%98/">LeetCode数学问题</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/06/11/LeetCode%E9%80%92%E5%BD%92/">LeetCode递归</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/06/10/LeetCode%E6%8E%92%E5%BA%8F/">LeetCode排序</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/06/05/LeetCode%E5%AD%97%E7%AC%A6%E4%B8%B2/">LeetCode字符串</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/05/27/LeetCode%E6%95%B0%E7%BB%84/">LeetCode数组</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/05/11/%E5%89%91%E6%8C%87offer/">剑指offer</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/05/02/%E5%9B%BE/">图</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/05/01/%E5%93%88%E5%B8%8C%E8%A1%A8/">哈希表</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/22/%E5%93%88%E5%BC%97%E6%9B%BC%E6%A0%91/">哈弗曼树</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/18/%E4%BA%8C%E5%8F%89%E6%A0%91/">二叉树</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/18/%E6%A0%91/">树</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/15/%E6%8E%92%E5%BA%8F/">排序</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/15/%E6%97%B6%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%92%8C%E7%A9%BA%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%88%86%E6%9E%90/">时间复杂度和空间复杂度分析</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/14/%E9%80%92%E5%BD%92/">递归</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/12/SpringBoot/">SpringBoot</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/12/%E9%93%BE%E8%A1%A8/">链表</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/11/%E9%98%9F%E5%88%97/">队列</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/11/%E6%A0%88/">栈</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/11/SpringMVC%E5%AF%B9Date%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2/">SpringMVC对Date类型转换</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/11/SpringMVC%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/">SpringMVC原理分析</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/11/SpringMVC%E5%AE%9E%E7%8E%B0%E8%87%AA%E5%AE%9A%E4%B9%89%E6%8B%A6%E6%88%AA%E5%99%A8/">SpringMVC实现自定义拦截器</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/10/SpringMVC%E5%AE%9E%E7%8E%B0%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E5%92%8C%E4%B8%8B%E8%BD%BD/">SpringMVC实现文件上传和下载</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/09/JSP%E4%B9%9D%E5%A4%A7%E5%86%85%E7%BD%AE%E5%AF%B9%E8%B1%A1%E5%92%8C%E5%9B%9B%E5%A4%A7%E4%BD%9C%E7%94%A8%E5%9F%9F/">JSP九大内置对象和四大作用域</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/09/SpringMVC%E5%AE%9E%E7%8E%B0%E8%8F%9C%E5%8D%95%E5%8A%9F%E8%83%BD/">SpringMVC实现菜单功能</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/07/SpringMVC/">SpringMVC</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/06/Ajax%E6%95%B4%E7%90%86/">Ajax整理</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/06/Spring%E5%B8%B8%E7%94%A8%E6%B3%A8%E8%A7%A3%E6%95%B4%E7%90%86/">Spring常用注解整理</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/04/Spring%E4%BA%8B%E5%8A%A1/">Spring事务</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/04/Spring%E5%8D%95%E4%BE%8B%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/">Spring单例设计模式</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/04/Spring%E5%8A%A0%E8%BD%BD%E5%B1%9E%E6%80%A7%E6%96%87%E4%BB%B6%E5%92%8Cscope%E5%B1%9E%E6%80%A7/">Spring加载属性文件和scope属性</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/03/Spring%E8%87%AA%E5%8A%A8%E6%B3%A8%E5%85%A5/">Spring自动注入</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/03/Spring%E4%BB%A3%E7%90%86%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/">Spring代理设计模式</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/02/AOP/">AOP</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/01/Spring%E6%95%B4%E5%90%88Mybatis/">Spring整合Mybatis</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/01/Spring%E7%BB%99Bean%E6%B3%A8%E5%85%A5/">Spring给Bean注入</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/31/Spring/">Spring</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/31/Mybatis%E8%BF%90%E8%A1%8C%E5%8E%9F%E7%90%86%E6%80%BB%E7%BB%93/">Mybatis运行原理总结</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/30/Mybatis%E6%B3%A8%E8%A7%A3/">Mybatis注解</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/29/%E4%BD%BF%E7%94%A8Mybatis%E7%9A%84%E5%8A%A8%E6%80%81Sql%E5%AE%9E%E7%8E%B0%E5%A4%9A%E8%A1%A8%E6%9F%A5%E8%AF%A2/">使用Mybatis的动态Sql实现多表查询</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/28/Mybatis%E7%BC%93%E5%AD%98/">Mybatis缓存</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/28/ThreadLocal/">ThreadLocal</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/28/%E5%8A%A8%E6%80%81SQL/">动态SQL</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/27/getMapper%E6%8E%A5%E5%8F%A3%E7%BB%91%E5%AE%9A%E5%92%8C%E5%A4%9A%E5%8F%82%E6%95%B0%E4%BC%A0%E9%80%92/">getMapper接口绑定和多参数传递</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/25/Mybatis%E5%AE%9E%E7%8E%B0%E8%BD%AC%E8%B4%A6/">Mybatis实现转账</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/25/Mybatis%E5%AE%9E%E7%8E%B0%E5%88%86%E9%A1%B5%E5%8A%9F%E8%83%BD%EF%BC%88%E5%AE%8C%E6%95%B4%E6%B5%81%E7%A8%8B%EF%BC%89/">Mybatis实现分页功能（完整流程）</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/24/Mybatis%E5%AE%9E%E7%8E%B0%E6%96%B0%E5%A2%9E%E5%88%A0%E9%99%A4%E4%BF%AE%E6%94%B9%E5%92%8C%E4%BA%8B%E5%8A%A1%E8%AE%B2%E8%A7%A3/">Mybatis实现新增删除修改和事务讲解</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/24/Mybatis%E5%AE%9E%E7%8E%B0mysql%E5%88%86%E9%A1%B5/">Mybatis实现mysql分页</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/21/Mybatis%E6%9F%A5%E8%AF%A2%E6%89%80%E6%9C%89/">Mybatis查询所有</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/21/Log4J/">Log4J</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/20/Mybatis%E5%85%A8%E5%B1%80%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/">Mybatis全局配置文件详解</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/20/Mybatis%EF%BC%88eclipse%E8%AF%A6%E7%BB%86%EF%BC%89/">Mybatis（eclipse详细）</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/18/Mybatis%EF%BC%88idea+maven%EF%BC%89/">Mybatis（idea+maven）</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/17/Nginx/">Nginx</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/17/Linux%E9%83%A8%E7%BD%B2/">Linux部署</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/16/Linux%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86/">Linux网络知识</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/16/Vim/">Vim</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/14/maven/">maven</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/13/redis%E9%85%8D%E5%90%88ajax%E5%AE%9E%E7%8E%B0%E6%98%BE%E7%A4%BA%E4%B8%8B%E6%8B%89%E5%88%97%E8%A1%A8%E7%9C%81%E4%BB%BD/">redis配合ajax实现显示下拉列表省份</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/10/Linux%E5%AE%89%E8%A3%85%E8%BD%AF%E4%BB%B6/">Linux安装软件</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/10/%E8%B0%B7%E6%AD%8CCar%E5%BC%95%E5%85%A5%E8%A3%85%E9%A5%B0%E8%80%85%E6%A8%A1%E5%BC%8F/">谷歌Car引入装饰者模式</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/10/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/">设计模式</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/10/%E6%B3%A8%E8%A7%A3/">注解</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/08/%E8%87%AA%E5%8A%A8%E7%99%BB%E5%BD%95%EF%BC%88%E8%BF%87%E6%BB%A4%E5%99%A8%EF%BC%89/">自动登录（过滤器）</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/08/Filter/">Filter</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/07/JQuery%E7%9C%81%E5%B8%82%E8%81%94%E5%8A%A8/">JQuery省市联动</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/06/Listener/">Listener</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/06/JQuery%E4%BB%BF%E7%99%BE%E5%BA%A6%E6%90%9C%E7%B4%A2/">JQuery仿百度搜索</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/06/JQuery%E6%A0%A1%E9%AA%8C%E7%94%A8%E6%88%B7%E5%90%8D/">JQuery校验用户名</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/06/JQuery%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/">JQuery基本用法</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/05/Ajax%E5%AE%9E%E7%8E%B0%E6%A0%A1%E9%AA%8C%E7%94%A8%E6%88%B7%E5%90%8D/">Ajax实现校验用户名</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/04/Ajax/">Ajax</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/29/%E5%AD%A6%E7%94%9F%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%EF%BC%882-0%EF%BC%89/">学生管理系统（2.0）</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/29/%E4%B8%89%E5%B1%82%E6%9E%B6%E6%9E%84/">三层架构</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/29/JSP%E5%BC%80%E5%8F%91%E6%A8%A1%E5%BC%8F/">JSP开发模式</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/29/DBUtils%E9%80%9A%E7%94%A8%E7%9A%84%E5%A2%9E%E5%88%A0%E6%9F%A5%E6%94%B9/">DBUtils通用的增删查改</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/29/DBUtils/">DBUtils</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/28/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0/">数据库连接池</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/27/%E4%BA%8B%E5%8A%A1/">事务</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/27/%E5%AD%A6%E7%94%9F%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/">学生管理系统</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/26/JSTL/">JSTL</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/26/EL%E8%A1%A8%E8%BE%BE%E5%BC%8F/">EL表达式</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/25/JSP/">JSP</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/25/Session%E5%AE%9E%E7%8E%B0%E8%B4%AD%E7%89%A9%E8%BD%A6/">Session实现购物车</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/24/Cookie%E8%8E%B7%E5%8F%96%E5%95%86%E5%93%81%E6%B5%8F%E8%A7%88%E8%AE%B0%E5%BD%95/">Cookie获取商品浏览记录</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/24/Cookie%E8%8E%B7%E5%8F%96%E4%B8%8A%E6%AC%A1%E7%99%BB%E5%BD%95%E6%97%B6%E9%97%B4/">Cookie获取上次登录时间</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/23/Session/">Session</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/23/Cookie/">Cookie</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/19/Linux/">Linux</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/18/ServletContext/">ServletContext</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/18/HTTPServletReauest%E5%92%8CHTTPServletResponse/">HTTPServletReauest和HTTPServletResponse</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/17/Servlet/">Servlet</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/17/HTTP%E5%8D%8F%E8%AE%AE/">HTTP协议</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/16/Tomcat/">Tomcat</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/16/dom4j%E5%85%A5%E9%97%A8/">dom4j入门</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/15/XML/">XML</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/15/%E6%95%B0%E6%8D%AE%E5%BA%93cmd%E7%9A%84%E6%93%8D%E4%BD%9C%EF%BC%88%E4%BB%A5%E5%90%8E%E5%86%99%EF%BC%89/">数据库cmd的操作（以后写）</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/15/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E5%88%9B%E5%BB%BA%E6%9F%A5%E7%9C%8B%E5%88%A0%E9%99%A4/">数据库的创建查看删除</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/14/JDBC%E4%B8%AD%E7%9A%84JAVAEE%E7%BB%93%E6%9E%84/">JDBC中的JAVAEE结构</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/13/JDBC%E5%AF%B9%E4%BA%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84CRUD/">数据库的CRUD</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/12/%E6%95%B0%E6%8D%AE%E5%BA%93/">数据库</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/12/JDBC%E7%9A%84%E5%B7%A5%E5%85%B7%E7%B1%BB/">JDBC的工具类</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/12/JDBC/">JDBC</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/12/bootstrap%E5%AE%9E%E7%8E%B0%E7%BD%91%E7%AB%99%E9%A6%96%E9%A1%B5/">bootstrap实现网站首页</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/12/boostrap%E5%AE%9E%E7%8E%B0%E5%AF%BC%E8%88%AA%E6%9D%A1/">boostrap实现导航条</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/10/JQ%E5%AE%9E%E7%8E%B0%E8%80%81%E9%BB%84%E5%8E%86/">JQ实现老黄历</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/10/JQ%E5%AE%9E%E7%8E%B0%E8%A1%A8%E5%8D%95%E6%A0%A1%E9%AA%8C/">JQ实现表单校验</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/10/Bootstrap/">Bootstrap</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/09/JQ%E5%AE%9E%E7%8E%B0%E5%95%86%E5%93%81%E5%B7%A6%E5%8F%B3%E9%80%89%E6%8B%A9/">JQ实现商品左右选择</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/09/JQ%E5%AE%9E%E7%8E%B0%E7%9C%81%E5%B8%82%E8%81%94%E5%8A%A8/">JQ实现省市联动</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/09/JQ%E5%AE%9E%E7%8E%B0%E8%A1%A8%E6%A0%BC%E5%8F%98%E8%89%B2%E5%92%8C%E5%85%A8%E9%80%89%E9%97%AE%E9%A2%98/">JQ实现表格隔行换色</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/09/JQ%E5%AE%9E%E7%8E%B0%E8%A1%A8%E5%8D%95%E5%B1%9E%E6%80%A7%E8%BF%87%E6%BB%A4/">JQ实现表单属性过滤</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/08/JQuery%E9%80%89%E6%8B%A9%E5%99%A8/">JQuery选择器</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/08/JQuery%E5%AE%9E%E7%8E%B0%E5%AE%9A%E6%97%B6%E6%92%AD%E6%94%BE%E5%B9%BF%E5%91%8A/">JQuery实现定时播放广告</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/07/JQuery/">JQuery</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/07/JS%E6%8E%A7%E5%88%B6%E4%B8%8B%E6%8B%89%E5%88%97%E8%A1%A8%E5%B7%A6%E5%8F%B3%E9%80%89%E6%8B%A9/">JS控制下拉列表左右选择</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/07/JS%E5%AE%9E%E7%8E%B0%E8%A1%A8%E5%8D%95%E6%A3%80%E9%AA%8C%EF%BC%88%E4%BD%BF%E7%94%A8onfoucs%E7%AD%89%E7%84%A6%E7%82%B9%E6%97%B6%E9%97%B4%EF%BC%89/">JS实现表单检验（使用onfoucs等焦点时间）</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/07/JS%E5%AE%9E%E7%8E%B0%E8%A1%A8%E6%A0%BC%E5%8F%98%E8%89%B2%E5%92%8C%E5%85%A8%E9%80%89%E9%97%AE%E9%A2%98/">JS实现表格变色和全选问题</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/07/JS%E5%AE%9E%E7%8E%B0DOM%E6%93%8D%E4%BD%9C%EF%BC%88%E5%85%B3%E4%BA%8Eselect%E6%A0%87%E7%AD%BE%E7%9A%84%E4%B8%8B%E6%8B%89%E7%9C%81%E5%B8%82%E8%81%94%E5%8A%A8%EF%BC%89/">JS实现DOM操作（关于select标签的下拉省市联动）</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/05/JS%E5%AE%9E%E7%8E%B0%E8%87%AA%E5%8A%A8%E6%92%AD%E6%94%BE%E5%B9%BF%E5%91%8A/">JS实现页面表单表格</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/05/JS%E5%AE%9E%E7%8E%B0%E8%BD%AE%E6%92%AD%E5%9B%BE/">JS实现轮播图</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/04/JS/">JS</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/04/CSS%E7%BD%91%E7%AB%99%E6%B3%A8%E5%86%8C%E6%A1%88%E4%BE%8B/">CSS网站注册案例</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/04/CSS-div%E5%AE%9E%E7%8E%B0%E7%BD%91%E7%AB%99%E9%A6%96%E9%A1%B5%E4%BC%98%E5%8C%96/">CSS+div实现网站首页优化</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/02/CSS/">CSS和DIV</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/02/HTML%E7%BD%91%E7%AB%99%E5%90%8E%E5%8F%B0%E6%A1%88%E4%BE%8B/">网站后台案例</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/02/HTML%E7%BD%91%E7%AB%99%E6%B3%A8%E5%86%8C%E6%A1%88%E4%BE%8B/">网站注册案例</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/01/HTML%E7%BD%91%E7%AB%99%E9%A6%96%E9%A1%B5%E6%A1%88%E4%BE%8B/">HTML网站首页案例</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/01/HTML/">HTML</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/01/30/%E5%8F%8D%E5%B0%84/">反射</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/01/28/%E7%A8%80%E7%96%8F%E6%95%B0%E7%BB%84/">稀疏数组</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/12/30/%E7%BD%91%E7%BB%9C%E8%AF%BE%E8%AE%BE/">网络课设</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/12/19/webserver/">webserver</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/25/TCP/">TCP编程</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/17/%E4%BC%A0%E8%BE%93%E5%8D%8F%E8%AE%AE/">传输协议(UDP)</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/13/%E7%AC%AC%E5%8D%81%E5%B1%8A%E8%93%9D%E6%A1%A5%E6%9D%AF%E7%9C%81%E8%B5%9B/">第十届蓝桥杯省赛</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/12/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/">网络编程</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/11/%E7%AD%89%E5%BE%85%E5%94%A4%E9%86%92%E6%9C%BA%E5%88%B6/">等待唤醒机制</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/07/%E8%93%9D%E6%A1%A5%E6%9D%AF%E6%A0%A1%E8%B5%9B/">蓝桥杯校赛</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/07/%E7%BA%BF%E7%A8%8B%E7%8A%B6%E6%80%81/">线程状态</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/05/%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8/">线程安全</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/04/JAVA-%E5%A4%9A%E7%BA%BF%E7%A8%8B/">JAVA-多线程</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/02/List/">List接口</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/02/Set/">Set集合</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/31/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/">正则表达式(regex)</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/29/%E8%BF%AD%E4%BB%A3%E5%99%A8/">集合2</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/29/%E6%B3%9B%E5%9E%8B/">泛型</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/26/%E8%93%9D%E6%A1%A5%E6%9D%AF%E7%BB%83%E4%B9%A0/">蓝桥杯</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/26/%E9%9B%86%E5%90%88/">集合1</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/24/Lambda/">Lambda表达式</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/23/%E9%A1%B5%E9%9D%A2/">人机交互实验</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/17/%E5%9B%9E%E6%BA%AF%E6%B3%95/">回溯算法</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/15/%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95/">贪心算法</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/11/%E7%88%AC%E6%A5%BC%E6%A2%AF/">以爬楼梯为例</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/11/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/">动态规划</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/08/idea%E5%AE%89%E8%A3%85/">IntelliJ IDEA</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/08/%E6%8E%A5%E9%9B%A8%E6%B0%B4(%E5%8F%8C%E6%8C%87%E9%92%88)/">接雨水</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/08/%E4%B9%98%E6%9B%B4%E5%A4%9A%E7%9A%84%E6%B0%B4(%E5%8F%8C%E6%8C%87%E9%92%88)/">乘更多的水</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/04/wenzipian2/">文字篇2-《码农翻身》</a></li></ul>
    <script src="https://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js"></script>
    <script>
        $(".post-list").addClass("toc-article");
        $(".post-list-item a").attr("target","_blank");
        $("#post-nav-button > a:nth-child(2)").click(function() {
            $(".fa-bars, .fa-times").toggle();
            $(".post-list").toggle(300);
            if ($(".toc").length > 0) {
                $("#toc, #tocButton").toggle(200, function() {
                    if ($(".switch-area").is(":visible")) {
                        $("#tocButton").attr("value", valueHide);
                        }
                    })
            }
            else {
            }
        })
    </script>



    <script>
        
    </script>
</div>
      <footer id="footer">
    <div class="outer">
        <div id="footer-info">
            <div class="footer-left">
                &copy; 2024 Larkkkkkkk
            </div>
            <div class="footer-right">
                <a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="http://bestwing.me" target="_blank">Sw'blog</a> by Swing
            </div>
        </div>
        
            <div class="visit">
                
                    <span id="busuanzi_container_site_pv" style='display:none'>
                        <span id="site-visit" >海贼到访数: 
                            <span id="busuanzi_value_site_uv"></span>
                        </span>
                    </span>
                
                
                    <span>, </span>
                
                
                    <span id="busuanzi_container_page_pv" style='display:none'>
                        <span id="page-visit">本页阅读量: 
                            <span id="busuanzi_value_page_pv"></span>
                        </span>
                    </span>
                
            </div>
        
    </div>
</footer>

    </div>
    
<script src="https://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js"></script>


<script src="/js/main.js"></script>


    <script>
        $(document).ready(function() {
            var backgroundnum = 24;
            var backgroundimg = "url(/background/bg-x.jpg)".replace(/x/gi, Math.ceil(Math.random() * backgroundnum));
            $("#mobile-nav").css({"background-image": backgroundimg,"background-size": "cover","background-position": "center"});
            $(".left-col").css({"background-image": backgroundimg,"background-size": "cover","background-position": "center"});
        })
    </script>





<div class="scroll" id="scroll">
    <a href="#"><i class="fa fa-arrow-up"></i></a>
    <a href="#comments"><i class="fa fa-comments-o"></i></a>
    <a href="#footer"><i class="fa fa-arrow-down"></i></a>
</div>
<script>
    $(document).ready(function() {
        if ($("#comments").length < 1) {
            $("#scroll > a:nth-child(2)").hide();
        };
    })
</script>

<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>

  <script language="javascript">
    $(function() {
        $("a[title]").each(function() {
            var a = $(this);
            var title = a.attr('title');
            if (title == undefined || title == "") return;
            a.data('title', title).removeAttr('title').hover(

            function() {
                var offset = a.offset();
                $("<div id=\"anchortitlecontainer\"></div>").appendTo($("body")).html(title).css({
                    top: offset.top - a.outerHeight() - 15,
                    left: offset.left + a.outerWidth()/2 + 1
                }).fadeIn(function() {
                    var pop = $(this);
                    setTimeout(function() {
                        pop.remove();
                    }, pop.text().length * 800);
                });
            }, function() {
                $("#anchortitlecontainer").remove();
            });
        });
    });
</script>


    <script type="text/javascript">
      window.onload = function(){
        document.getElementById("search").onclick = function(){
            console.log("search")
            search();
        }
      }
      function search(){
        (function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){
        (w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);
        e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);
        })(window,document,'script','//s.swiftypecdn.com/install/v2/st.js','_st');

        _st('install','A1Pz-LKMXbrzcFg2FWi6','2.0.0');
      }
    </script>

  </div>
</body>
</html>