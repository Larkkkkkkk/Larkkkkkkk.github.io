<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Larkkkkkkk</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Larkkkkkkk">
<meta property="og:url" content="https://larkkkkkkk.github.io/page/6/index.html">
<meta property="og:site_name" content="Larkkkkkkk">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Larkkkkkkk">
<meta name="twitter:card" content="summary">
  
    <link rel="alternative" href="/atom.xml" title="Larkkkkkkk" type="application/atom+xml">
  
  
    <link rel="icon" href="/http://oayoilchh.bkt.clouddn.com/2016/07/27/18:05:26%20">
  
  
      
<link rel="stylesheet" href="//cdn.bootcss.com/animate.css/3.5.0/animate.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  <link rel="stylesheet" href="/font-awesome/css/font-awesome.min.css">
  <link rel="apple-touch-icon" href="/apple-touch-icon.png">
  
    
    
  
  
      <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  
  <!-- 加载特效 -->
    <script src="/js/pace.js"></script>
    <link href="/css/pace/pace-theme-flash.css" rel="stylesheet" />
  <script>
      var yiliaConfig = {
          rootUrl: '/',
          fancybox: true,
          animate: true,
          isHome: true,
          isPost: false,
          isArchive: false,
          isTag: false,
          isCategory: false,
          open_in_new: false
      }
  </script>
<meta name="generator" content="Hexo 4.2.1"></head>
<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
    <header id="header" class="inner">
        <script src="http://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js"></script>
        <a href="/" class="profilepic">
            
            <img lazy-src="img/head.jpg" class="js-avatar">
            
        </a>
        <hgroup>
          <h1 class="header-author"><a href="/">Larkkkkkkk</a></h1>
        </hgroup>
        
        
            <form>
                <input type="text" class="st-default-search-input search" id="local-search-input" placeholder="搜索一下" autocomplete="off">
            </form>
            <div id="local-search-result"></div>
        
        
            <script type="text/javascript">
                (function() {
                    'use strict';
                    function getMatchData(keyword, data) {
                        var matchData = [];
                        for(var i =0;i<data.length;i++){
                            if(data[i].title.toLowerCase().indexOf(keyword)>=0) 
                                matchData.push(data[i])
                        }
                        return matchData;
                    }
                    var $input = $('#local-search-input');
                    var $resultContent = $('#local-search-result');
                    $input.keyup(function(){
                        $.ajax({
                            url: '/search.json',
                            dataType: "json",
                            success: function( json ) {
                                var str='<ul class=\"search-result-list\">';                
                                var keyword = $input.val().trim().toLowerCase();
                                $resultContent.innerHTML = "";
                                if ($input.val().trim().length <= 0) {
                                    $resultContent.empty();
                                    $('#switch-area').show();
                                    return;
                                }
                                var results = getMatchData(keyword, json);
                                if(results.length === 0){
                                    $resultContent.empty();
                                    $('#switch-area').show();
                                    return;
                                } 
                                for(var i =0; i<results.length; i++){
                                    str += "<li><a href='"+ results[i].url +"' class='search-result-title'>"+ results[i].title +"</a></li>";
                                }
                                str += "</ul>";
                                $resultContent.empty();
                                $resultContent.append(str);
                                $('#switch-area').hide();
                            }
                        });
                    });
                })();
            </script>
        
        
            <div id="switch-btn" class="switch-btn">
                <div class="icon">
                    <div class="icon-ctn">
                        <div class="icon-wrap icon-house" data-idx="0">
                            <div class="birdhouse"></div>
                            <div class="birdhouse_holes"></div>
                        </div>
                        <div class="icon-wrap icon-ribbon hide" data-idx="1">
                            <div class="ribbon"></div>
                        </div>
                        
                        <div class="icon-wrap icon-link hide" data-idx="2">
                            <div class="loopback_l"></div>
                            <div class="loopback_r"></div>
                        </div>
                        
                        
                        <div class="icon-wrap icon-me hide" data-idx="3">
                            <div class="user"></div>
                            <div class="shoulder"></div>
                        </div>
                        
                    </div>
                </div>
                <div class="tips-box hide">
                    <div class="tips-arrow"></div>
                    <ul class="tips-inner">
                        <li>菜单</li>
                        <li>标签</li>
                        
                        <li>友情链接</li>
                        
                        
                        <li>关于我</li>
                        
                    </ul>
                </div>
            </div>
        
        <div id="switch-area" class="switch-area">
            <div class="switch-wrap">
                <section class="switch-part switch-part1">
                    <nav class="header-menu">
                        <ul>
                        
                            <li><a  href="https://github.com/Larkkkkkkk" target="_blank" rel="noopener">博客首页</a></li>
                        
                            <li><a  href="/archives">文章归档</a></li>
                        
                            <li><a  href="/CTFStudy">学习导航</a></li>
                        
                            <li><a  href="/PWNABLE">PWNABLE</a></li>
                        
                            <li><a  href="/resume">个人简历</a></li>
                        
                        </ul>
                    </nav>
                    <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fl mail"  target="_blank" href="http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&email=U2JgZ2ZlY2VmamATIiJ9MDw_" title="mail">mail</a>
                            
                                <a class="fl github"  target="_blank" href="https://github.com/Larkkkkkkk" title="github">github</a>
                            
                                <a class="fl zhihu"  target="_blank" href="https://www.zhihu.com/people/plain-3-78/activities" title="zhihu">zhihu</a>
                            
                                <a class="fl weibo"  target="_blank" href="https://weibo.com/5304208276/profile?topnav=1&wvr=6" title="weibo">weibo</a>
                            
                                <a class="fl rss"  target="_blank" href="/atom.xml" title="rss">rss</a>
                            
                        </ul>
                    </nav>
                </section>
                
                <section class="switch-part switch-part2">
                    <div class="widget tagcloud" id="js-tagcloud">
                        <a href="/tags/Ajax/" style="font-size: 12px;">Ajax</a> <a href="/tags/Cookie%E5%92%8CSession/" style="font-size: 14px;">Cookie和Session</a> <a href="/tags/DBUtils/" style="font-size: 11px;">DBUtils</a> <a href="/tags/Docker/" style="font-size: 10px;">Docker</a> <a href="/tags/EL%E8%A1%A8%E8%BE%BE%E5%BC%8F/" style="font-size: 10px;">EL表达式</a> <a href="/tags/Filter/" style="font-size: 11px;">Filter</a> <a href="/tags/HTTP/" style="font-size: 10px;">HTTP</a> <a href="/tags/HTTPServletReauest%E5%92%8CHTTPServletResponse/" style="font-size: 10px;">HTTPServletReauest和HTTPServletResponse</a> <a href="/tags/IDEA%E5%AE%89%E8%A3%85%E5%92%8C%E7%A0%B4%E8%A7%A3/" style="font-size: 10px;">IDEA安装和破解</a> <a href="/tags/JAVA/" style="font-size: 19px;">JAVA</a> <a href="/tags/JAVA-Lambda%E8%A1%A8%E8%BE%BE%E5%BC%8F/" style="font-size: 10px;">JAVA-Lambda表达式</a> <a href="/tags/JAVA-Set%E9%9B%86%E5%90%88/" style="font-size: 10px;">JAVA-Set集合</a> <a href="/tags/JAVA-%E5%8F%8D%E5%B0%84/" style="font-size: 10px;">JAVA-反射</a> <a href="/tags/JAVA-%E5%A4%9A%E7%BA%BF%E7%A8%8B/" style="font-size: 12px;">JAVA-多线程</a> <a href="/tags/JAVA-%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/" style="font-size: 10px;">JAVA-正则表达式</a> <a href="/tags/JAVA-%E6%B3%9B%E5%9E%8B/" style="font-size: 10px;">JAVA-泛型</a> <a href="/tags/JAVA-%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/" style="font-size: 12px;">JAVA-网络编程</a> <a href="/tags/JAVA-%E9%9B%86%E5%90%88/" style="font-size: 12px;">JAVA-集合</a> <a href="/tags/JAVA%E7%BB%83%E4%B9%A0/" style="font-size: 11px;">JAVA练习</a> <a href="/tags/JAVA%E7%BB%83%E4%B9%A0-%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/" style="font-size: 10px;">JAVA练习-动态规划</a> <a href="/tags/JQuery/" style="font-size: 13px;">JQuery</a> <a href="/tags/JSP/" style="font-size: 10px;">JSP</a> <a href="/tags/JVM/" style="font-size: 10px;">JVM</a> <a href="/tags/LeetCode/" style="font-size: 17px;">LeetCode</a> <a href="/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/tags/Listener/" style="font-size: 10px;">Listener</a> <a href="/tags/Mybatis/" style="font-size: 18px;">Mybatis</a> <a href="/tags/Mysql/" style="font-size: 10px;">Mysql</a> <a href="/tags/Mysql%E6%95%B0%E6%8D%AE%E5%BA%93%E5%92%8CJDBC/" style="font-size: 15px;">Mysql数据库和JDBC</a> <a href="/tags/Redis/" style="font-size: 10px;">Redis</a> <a href="/tags/Servlet/" style="font-size: 11px;">Servlet</a> <a href="/tags/Spring/" style="font-size: 16px;">Spring</a> <a href="/tags/SpringMVC/" style="font-size: 15px;">SpringMVC</a> <a href="/tags/Tomcat/" style="font-size: 10px;">Tomcat</a> <a href="/tags/Web%E5%89%8D%E7%AB%AF%E7%9F%A5%E8%AF%86%E7%82%B9/" style="font-size: 20px;">Web前端知识点</a> <a href="/tags/XML/" style="font-size: 11px;">XML</a> <a href="/tags/django/" style="font-size: 10px;">django</a> <a href="/tags/flask%E6%A1%86%E6%9E%B6/" style="font-size: 10px;">flask框架</a> <a href="/tags/git/" style="font-size: 10px;">git</a> <a href="/tags/jsp%E6%A0%87%E5%87%86%E6%A0%87%E7%AD%BE%E5%BA%93/" style="font-size: 10px;">jsp标准标签库</a> <a href="/tags/maven/" style="font-size: 10px;">maven</a> <a href="/tags/picture/" style="font-size: 10px;">picture</a> <a href="/tags/python/" style="font-size: 12px;">python</a> <a href="/tags/pytorch/" style="font-size: 10px;">pytorch</a> <a href="/tags/redis/" style="font-size: 10px;">redis</a> <a href="/tags/ssm%E6%A1%86%E6%9E%B6%E6%A8%A1%E6%9D%BF/" style="font-size: 10px;">ssm框架模板</a> <a href="/tags/webserver%E7%BC%96%E7%A8%8B/" style="font-size: 10px;">webserver编程</a> <a href="/tags/%E4%BA%8B%E5%8A%A1/" style="font-size: 10px;">事务</a> <a href="/tags/%E4%BA%AC%E4%B8%9C/" style="font-size: 11px;">京东</a> <a href="/tags/%E5%90%8E%E7%BC%80%E6%A0%91/" style="font-size: 10px;">后缀树</a> <a href="/tags/%E5%93%88%E5%B8%8C%E8%A1%A8/" style="font-size: 10px;">哈希表</a> <a href="/tags/%E5%9B%BE/" style="font-size: 10px;">图</a> <a href="/tags/%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%88%86%E6%9E%90/" style="font-size: 10px;">复杂度分析</a> <a href="/tags/%E5%AD%A6%E7%94%9F%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/" style="font-size: 10px;">学生管理系统</a> <a href="/tags/%E5%AD%A6%E7%94%9F%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F2-0/" style="font-size: 12px;">学生管理系统2.0</a> <a href="/tags/%E6%8B%BC%E5%A4%9A%E5%A4%9A/" style="font-size: 10px;">拼多多</a> <a href="/tags/%E6%8E%92%E5%BA%8F/" style="font-size: 10px;">排序</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/" style="font-size: 10px;">数据分析</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0/" style="font-size: 10px;">数据库连接池</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%A8%80%E7%96%8F%E6%95%B0%E7%BB%84/" style="font-size: 10px;">数据结构-稀疏数组</a> <a href="/tags/%E6%96%87%E5%AD%97%E7%AF%87-%E8%AE%B0%E5%BD%95/" style="font-size: 10px;">文字篇-记录</a> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="font-size: 12px;">机器学习</a> <a href="/tags/%E6%A0%88/" style="font-size: 10px;">栈</a> <a href="/tags/%E6%A0%91/" style="font-size: 12px;">树</a> <a href="/tags/%E6%B3%A8%E8%A7%A3/" style="font-size: 10px;">注解</a> <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" style="font-size: 14px;">深度学习</a> <a href="/tags/%E7%88%AC%E8%99%AB/" style="font-size: 11px;">爬虫</a> <a href="/tags/%E7%94%9F%E7%89%A9%E4%BF%A1%E6%81%AF%E5%AD%A6/" style="font-size: 10px;">生物信息学</a> <a href="/tags/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/" style="font-size: 12px;">知识图谱</a> <a href="/tags/%E7%A0%94%E7%A9%B6%E7%94%9F%E5%88%9D%E8%AF%95/" style="font-size: 12px;">研究生初试</a> <a href="/tags/%E7%A7%8B%E6%8B%9B/" style="font-size: 10px;">秋招</a> <a href="/tags/%E7%AE%97%E6%B3%95-%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/" style="font-size: 10px;">算法-动态规划</a> <a href="/tags/%E7%AE%97%E6%B3%95-%E5%9B%9E%E6%BA%AF%E6%B3%95/" style="font-size: 10px;">算法-回溯法</a> <a href="/tags/%E7%AE%97%E6%B3%95-%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95/" style="font-size: 10px;">算法-贪心算法</a> <a href="/tags/%E8%80%83%E7%A0%94/" style="font-size: 10px;">考研</a> <a href="/tags/%E8%93%9D%E6%A1%A5%E6%9D%AF/" style="font-size: 13px;">蓝桥杯</a> <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/" style="font-size: 11px;">计算机网络</a> <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E8%AF%BE%E8%AE%BE-%E8%BD%AF%E4%BB%B6%E4%B8%93%E4%B8%9A%E9%A2%98%E7%9B%AE/" style="font-size: 10px;">计算机网络课设(软件专业题目)</a> <a href="/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/" style="font-size: 12px;">设计模式</a> <a href="/tags/%E8%BD%AF%E4%BB%B6%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/" style="font-size: 10px;">软件体系结构</a> <a href="/tags/%E9%80%92%E5%BD%92/" style="font-size: 10px;">递归</a> <a href="/tags/%E9%87%8D%E6%96%B0%E9%83%A8%E7%BD%B2/" style="font-size: 10px;">重新部署</a> <a href="/tags/%E9%93%BE%E8%A1%A8/" style="font-size: 10px;">链表</a> <a href="/tags/%E9%98%9F%E5%88%97/" style="font-size: 10px;">队列</a> <a href="/tags/%E9%9D%A2%E8%AF%95/" style="font-size: 10px;">面试</a> <a href="/tags/%E9%A1%B5%E9%9D%A2%EF%BC%88H5-CSS%EF%BC%89/" style="font-size: 10px;">页面（H5+CSS）</a> <a href="/tags/%E9%A1%B9%E7%9B%AE%E4%B8%8A%E4%BC%A0/" style="font-size: 10px;">项目上传</a>
                    </div>
                </section>
                
                
                <section class="switch-part switch-part3">
                    <div id="js-friends">
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://ring3.xyz/">Yllen</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://mxny.org/">麦香浓郁</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://whereisk0shl.top/">K0sh1</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://www.ycjcl.cc/">信鑫</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://bystudent.com/">ByStundet表哥</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="https://www.jarviswang.me/">汪神_Jarvis</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://sh3ll.me/">Chu</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="https://www.hackfun.org/">4ido10n</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://www.cnblogs.com/iamstudy">L3m0n</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://o0xmuhe.me/">muhe</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://blog.nuptzj.cn/">_画船听雨</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://www.virzz.com/index.html">Virink</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://www.sqlsec.com/">国光</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://www.bodkin.ren/">老锥</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://www.cizel.cn/">C1zel</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://1phan.cc">1phan</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="https://www.liuil.top/">liuil</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://www.cnblogs.com/Ox9A82/">Ox9A82</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://burnegg.com/">burnegg</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="https://jwrsec.cn/">jwr-sec</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://sudalover.cn/">苏打</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://blog.binklac.com">VeroFess</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://www.bendawang.site/">bendawang</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://weeklyalgo.codes/">hook</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://www.flier.net.cn/">Flier&#39;blog</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://www.mutepig.club">mutepig</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="https://blog.iret.xyz/list.aspx">Silver</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://simp1e.leanote.com/">Simple</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="http://processor.pub/">Processor</a>
                    
                    </div>
                </section>
                
                
                
                <section class="switch-part switch-part4">
                
                    <div id="js-aboutme">一只淹死在二进制海洋里的二进制狗!</div>
                </section>
                
            </div>
        </div>
    </header>
</div>

    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
      <div class="overlay">
          <div class="slider-trigger"></div>
          <h1 class="header-author js-mobile-header hide"><a href="/" title="Me">Larkkkkkkk</a></h1>
      </div>
    <div class="intrude-less">
        <header id="header" class="inner">
            <a href="/" class="profilepic">
                
                    <img lazy-src="/img/head.jpg" class="js-avatar">
                
            </a>
            <hgroup>
              <h1 class="header-author"><a href="/" title="Me">Larkkkkkkk</a></h1>
            </hgroup>
            
            <nav class="header-menu">
                <ul>
                
                    <li><a href="https://github.com/Larkkkkkkk" target="_blank" rel="noopener">博客首页</a></li>
                
                    <li><a href="/archives">文章归档</a></li>
                
                    <li><a href="/CTFStudy">学习导航</a></li>
                
                    <li><a href="/PWNABLE">PWNABLE</a></li>
                
                    <li><a href="/resume">个人简历</a></li>
                
                <div class="clearfix"></div>
                </ul>
            </nav>
            <nav class="header-nav">
                <div class="social">
                    
                        <a class="mail" target="_blank" href="http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&email=U2JgZ2ZlY2VmamATIiJ9MDw_" title="mail">mail</a>
                    
                        <a class="github" target="_blank" href="https://github.com/Larkkkkkkk" title="github">github</a>
                    
                        <a class="zhihu" target="_blank" href="https://www.zhihu.com/people/plain-3-78/activities" title="zhihu">zhihu</a>
                    
                        <a class="weibo" target="_blank" href="https://weibo.com/5304208276/profile?topnav=1&wvr=6" title="weibo">weibo</a>
                    
                        <a class="rss" target="_blank" href="/atom.xml" title="rss">rss</a>
                    
                </div>
            </nav>
        </header>                
    </div>
</nav>
      <div class="body-wrap">
  
    <article id="post-Scrapy爬虫进阶" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2022/11/01/Scrapy%E7%88%AC%E8%99%AB%E8%BF%9B%E9%98%B6/" class="article-date">
      <time datetime="2022-11-01T11:27:46.000Z" itemprop="datePublished">2022-11-01</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/11/01/Scrapy%E7%88%AC%E8%99%AB%E8%BF%9B%E9%98%B6/">Scrapy爬虫进阶</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h1 id="Scrapy爬虫库"><a href="#Scrapy爬虫库" class="headerlink" title="Scrapy爬虫库"></a>Scrapy爬虫库</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1.中文地址:https:&#x2F;&#x2F;scrapy.org&#x2F;</span><br></pre></td></tr></table></figure>

<p><img src="/2022/11/01/Scrapy%E7%88%AC%E8%99%AB%E8%BF%9B%E9%98%B6/1.png" alt></p>

      
      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%88%AC%E8%99%AB/" rel="tag">爬虫</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-爬虫" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2022/10/28/%E7%88%AC%E8%99%AB/" class="article-date">
      <time datetime="2022-10-28T13:11:16.000Z" itemprop="datePublished">2022-10-28</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/10/28/%E7%88%AC%E8%99%AB/">爬虫基础</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h1 id="了解网页结构"><a href="#了解网页结构" class="headerlink" title="了解网页结构"></a>了解网页结构</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1.网页构成:</span><br><span class="line">	1.1 html</span><br><span class="line">	1.2 css</span><br><span class="line">	1.3 JavaScript</span><br><span class="line">2.html介绍：</span><br><span class="line">	2.1 header部分:看到网页的元信息(比如像title标题)</span><br><span class="line">	2.2 body部分:可以看到网页的内容(p&#x2F;a&#x2F;h1等标签)</span><br></pre></td></tr></table></figure>

<h2 id="用到的网页html代码"><a href="#用到的网页html代码" class="headerlink" title="用到的网页html代码"></a>用到的网页html代码</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;html lang&#x3D;&quot;cn&quot;&gt;</span><br><span class="line">&lt;head&gt;</span><br><span class="line">	&lt;meta charset&#x3D;&quot;UTF-8&quot;&gt;</span><br><span class="line">	&lt;title&gt;Scraping tutorial 1 | 莫烦Python&lt;&#x2F;title&gt;</span><br><span class="line">	&lt;link rel&#x3D;&quot;icon&quot; href&#x3D;&quot;https:&#x2F;&#x2F;morvanzhou.github.io&#x2F;static&#x2F;img&#x2F;description&#x2F;tab_icon.png&quot;&gt;</span><br><span class="line">&lt;&#x2F;head&gt;</span><br><span class="line">&lt;body&gt;</span><br><span class="line">	&lt;h1&gt;爬虫测试1&lt;&#x2F;h1&gt;</span><br><span class="line">	&lt;p&gt;</span><br><span class="line">		这是一个在 &lt;a href&#x3D;&quot;https:&#x2F;&#x2F;morvanzhou.github.io&#x2F;&quot;&gt;莫烦Python&lt;&#x2F;a&gt;</span><br><span class="line">		&lt;a href&#x3D;&quot;https:&#x2F;&#x2F;morvanzhou.github.io&#x2F;tutorials&#x2F;data-manipulation&#x2F;scraping&#x2F;&quot;&gt;爬虫教程&lt;&#x2F;a&gt; 中的简单测试.</span><br><span class="line">	&lt;&#x2F;p&gt;</span><br><span class="line">&lt;&#x2F;body&gt;</span><br><span class="line">&lt;&#x2F;html&gt;</span><br></pre></td></tr></table></figure>

<h1 id="匹配网页内容-两种方式"><a href="#匹配网页内容-两种方式" class="headerlink" title="匹配网页内容(两种方式)"></a>匹配网页内容(两种方式)</h1><h2 id="正则表达式-regex库"><a href="#正则表达式-regex库" class="headerlink" title="正则表达式(regex库)"></a>正则表达式(regex库)</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">from urllib.request import urlopen #python自带的打开</span><br><span class="line">import re  #正则表达式RegEx进行文字匹配</span><br><span class="line">html&#x3D;urlopen(&quot;https:&#x2F;&#x2F;morvanzhou.github.io&#x2F;static&#x2F;scraping&#x2F;basic-structure.html&quot;).read().decode(&#39;utf-8&#39;)</span><br><span class="line">print(html)</span><br><span class="line"></span><br><span class="line">#1.初级页面匹配用正则表达式</span><br><span class="line">##1.1 找到网页的title</span><br><span class="line">res&#x3D;re.findall(r&quot;&lt;title&gt;(.+?)&lt;&#x2F;title&gt;&quot;,html)</span><br><span class="line">print(&quot;\n文章的标题是: &quot;,res[0])</span><br><span class="line">##1.2 找到中间段落p</span><br><span class="line">res&#x3D;re.findall(r&quot;&lt;p&gt;(.*?)&lt;&#x2F;p&gt;&quot;,html,flags&#x3D;re.DOTALL)  #re.DOTALL对这些tab new line不敏感</span><br><span class="line">print(&quot;\n文章的中间段落是: &quot;,res[0])</span><br><span class="line">##1.3 找到所有的链接</span><br><span class="line">res&#x3D;re.findall(r&#39;href&#x3D;&quot;(.*?)&quot;&#39;,html)</span><br><span class="line">print(&quot;\n所有的链接：&quot;,res)</span><br></pre></td></tr></table></figure>

<p><img src="/2022/10/28/%E7%88%AC%E8%99%AB/2.png" alt></p>
<h2 id="BeautifulSoup-bs4库的BeautifulSoup"><a href="#BeautifulSoup-bs4库的BeautifulSoup" class="headerlink" title="BeautifulSoup(bs4库的BeautifulSoup)"></a>BeautifulSoup(bs4库的BeautifulSoup)</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1.概念:是一个可以从HTML&#x2F;XML文件中提取数据的Python库.它能够通过你喜欢的转换器实现惯用的文档导航,查找,修改文档的方式.Beautiful Soup会帮你节省数小时甚至数天的工作时间.</span><br><span class="line">2.官网:https:&#x2F;&#x2F;www.crummy.com&#x2F;software&#x2F;BeautifulSoup&#x2F;bs4&#x2F;doc.zh&#x2F;</span><br></pre></td></tr></table></figure>

<h3 id="解析网页-基础-按照标签名进行匹配"><a href="#解析网页-基础-按照标签名进行匹配" class="headerlink" title="解析网页:基础(按照标签名进行匹配)"></a>解析网页:基础(按照标签名进行匹配)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">#和刚才正则表达式对比:</span><br><span class="line">from urllib.request import urlopen #python自带的打开</span><br><span class="line">from bs4 import BeautifulSoup #bs4里面的</span><br><span class="line">html&#x3D;urlopen(&quot;https:&#x2F;&#x2F;morvanzhou.github.io&#x2F;static&#x2F;scraping&#x2F;basic-structure.html&quot;).read().decode(&#39;utf-8&#39;)</span><br><span class="line">#print(html)</span><br><span class="line">#2.高级页面匹配用BeautifulSoup</span><br><span class="line">soup&#x3D;BeautifulSoup(html,features&#x3D;&#39;lxml&#39;) #将刚才获取的地址 --&gt; lxml格式保存</span><br><span class="line">#输出soup的h标题</span><br><span class="line">print(soup.h1)</span><br><span class="line">#输出soup的p标签</span><br><span class="line">print(soup.p)</span><br><span class="line">#输出soup的a标签(特别多的话可以用find_all()找到所有选项)</span><br><span class="line">all_href&#x3D;soup.find_all(&#39;a&#39;) #将所有a找到 -- 但是里面会有很多其他杂质(&lt;a href&#x3D;&quot;xxx&quot;&gt;爬虫教程&lt;&#x2F;a&gt;])</span><br><span class="line">print(all_href)</span><br><span class="line">for i in all_href:</span><br><span class="line">    print(&quot;a里面的地址:&quot;,i[&#39;href&#39;])</span><br></pre></td></tr></table></figure>

<p><img src="/2022/10/28/%E7%88%AC%E8%99%AB/1.png" alt></p>
<h3 id="解析网页-CSS-按照css的class进行匹配"><a href="#解析网页-CSS-按照css的class进行匹配" class="headerlink" title="解析网页:CSS(按照css的class进行匹配)"></a>解析网页:CSS(按照css的class进行匹配)</h3><p><strong>要准备的html网页:</strong></p>
<p><img src="/2022/10/28/%E7%88%AC%E8%99%AB/3.png" alt></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">from urllib.request import urlopen #python自带的打开</span><br><span class="line">import re  #正则表达式RegEx进行文字匹配</span><br><span class="line">from bs4 import BeautifulSoup #bs4里面的</span><br><span class="line">html&#x3D;urlopen(&quot;https:&#x2F;&#x2F;mofanpy.com&#x2F;static&#x2F;scraping&#x2F;list.html&quot;).read().decode(&#39;utf-8&#39;)</span><br><span class="line">#print(html)</span><br><span class="line">soup&#x3D;BeautifulSoup(html,features&#x3D;&#39;lxml&#39;)</span><br><span class="line"></span><br><span class="line">#1.找到所有class&#x3D;month的信息</span><br><span class="line">month&#x3D;soup.find_all(&#39;li&#39;,&#123;&quot;class&quot;:&quot;month&quot;&#125;) #根据li标签获取class&#x3D;month的信息</span><br><span class="line">for m in month:</span><br><span class="line">    print(m.get_text())  #获取li标签里面的所有文字标题</span><br><span class="line"></span><br><span class="line">#2.找到class&#x3D;jan的信息 然后在ul下面继续找ul内部的li信息(一层层嵌套)</span><br><span class="line">jan&#x3D;soup.find(&#39;ul&#39;,&#123;&quot;class&quot;:&#39;jan&#39;&#125;)</span><br><span class="line">d_jan&#x3D;jan.find_all(&#39;li&#39;)</span><br><span class="line">for d in d_jan:</span><br><span class="line">    print(d.get_text())</span><br></pre></td></tr></table></figure>

<p><img src="/2022/10/28/%E7%88%AC%E8%99%AB/4.png" alt></p>
<h3 id="解析网页-正则表达式"><a href="#解析网页-正则表达式" class="headerlink" title="解析网页:正则表达式"></a>解析网页:正则表达式</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">from urllib.request import urlopen #python自带的打开</span><br><span class="line">import re  #正则表达式RegEx进行文字匹配</span><br><span class="line">from bs4 import BeautifulSoup #bs4里面的</span><br><span class="line"></span><br><span class="line">#获取网址</span><br><span class="line">html&#x3D;urlopen(&quot;https:&#x2F;&#x2F;mofanpy.com&#x2F;static&#x2F;scraping&#x2F;table.html&quot;).read().decode(&#39;utf-8&#39;)</span><br><span class="line">#将页面保存到soup</span><br><span class="line">soup&#x3D;BeautifulSoup(html,features&#x3D;&#39;lxml&#39;)</span><br><span class="line">#获取所有的图片 后缀是jpg的图片()</span><br><span class="line">img_links&#x3D;soup.find_all(&quot;img&quot;,&#123;&quot;src&quot;:re.compile(&#39;.*?\.jpg&#39;)&#125;) # .匹配任何字符  *匹配前一个字符0&#x2F;无限次 ?前面的字符可有可无  \.就是匹配.  --&gt; xxx.jpg</span><br><span class="line">#for循环遍历</span><br><span class="line">for link in img_links:</span><br><span class="line">    print(link[&#39;src&#39;]) #根据src进行遍历</span><br></pre></td></tr></table></figure>

<p><img src="/2022/10/28/%E7%88%AC%E8%99%AB/18.png" alt></p>
<h1 id="正则表达式"><a href="#正则表达式" class="headerlink" title="正则表达式"></a>正则表达式</h1><p><strong>正则表达式匹配流程:</strong></p>
<p><img src="/2022/10/28/%E7%88%AC%E8%99%AB/6.png" alt></p>
<h2 id="简单匹配-re-search"><a href="#简单匹配-re-search" class="headerlink" title="简单匹配(re.search)"></a>简单匹配(re.search)</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">import re  #正则表达式RegEx进行文字匹配</span><br><span class="line">pattern1 &#x3D; &quot;cat&quot;</span><br><span class="line">pattern2 &#x3D; &quot;bird&quot;</span><br><span class="line">string &#x3D; &quot;dog runs to cat&quot;</span><br><span class="line">#使用普通字符串匹配</span><br><span class="line">print(pattern1 in string)    # True</span><br><span class="line">print(pattern2 in string)    # False</span><br><span class="line">#使用正则表达式匹配</span><br><span class="line">print(re.search(pattern1,string))  #匹配到了会说范围span和匹配的内容match</span><br><span class="line">print(re.search(pattern2,string))  #没匹配到就是None</span><br></pre></td></tr></table></figure>

<p><img src="/2022/10/28/%E7%88%AC%E8%99%AB/7.png" alt></p>
<h2 id="灵活匹配-pattern"><a href="#灵活匹配-pattern" class="headerlink" title="灵活匹配(pattern)"></a>灵活匹配(pattern)</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">import re  #正则表达式RegEx进行文字匹配</span><br><span class="line"></span><br><span class="line">pattern1 &#x3D; &quot;cat&quot;</span><br><span class="line">pattern2 &#x3D; &quot;bird&quot;</span><br><span class="line">string &#x3D; &quot;dog runs to cat&quot;</span><br><span class="line"></span><br><span class="line">#r&quot;xxx&quot;表示这是正则表达式</span><br><span class="line">##1.r[au]n --&gt; 匹配 ran&#x2F;run</span><br><span class="line">ptn&#x3D;r&quot;r[au]n&quot;</span><br><span class="line">print(re.search(ptn,string))</span><br><span class="line">##2.r[A-Z]n --&gt; 匹配rAn&#x2F;rBn...&#x2F;rZn</span><br><span class="line">print(re.search(r&quot;r[A-Z]n&quot;,string))</span><br><span class="line">##3.r[a-z]n --&gt; 匹配ran&#x2F;rbn...&#x2F;rzn</span><br><span class="line">print(re.search(r&quot;r[a-z]n&quot;,string))</span><br><span class="line">##4.r[0-9]n --&gt; 匹配r0n&#x2F;r1n...&#x2F;r9n</span><br><span class="line">print(re.search(r&quot;r[0-9]n]&quot;,string))</span><br><span class="line">##5.r[0-9a-z] --&gt; 匹配可以是数字也可以是任何字母</span><br><span class="line">print(re.search(r&quot;r[0-9a-z]n&quot;,string))</span><br></pre></td></tr></table></figure>

<p><img src="/2022/10/28/%E7%88%AC%E8%99%AB/8.png" alt></p>
<h2 id="类型匹配-好多设定好的"><a href="#类型匹配-好多设定好的" class="headerlink" title="类型匹配(好多设定好的)"></a>类型匹配(好多设定好的)</h2><p><strong>特殊的匹配类型:</strong></p>
<p><img src="/2022/10/28/%E7%88%AC%E8%99%AB/9.png" alt></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">import re  #正则表达式RegEx进行文字匹配</span><br><span class="line"></span><br><span class="line">#匹配r(任何数字)n</span><br><span class="line">print(re.search(r&quot;r\dn&quot;,&quot;run r4n&quot;))  #匹配到r4n</span><br><span class="line">#匹配r(不是数字)n</span><br><span class="line">print(re.search(r&quot;r\Dn&quot;,&quot;run r4n&quot;))  #匹配到run</span><br><span class="line">#匹配r(任何white space)n   --比如\t \n \r \f \v</span><br><span class="line">print(re.search(r&quot;r\sn&quot;, &quot;r\nn r4n&quot;)) #匹配到r\nn</span><br><span class="line">#匹配r(不是white space)n</span><br><span class="line">print(re.search(r&quot;r\Sn&quot;, &quot;r\nn r4n&quot;)) #匹配到r4n</span><br><span class="line">#匹配r(任何大小写字母和数字还有_ a-zA-Z0-9)</span><br><span class="line">print(re.search(r&quot;r\wn&quot;, &quot;r\nn r4n&quot;)) #匹配到r4n</span><br><span class="line">#匹配r(任何不是大小写字母和数字还有_ a-zA-Z0-9这个范围内)</span><br><span class="line">print(re.search(r&quot;r\Wn&quot;, &quot;r\nn r4n&quot;)) #匹配到r\nn</span><br><span class="line">#匹配r(只在某个字的开头&#x2F;结尾的空白字符)n</span><br><span class="line">print(re.search(r&quot;r\bn&quot;, &quot;dog runs to cat&quot;)) #什么都匹配不到</span><br><span class="line">#匹配(不在某个字的开头&#x2F;结尾的空白字符) runs (不在某个字的开头&#x2F;结尾的空白字符)</span><br><span class="line">print(re.search(r&quot;\B runs \B&quot;, &quot;dog   runs  to cat&quot;)) #匹配到 runs</span><br><span class="line">#匹配runs(\)</span><br><span class="line">print(re.search(r&quot;runs\\&quot;, &quot;runs\ to me&quot;)) #匹配到runs\\</span><br><span class="line">#匹配r(任何字符 除了\n)n</span><br><span class="line">print(re.search(r&quot;r.n&quot;, &quot;r[ns to me&quot;)) #匹配r[n</span><br><span class="line">#匹配(开头)dog</span><br><span class="line">print(re.search(r&quot;^dog&quot;, &quot;dog runs to cat&quot;))  #匹配dog</span><br><span class="line">#匹配cat(结尾)</span><br><span class="line">print(re.search(r&quot;cat$&quot;, &quot;dog runs to cat&quot;))  #匹配cat</span><br><span class="line">#匹配Mon(day)可有可无  --&gt;Monday和Mon都可以</span><br><span class="line">print(re.search(r&quot;Mon(day)?&quot;, &quot;Monday&quot;)) #匹配Monday</span><br><span class="line">print(re.search(r&quot;Mon(day)?&quot;, &quot;Mon&quot;)) #匹配Mon</span><br><span class="line"></span><br><span class="line">#匹配多行字符串</span><br><span class="line">#使用^形式匹配行开头的字符</span><br><span class="line">string&#x3D;&quot;&quot;&quot;</span><br><span class="line">dog runs to cat.</span><br><span class="line">I run to dog.</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">#匹配不到</span><br><span class="line">print(re.search(r&quot;^I&quot;,string))</span><br><span class="line">#可以匹配到</span><br><span class="line">#可以对每一行单独处理  flags&#x3D;re.M &#x2F; flags&#x3D;re.MULTILINE</span><br><span class="line">print(re.search(r&quot;^I&quot;,string,flags&#x3D;re.M))</span><br></pre></td></tr></table></figure>

<p><img src="/2022/10/28/%E7%88%AC%E8%99%AB/10.png" alt></p>
<h2 id="重复匹配-重复出现"><a href="#重复匹配-重复出现" class="headerlink" title="重复匹配(重复出现)"></a>重复匹配(重复出现)</h2><p><strong>重复匹配分类:</strong></p>
<p><img src="/2022/10/28/%E7%88%AC%E8%99%AB/11.png" alt></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">import re  #正则表达式RegEx进行文字匹配</span><br><span class="line"></span><br><span class="line"># *重复0次&#x2F;多次</span><br><span class="line">print(re.search(r&quot;ab*&quot;,&quot;a&quot;))  # a出现一次 b出现0次&#x2F;多次 a</span><br><span class="line">print(re.search(r&quot;ab*&quot;,&quot;abbbbb&quot;)) # a出现一次 b出现0次&#x2F;多次  abbbbb</span><br><span class="line">print(re.search(r&quot;ab*&quot;,&quot;abababab&quot;))  # a出现一次 b出现0次&#x2F;多次  ab</span><br><span class="line">print()</span><br><span class="line"></span><br><span class="line"># +重复1次&#x2F;多次</span><br><span class="line">print(re.search(r&quot;ab+&quot;,&quot;a&quot;)) # a出现一次 b出现一次&#x2F;多次 None</span><br><span class="line">print(re.search(r&quot;ab+&quot;,&quot;ab&quot;)) #a出现一次 b出现一次&#x2F;多次 ab</span><br><span class="line">print(re.search(r&quot;ab+&quot;,&quot;abb&quot;)) #a出现一次 b出现一次&#x2F;多次 abb</span><br><span class="line">print()</span><br><span class="line"></span><br><span class="line"># &#123;n,m&#125;重复n至m次</span><br><span class="line">print(re.search(r&quot;ab&#123;2,10&#125;&quot;,&quot;a&quot;))  #a出现一次 b出现2-10次 None</span><br><span class="line">print(re.search(r&quot;ab&#123;2,10&#125;&quot;,&quot;ab&quot;))  #a出现一次 b出现2-10次 None</span><br><span class="line">print(re.search(r&quot;ab&#123;2,10&#125;&quot;,&quot;abb&quot;))  #a出现一次 b出现2-10次 abb</span><br><span class="line">print(re.search(r&quot;ab&#123;2,10&#125;&quot;,&quot;abbbb&quot;))  #a出现一次 b出现2-10次 abbbb</span><br><span class="line">print(re.search(r&quot;ab&#123;2,10&#125;&quot;,&quot;ababab&quot;)) #a出现一次 b出现2-10次 None</span><br></pre></td></tr></table></figure>

<p><img src="/2022/10/28/%E7%88%AC%E8%99%AB/12.png" alt></p>
<h2 id="分组-re-search-group"><a href="#分组-re-search-group" class="headerlink" title="分组(re.search().group())"></a>分组(re.search().group())</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">import re  #正则表达式RegEx进行文字匹配</span><br><span class="line"></span><br><span class="line"># match.group()表示返回所有组里的内容</span><br><span class="line">string&#x3D;&quot;ID: 021523, Date: Feb&#x2F;12&#x2F;2017&quot;</span><br><span class="line">match&#x3D;re.search(r&quot;(\d+), Date:(.+)&quot;,string) # (\d+)表示匹配数字重复1次或者多次  (.+)表示匹配任何字符(除了\n)</span><br><span class="line">print(match.group())  #匹配出来 021526, Date:Feb&#x2F;12&#x2F;2017</span><br><span class="line">print(match.group(1)) # 021526</span><br><span class="line">print(match.group(2)) # Feb&#x2F;12&#x2F;2017</span><br><span class="line">print()</span><br><span class="line"></span><br><span class="line"># ?P&lt;名字&gt;</span><br><span class="line">string&#x3D; &quot;ID: 021523, Date: Feb&#x2F;12&#x2F;2017&quot;</span><br><span class="line">match&#x3D;re.search(r&quot;(?P&lt;id&gt;\d+), Date:(?P&lt;date&gt;.+)&quot;,string)  #匹配出来 id:021526  date:Date:Feb&#x2F;12&#x2F;2017</span><br><span class="line">print(match.group(&#39;id&#39;))                # 021523</span><br><span class="line">print(match.group(&#39;date&#39;))              # Date: Feb&#x2F;12&#x2F;2017</span><br></pre></td></tr></table></figure>

<p><img src="/2022/10/28/%E7%88%AC%E8%99%AB/13.png" alt></p>
<h2 id="findall-全部-和or"><a href="#findall-全部-和or" class="headerlink" title="findall(全部)和or(|)"></a>findall(全部)和or(|)</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">import re  #正则表达式RegEx进行文字匹配</span><br><span class="line"> </span><br><span class="line">#findall是找到所有的可能</span><br><span class="line">#|是找到其中一个(要么是前者要么是后者)</span><br><span class="line">print(re.findall(r&quot;r[uae]n&quot;,&quot;run ran ren&quot;))     # [&#39;run&#39;, &#39;ran&#39;, &#39;ren&#39;]</span><br><span class="line">print(re.findall(r&quot;(run|ran)&quot;,&quot;run ran ren&quot;))   # [&#39;run&#39;, &#39;ran&#39;]</span><br></pre></td></tr></table></figure>

<p><img src="/2022/10/28/%E7%88%AC%E8%99%AB/14.png" alt></p>
<h2 id="replace-re-sub"><a href="#replace-re-sub" class="headerlink" title="replace(re.sub())"></a>replace(re.sub())</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import re  #正则表达式RegEx进行文字匹配</span><br><span class="line"> </span><br><span class="line">#re.sub()替换</span><br><span class="line">#匹配rans|runs</span><br><span class="line">print(re.sub(r&quot;r[au]ns&quot;, &quot;catches&quot;, &quot;dog runs to cat&quot;)) #用catches替换掉runs&#x2F;rans</span><br></pre></td></tr></table></figure>

<p><img src="/2022/10/28/%E7%88%AC%E8%99%AB/15.png" alt></p>
<h2 id="split-re-split"><a href="#split-re-split" class="headerlink" title="split(re.split())"></a>split(re.split())</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import re  #正则表达式RegEx进行文字匹配</span><br><span class="line"></span><br><span class="line">#re.split()</span><br><span class="line">string&#x3D;&quot;a;b,c.d;]we&quot;</span><br><span class="line">print(re.split(r&quot;[,;\.]&quot;,string))  #通过, ; \ .其中一个进行分割成单词</span><br></pre></td></tr></table></figure>

<p><img src="/2022/10/28/%E7%88%AC%E8%99%AB/16.png" alt></p>
<h2 id="compile-将匹配的规则重复使用"><a href="#compile-将匹配的规则重复使用" class="headerlink" title="compile(将匹配的规则重复使用)"></a>compile(将匹配的规则重复使用)</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">import re  #正则表达式RegEx进行文字匹配</span><br><span class="line"></span><br><span class="line">#compile()</span><br><span class="line">#使用compile过后的正则,对这个正则重复使用</span><br><span class="line">compiled_re&#x3D;re.compile(r&quot;r[ua]n&quot;) #匹配的是run&#x2F;ran</span><br><span class="line">print(compiled_re.search(&quot;dog ran to cat&quot;)) #匹配ran&#x2F;run --&gt; ran</span><br></pre></td></tr></table></figure>

<p><img src="/2022/10/28/%E7%88%AC%E8%99%AB/17.png" alt></p>
<h2 id="小抄"><a href="#小抄" class="headerlink" title="小抄"></a>小抄</h2><p><img src="/2022/10/28/%E7%88%AC%E8%99%AB/5.png" alt></p>
<h1 id="小练习-爬百度百科"><a href="#小练习-爬百度百科" class="headerlink" title="小练习-爬百度百科"></a>小练习-爬百度百科</h1><h2 id="步骤和要求"><a href="#步骤和要求" class="headerlink" title="步骤和要求"></a>步骤和要求</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1.设定基础url路径</span><br><span class="line">2.设定his存放&#x2F;item&#x2F;页面</span><br><span class="line">3.设置url路径</span><br><span class="line">4.读取url路径</span><br><span class="line">5.将html设置到soup内部</span><br><span class="line">6.输出相关的标题或者其他内容</span><br></pre></td></tr></table></figure>


<h2 id="爬取一个页面"><a href="#爬取一个页面" class="headerlink" title="爬取一个页面"></a>爬取一个页面</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">from urllib.request import urlopen #python自带的打开</span><br><span class="line">import re  #正则表达式RegEx进行文字匹配</span><br><span class="line">from bs4 import BeautifulSoup #bs4里面的</span><br><span class="line">import random</span><br><span class="line"></span><br><span class="line">#观看规律</span><br><span class="line">#&lt;a target&#x3D;&quot;_blank&quot; href&#x3D;&quot;&#x2F;item&#x2F;%E8%9C%98%E8%9B%9B&#x2F;8135707&quot; data-lemmaid&#x3D;&quot;8135707&quot;&gt;蜘蛛&lt;&#x2F;a&gt;</span><br><span class="line">#&lt;a target&#x3D;&quot;_blank&quot; href&#x3D;&quot;&#x2F;item&#x2F;%E8%A0%95%E8%99%AB&quot;&gt;蠕虫&lt;&#x2F;a&gt;</span><br><span class="line">#&lt;a target&#x3D;&quot;_blank&quot; href&#x3D;&quot;&#x2F;item&#x2F;%E9%80%9A%E7%94%A8%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E&quot;&gt;通用搜索引擎&lt;&#x2F;a&gt;</span><br><span class="line"></span><br><span class="line">#基础url路径</span><br><span class="line">base_url&#x3D;&quot;https:&#x2F;&#x2F;baike.baidu.com&quot;</span><br><span class="line">#将&#x2F;item&#x2F;...的页面都放在his中</span><br><span class="line">his&#x3D;[&quot;&#x2F;item&#x2F;%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB&#x2F;5162711&quot;]</span><br><span class="line"></span><br><span class="line">#根据基础url+his的地址</span><br><span class="line">url&#x3D;base_url+his[-1]  # 爬取网页为:https:&#x2F;&#x2F;baike.baidu.com&#x2F;item&#x2F;%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB&#x2F;5162711</span><br><span class="line">#将html放在soup里</span><br><span class="line">html&#x3D;urlopen(url).read().decode(&#39;utf-8&#39;)</span><br><span class="line">soup&#x3D;BeautifulSoup(html,features&#x3D;&#39;lxml&#39;)</span><br><span class="line">print(soup.find(&#39;h1&#39;).get_text())  #获取页面的h1标题</span><br><span class="line">print(&#39;url:&#39;,his[-1])</span><br></pre></td></tr></table></figure>

<p><img src="/2022/10/28/%E7%88%AC%E8%99%AB/19.png" alt></p>
<h2 id="for循环爬取"><a href="#for循环爬取" class="headerlink" title="for循环爬取"></a>for循环爬取</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">from urllib.request import urlopen #python自带的打开</span><br><span class="line">import re  #正则表达式RegEx进行文字匹配</span><br><span class="line">from bs4 import BeautifulSoup #bs4里面的</span><br><span class="line">import random</span><br><span class="line"></span><br><span class="line">#观看规律</span><br><span class="line">#&lt;a target&#x3D;&quot;_blank&quot; href&#x3D;&quot;&#x2F;item&#x2F;%E8%9C%98%E8%9B%9B&#x2F;8135707&quot; data-lemmaid&#x3D;&quot;8135707&quot;&gt;蜘蛛&lt;&#x2F;a&gt;</span><br><span class="line">#&lt;a target&#x3D;&quot;_blank&quot; href&#x3D;&quot;&#x2F;item&#x2F;%E8%A0%95%E8%99%AB&quot;&gt;蠕虫&lt;&#x2F;a&gt;</span><br><span class="line">#&lt;a target&#x3D;&quot;_blank&quot; href&#x3D;&quot;&#x2F;item&#x2F;%E9%80%9A%E7%94%A8%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E&quot;&gt;通用搜索引擎&lt;&#x2F;a&gt;</span><br><span class="line"></span><br><span class="line">#基础url路径</span><br><span class="line">base_url&#x3D;&quot;https:&#x2F;&#x2F;baike.baidu.com&quot;</span><br><span class="line">#将&#x2F;item&#x2F;...的页面都放在his中</span><br><span class="line">his&#x3D;[&quot;&#x2F;item&#x2F;%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB&#x2F;5162711&quot;]</span><br><span class="line"></span><br><span class="line">for i in range(5):</span><br><span class="line">#根据基础url+his的地址</span><br><span class="line">    url&#x3D;base_url+his[-1]  # 爬取网页为:https:&#x2F;&#x2F;baike.baidu.com&#x2F;item&#x2F;%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB&#x2F;5162711</span><br><span class="line">    #将html放在soup里</span><br><span class="line">    html&#x3D;urlopen(url).read().decode(&#39;utf-8&#39;)</span><br><span class="line">    soup&#x3D;BeautifulSoup(html,features&#x3D;&#39;lxml&#39;)</span><br><span class="line">    print(soup.find(&#39;h1&#39;).get_text())  #获取页面的第一个h1标题</span><br><span class="line">    print(&#39;url:&#39;,his[-1]) #获取页面的标签下的地址</span><br><span class="line"></span><br><span class="line">    #找到所有url</span><br><span class="line">    sub_urls&#x3D;soup.find_all(&quot;a&quot;,&#123;</span><br><span class="line">                                &quot;target&quot;:&quot;_blank&quot;,</span><br><span class="line">                                &quot;href&quot;:re.compile(&quot;&#x2F;item&#x2F;(%.&#123;2&#125;)+$&quot;)&#125;)  #找到所有a标签 然后target&#x3D;&quot;_blank&quot; href标签都是&#x2F;item&#x2F;...</span><br><span class="line">    if len(sub_urls) !&#x3D; 0:</span><br><span class="line">        his.append(random.sample(sub_urls,1)[0][&#39;href&#39;])  #如果可以就往下继续找 找到下一个标签的第一个位置</span><br><span class="line">    else:</span><br><span class="line">        his.pop()  #如果没有就往回走一个页面</span><br><span class="line">    print(his)</span><br></pre></td></tr></table></figure>

<p><img src="/2022/10/28/%E7%88%AC%E8%99%AB/20.png" alt></p>
<h1 id="Requests"><a href="#Requests" class="headerlink" title="Requests"></a>Requests</h1><h2 id="get和post区别"><a href="#get和post区别" class="headerlink" title="get和post区别"></a>get和post区别</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1.get:取得(被动)	</span><br><span class="line">2.post:发送(主动)控制了服务器返回的内容，可以进行个性化服务</span><br></pre></td></tr></table></figure>

<p><img src="/2022/10/28/%E7%88%AC%E8%99%AB/21.png" alt></p>
<h2 id="request-get请求"><a href="#request-get请求" class="headerlink" title="request get请求"></a>request get请求</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">import webbrowser</span><br><span class="line">param&#x3D;&#123;&quot;wd&quot;:&quot;莫烦Python&quot;&#125;  #wd&#x3D;莫烦Python</span><br><span class="line">r&#x3D;requests.get(&#39;http:&#x2F;&#x2F;www.baidu.com&#x2F;s&#39;,params&#x3D;param)</span><br><span class="line">print(r.url)</span><br><span class="line">webbrowser.open(r.url)  #用py打开默认浏览器</span><br></pre></td></tr></table></figure>

<p><img src="/2022/10/28/%E7%88%AC%E8%99%AB/22.png" alt></p>
<h2 id="request-post请求"><a href="#request-post请求" class="headerlink" title="request post请求"></a>request post请求</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">import webbrowser</span><br><span class="line">data&#x3D;&#123;&#39;firstname&#39;:&#39;莫烦&#39;,&#39;lastname&#39;:&#39;周&#39;&#125; </span><br><span class="line">r&#x3D;requests.post(&#39;https:&#x2F;&#x2F;pythonscraping.com&#x2F;pages&#x2F;files&#x2F;processing.php&#39;,data&#x3D;data)</span><br><span class="line">print(r.text)</span><br></pre></td></tr></table></figure>

<h2 id="上传照片"><a href="#上传照片" class="headerlink" title="上传照片"></a>上传照片</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">import webbrowser</span><br><span class="line">file &#x3D; &#123;&#39;uploadFile&#39;: open(&#39;.&#x2F;1.jpg&#39;,&#39;rb&#39;)&#125;</span><br><span class="line">r&#x3D;requests.post(&#39;http:&#x2F;&#x2F;pythonscraping.com&#x2F;files&#x2F;processing2.php&#39;,files&#x3D;file)</span><br><span class="line">print(r.text)</span><br></pre></td></tr></table></figure>

<h2 id="登录"><a href="#登录" class="headerlink" title="登录"></a>登录</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">1.使用 post 方法登录了第一个红框的 url</span><br><span class="line">2.post 的时候, 使用了 Form data 中的用户名和密码</span><br><span class="line">3.生成了一些cookies</span><br><span class="line"></span><br><span class="line">import requests</span><br><span class="line">import webbrowser</span><br><span class="line">from requests.packages.urllib3.exceptions import InsecureRequestWarning</span><br><span class="line">requests.packages.urllib3.disable_warnings(InsecureRequestWarning)</span><br><span class="line">payload&#x3D;&#123;&#39;username&#39;:&#39;Lark&#39;,&#39;password&#39;:&#39;password&#39;&#125;   #登录的账号和密码</span><br><span class="line">r&#x3D;requests.post(&#39;http:&#x2F;&#x2F;pythonscraping.com&#x2F;pages&#x2F;cookies&#x2F;welcome.php&#39;,data&#x3D;payload) #将账号密码通过post上传</span><br><span class="line">print(r.cookies.get_dict())  #生成cookies</span><br><span class="line"></span><br><span class="line">r&#x3D;requests.get(&#39;http:&#x2F;&#x2F;pythonscraping.com&#x2F;pages&#x2F;cookies&#x2F;profile.php&#39;,cookies&#x3D;r.cookies,verify&#x3D;False) #通过以前的cookies传入get请求 就可以通过已登录的名义访问get页面</span><br><span class="line">print(r.text)</span><br></pre></td></tr></table></figure>

<p><img src="/2022/10/28/%E7%88%AC%E8%99%AB/23.png" alt></p>
<h2 id="使用Session登录"><a href="#使用Session登录" class="headerlink" title="使用Session登录"></a>使用Session登录</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">import webbrowser</span><br><span class="line">from requests.packages.urllib3.exceptions import InsecureRequestWarning</span><br><span class="line">requests.packages.urllib3.disable_warnings(InsecureRequestWarning)</span><br><span class="line"></span><br><span class="line">session&#x3D;requests.Session() #获取session</span><br><span class="line">payload&#x3D;&#123;&#39;username&#39;:&#39;Lark&#39;,&#39;password&#39;:&#39;password&#39;&#125;   #登录的账号和密码</span><br><span class="line">r&#x3D;requests.post(&#39;http:&#x2F;&#x2F;pythonscraping.com&#x2F;pages&#x2F;cookies&#x2F;welcome.php&#39;,data&#x3D;payload) #将账号密码通过post上传</span><br><span class="line">print(r.cookies.get_dict())  #生成cookies</span><br><span class="line"></span><br><span class="line">r&#x3D;requests.get(&#39;http:&#x2F;&#x2F;pythonscraping.com&#x2F;pages&#x2F;cookies&#x2F;profile.php&#39;,cookies&#x3D;r.cookies,verify&#x3D;False) #通过以前的cookies传入get请求 就可以通过已登录的名义访问get页面</span><br><span class="line">print(r.text)</span><br></pre></td></tr></table></figure>

<p><img src="/2022/10/28/%E7%88%AC%E8%99%AB/23.png" alt></p>
<h2 id="下载文件-urllib-urlretrieve"><a href="#下载文件-urllib-urlretrieve" class="headerlink" title="下载文件(urllib.urlretrieve)"></a>下载文件(urllib.urlretrieve)</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">import webbrowser</span><br><span class="line">from requests.packages.urllib3.exceptions import InsecureRequestWarning</span><br><span class="line">requests.packages.urllib3.disable_warnings(InsecureRequestWarning)</span><br><span class="line">import os</span><br><span class="line">from urllib.request import urlretrieve</span><br><span class="line"></span><br><span class="line">os.makedirs(&#39;.&#x2F;img&#x2F;&#39;,exist_ok&#x3D;True)  #设定一个img文件夹</span><br><span class="line">IMAGE_URL&#x3D;&quot;https:&#x2F;&#x2F;static.mofanpy.com&#x2F;static&#x2F;img&#x2F;description&#x2F;learning_step_flowchart.png&quot;  #图片地址</span><br><span class="line"></span><br><span class="line">urlretrieve(IMAGE_URL,&#39;.&#x2F;img&#x2F;image1.png&#39;)  #urllib模块提供一个下载功能urlretrieve</span><br><span class="line"></span><br><span class="line">r&#x3D;requests.get(IMAGE_URL)</span><br><span class="line">with open(&#39;.&#x2F;img&#x2F;image2.png&#39;, &#39;wb&#39;) as f:</span><br><span class="line">    for chunk in r.iter_content(chunk_size&#x3D;32):  #可以通过控制每个chunk的大小 将大的文件按照一个个chunk存放</span><br><span class="line">        f.write(chunk)</span><br></pre></td></tr></table></figure>

<h1 id="小练习-下载美图"><a href="#小练习-下载美图" class="headerlink" title="小练习-下载美图"></a>小练习-下载美图</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">import webbrowser</span><br><span class="line">from requests.packages.urllib3.exceptions import InsecureRequestWarning</span><br><span class="line">requests.packages.urllib3.disable_warnings(InsecureRequestWarning)</span><br><span class="line">import os</span><br><span class="line">from urllib.request import urlretrieve</span><br><span class="line">from bs4 import BeautifulSoup</span><br><span class="line"></span><br><span class="line">#获取url路径</span><br><span class="line">URL&#x3D;&quot;http:&#x2F;&#x2F;www.nationalgeographic.com.cn&#x2F;animals&#x2F;&quot;</span><br><span class="line">#用soup找到带有img_list的这种ul标签</span><br><span class="line">html&#x3D;requests.get(URL).text</span><br><span class="line">soup&#x3D;BeautifulSoup(html, &#39;lxml&#39;)</span><br><span class="line">img_ul&#x3D;soup.find_all(&#39;ul&#39;, &#123;&quot;class&quot;: &quot;img_list&quot;&#125;)  #找到所有ul标签里class&#x3D;img_list</span><br><span class="line">#从ul中找到所有的img,然后提取img的src属性(图片的网址)</span><br><span class="line">for ul in img_ul:</span><br><span class="line">    imgs&#x3D;ul.find_all(&#39;img&#39;)  #获取所有img图片</span><br><span class="line">    url &#x3D; img[&#39;src&#39;] #url就是所有img图片的地址</span><br><span class="line">    r &#x3D; requests.get(url, stream&#x3D;True)</span><br><span class="line">    image_name &#x3D; url.split(&#39;&#x2F;&#39;)[-1]</span><br><span class="line">    with open(&#39;.&#x2F;img&#x2F;%s&#39; % image_name, &#39;wb&#39;) as f:</span><br><span class="line">        for chunk in r.iter_content(chunk_size&#x3D;128):</span><br><span class="line">            f.write(chunk)</span><br><span class="line">    print(&#39;Saved %s&#39; % image_name)</span><br></pre></td></tr></table></figure>

<h1 id="加速爬虫-多进程分布式"><a href="#加速爬虫-多进程分布式" class="headerlink" title="加速爬虫(多进程分布式)"></a>加速爬虫(多进程分布式)</h1><h2 id="分布式爬虫-multiprocessing"><a href="#分布式爬虫-multiprocessing" class="headerlink" title="分布式爬虫(multiprocessing)"></a>分布式爬虫(multiprocessing)</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">import multiprocessing as mp</span><br><span class="line">import time</span><br><span class="line">from urllib.request import urlopen,urljoin</span><br><span class="line">from bs4 import BeautifulSoup</span><br><span class="line">import re</span><br><span class="line">#基本路径url</span><br><span class="line">base_url&#x3D;&#39;https:&#x2F;&#x2F;mofanpy.com&#x2F;&#39;</span><br><span class="line"></span><br><span class="line">#爬取网页crawl</span><br><span class="line">def crawl(url):</span><br><span class="line">    response &#x3D; urlopen(url)</span><br><span class="line">    time.sleep(0.1)             # slightly delay for downloading</span><br><span class="line">    return response.read().decode()</span><br><span class="line"></span><br><span class="line">#解析网页parse</span><br><span class="line">def parse(html):</span><br><span class="line">    soup&#x3D;BeautifulSoup(html,&#39;lxml&#39;)</span><br><span class="line">    urls&#x3D;soup.find_all(&#39;a&#39;,&#123;&quot;href&quot;:re.compile(&#39;^&#x2F;.+?&#x2F;$&#39;)&#125;)</span><br><span class="line">    title&#x3D;soup.find(&#39;h1&#39;).get_text().strip()</span><br><span class="line">    page_urls &#x3D; set([urljoin(base_url, url[&#39;href&#39;]) for url in urls])  # 去重</span><br><span class="line">    url &#x3D; soup.find(&#39;meta&#39;, &#123;&#39;property&#39;: &quot;og:url&quot;&#125;)[&#39;content&#39;]</span><br><span class="line">    return title, page_urls, url</span><br></pre></td></tr></table></figure>

<h1 id="加速爬虫-异步加载Asyncio"><a href="#加速爬虫-异步加载Asyncio" class="headerlink" title="加速爬虫(异步加载Asyncio)"></a>加速爬虫(异步加载Asyncio)</h1><h2 id="Asyncio库"><a href="#Asyncio库" class="headerlink" title="Asyncio库"></a>Asyncio库</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1.Python的原装库</span><br><span class="line">2.Python3.5之后</span><br><span class="line">3.Python3.5:async和await协同工作</span><br></pre></td></tr></table></figure>

<h2 id="普通代码执行"><a href="#普通代码执行" class="headerlink" title="普通代码执行"></a>普通代码执行</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">import time</span><br><span class="line"></span><br><span class="line">#我们的job是按顺序执行的</span><br><span class="line">#必须执行完job1才能开始执行job2</span><br><span class="line">#而且job1需要1秒的执行时间,而job2需要2秒. 所以总时间是3秒多. </span><br><span class="line"></span><br><span class="line">def job(t):</span><br><span class="line">    print(&#39;Start job:&#39;,t)</span><br><span class="line">    time.sleep(t)               # wait for &quot;t&quot; seconds</span><br><span class="line">    print(&#39;Job&#39;,t,&#39;takes:&#39;,t,&#39;s&#39;)</span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">    [job(t) for t in range(1, 3)]</span><br><span class="line"></span><br><span class="line">t1&#x3D;time.time()</span><br><span class="line">main()</span><br><span class="line">print(&quot;NO async total time:&quot;,time.time()-t1)</span><br></pre></td></tr></table></figure>

<p><img src="/2022/10/28/%E7%88%AC%E8%99%AB/24.png" alt></p>
<h2 id="async版代码执行"><a href="#async版代码执行" class="headerlink" title="async版代码执行"></a>async版代码执行</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">import asyncio</span><br><span class="line">import time</span><br><span class="line"></span><br><span class="line">async def job(t):</span><br><span class="line">    print(&#39;Start job:&#39;,t)</span><br><span class="line">    await asyncio.sleep(t)               # wait for &quot;t&quot; seconds</span><br><span class="line">    print(&#39;Job&#39;,t,&#39;takes:&#39;,t,&#39;s&#39;)</span><br><span class="line"></span><br><span class="line">async def main(loop):</span><br><span class="line">    tasks &#x3D; [</span><br><span class="line">        loop.create_task(job(t)) for t in range(1, 3)</span><br><span class="line">    ]  # 创建任务, 但是不执行</span><br><span class="line">    await asyncio.wait(tasks)  # 执行并等待所有任务完成</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">t1&#x3D;time.time()</span><br><span class="line">loop&#x3D;asyncio.get_event_loop()             # 建立 loop</span><br><span class="line">loop.run_until_complete(main(loop))         # 执行 loop</span><br><span class="line">loop.close()                                # 关闭 loop</span><br><span class="line">print(&quot;Async total time:&quot;, time.time()-t1)</span><br></pre></td></tr></table></figure>

<p><img src="/2022/10/28/%E7%88%AC%E8%99%AB/25.png" alt></p>
<h2 id="aiohttp"><a href="#aiohttp" class="headerlink" title="aiohttp"></a>aiohttp</h2><p><strong>aiohttp介绍:</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1.aiohttp:可以将requests替换成aiohttp(换成异步requests)</span><br><span class="line">2.aiohttp官网:https:&#x2F;&#x2F;docs.aiohttp.org&#x2F;en&#x2F;stable&#x2F;index.html</span><br></pre></td></tr></table></figure>

<p><strong>一般的requests模块:</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">import time</span><br><span class="line">import requests</span><br><span class="line"></span><br><span class="line">#url地址</span><br><span class="line">URL&#x3D;&#39;https:&#x2F;&#x2F;mofanpy.com&#x2F;&#39;</span><br><span class="line"></span><br><span class="line">def normal():</span><br><span class="line">    for i in range(5):</span><br><span class="line">        r&#x3D;requests.get(URL)   #获取url地址</span><br><span class="line">        url&#x3D;r.url</span><br><span class="line">        print(url)</span><br><span class="line"></span><br><span class="line">t1&#x3D;time.time()</span><br><span class="line">normal()</span><br><span class="line">print(&quot;普通的全部时间:&quot;,time.time()-t1)</span><br></pre></td></tr></table></figure>

<p><img src="/2022/10/28/%E7%88%AC%E8%99%AB/26.png" alt></p>
<p><strong>aiohttp模块:</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">import time</span><br><span class="line">import requests</span><br><span class="line">import aiohttp</span><br><span class="line"></span><br><span class="line">async def job(session):</span><br><span class="line">    response &#x3D; await session.get(URL)       # 等待并切换</span><br><span class="line">    return str(response.url)</span><br><span class="line"></span><br><span class="line">async def main(loop):</span><br><span class="line">    async with aiohttp.ClientSession() as session:  # 官网推荐建立 Session 的形式</span><br><span class="line">        tasks &#x3D; [loop.create_task(job(session)) for _ in range(2)]</span><br><span class="line">        finished, unfinished &#x3D; await asyncio.wait(tasks)</span><br><span class="line">        all_results &#x3D; [r.result() for r in finished]  # 获取所有结果</span><br><span class="line">        print(all_results)</span><br><span class="line"></span><br><span class="line">t1 &#x3D; time.time()</span><br><span class="line">loop&#x3D;asyncio.get_event_loop()        #建立loop</span><br><span class="line">loop.run_until_complete(main(loop))  #执行loop</span><br><span class="line">loop.close()  #关闭loop</span><br><span class="line">print(&quot;Async total time:&quot;, time.time() - t1)</span><br></pre></td></tr></table></figure>

<p><img src="/2022/10/28/%E7%88%AC%E8%99%AB/27.png" alt></p>
<h1 id="Selenium"><a href="#Selenium" class="headerlink" title="Selenium"></a>Selenium</h1><h2 id="概念和安装"><a href="#概念和安装" class="headerlink" title="概念和安装"></a>概念和安装</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1.概念:它能够控制你的浏览器,有模有样地学人类&quot;看&quot;网页</span><br><span class="line">2.安装:</span><br><span class="line">	2.1 pip3 install selenium</span><br><span class="line">	2.2 分为linux和macos&#x2F;windows区别</span><br></pre></td></tr></table></figure>

<h2 id="Firefox浏览器插件-Katalon-Recorder"><a href="#Firefox浏览器插件-Katalon-Recorder" class="headerlink" title="Firefox浏览器插件(Katalon Recorder)"></a>Firefox浏览器插件(Katalon Recorder)</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1.下载:https:&#x2F;&#x2F;addons.mozilla.org&#x2F;en-US&#x2F;firefox&#x2F;addon&#x2F;katalon-automation-record&#x2F;</span><br><span class="line">2.打开插件点击record进行网页操作</span><br><span class="line">3.打开插件点击Export进行浏览代码</span><br></pre></td></tr></table></figure>

<h2 id="Python控制浏览器"><a href="#Python控制浏览器" class="headerlink" title="Python控制浏览器"></a>Python控制浏览器</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">from selenium import webdriver</span><br><span class="line"></span><br><span class="line">#打开火狐FireFox浏览器</span><br><span class="line">#selenium.common.exceptions.WebDriverException: Message: ‘chromedriver&#39; 就需要去根据chrome版本下载exe文件然后放在对应位置</span><br><span class="line">driver&#x3D;webdriver.Chrome(executable_path&#x3D;r&quot;D:\python\PyCharm 2021.1.1\plugins\python\helpers\typeshed\scripts\chromedriver.exe&quot;)</span><br><span class="line"></span><br><span class="line">#将火狐插件Export记录的代码放入</span><br><span class="line">driver.get(&quot;https:&#x2F;&#x2F;mofanpy.com&#x2F;&quot;)</span><br><span class="line">driver.find_element_by_xpath(u&quot;&#x2F;&#x2F;img[@alt&#x3D;&#39;强化学习 (Reinforcement Learning)&#39;]&quot;).click()</span><br><span class="line">driver.find_element_by_link_text(&quot;About&quot;).click()</span><br><span class="line">driver.find_element_by_link_text(u&quot;赞助&quot;).click()</span><br><span class="line">driver.find_element_by_link_text(u&quot;数据处理 ▾&quot;).click()</span><br><span class="line">driver.find_element_by_link_text(u&quot;网页爬虫&quot;).click()</span><br><span class="line"></span><br><span class="line">#得到网页html</span><br><span class="line">html&#x3D;driver.page_source</span><br><span class="line">driver.get_screenshot_as_file(&quot;.&#x2F;img&#x2F;screenshot1.png&quot;)</span><br><span class="line">driver.close()</span><br></pre></td></tr></table></figure>

<h1 id="Scrapy爬虫库"><a href="#Scrapy爬虫库" class="headerlink" title="Scrapy爬虫库"></a>Scrapy爬虫库</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src alt></p>

      
      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%88%AC%E8%99%AB/" rel="tag">爬虫</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-算法汇总（Python）" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2022/10/26/%E7%AE%97%E6%B3%95%E6%B1%87%E6%80%BB%EF%BC%88Python%EF%BC%89/" class="article-date">
      <time datetime="2022-10-26T13:32:44.000Z" itemprop="datePublished">2022-10-26</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/10/26/%E7%AE%97%E6%B3%95%E6%B1%87%E6%80%BB%EF%BC%88Python%EF%BC%89/">算法汇总（Python）</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h1 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">寒假放学前必须给我把本科不会的算法思路和算法搞懂！</span><br><span class="line">寒假放学前必须给我把leetcode简单的700道题都刷完!</span><br></pre></td></tr></table></figure>

<h1 id="递归"><a href="#递归" class="headerlink" title="递归"></a>递归</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
      
      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/LeetCode/" rel="tag">LeetCode</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-CS224n斯坦福深度自然语言处理课" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2022/10/15/CS224n%E6%96%AF%E5%9D%A6%E7%A6%8F%E6%B7%B1%E5%BA%A6%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E8%AF%BE/" class="article-date">
      <time datetime="2022-10-15T09:19:09.000Z" itemprop="datePublished">2022-10-15</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/10/15/CS224n%E6%96%AF%E5%9D%A6%E7%A6%8F%E6%B7%B1%E5%BA%A6%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E8%AF%BE/">CS224n斯坦福深度自然语言处理课</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h1 id="课程链接"><a href="#课程链接" class="headerlink" title="课程链接"></a>课程链接</h1><p><a href="https://www.bilibili.com/video/BV1pt411h7aT/?spm_id_from=333.999.0.0" target="_blank" rel="noopener" title="CS224n自然语言处理课">https://www.bilibili.com/video/BV1pt411h7aT/?spm_id_from=333.999.0.0</a></p>
<p><img src="/2022/10/15/CS224n%E6%96%AF%E5%9D%A6%E7%A6%8F%E6%B7%B1%E5%BA%A6%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E8%AF%BE/1.png" alt></p>
<h1 id="学习词汇向量模型-Word2Vec"><a href="#学习词汇向量模型-Word2Vec" class="headerlink" title="学习词汇向量模型:Word2Vec"></a>学习词汇向量模型:Word2Vec</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">1.Word2Vec词汇向量模型：</span><br><span class="line">	1.1 概念:word单词 --&gt; 向量</span><br><span class="line">	1.2 算法:skip-gram(中心词--&gt;周围的词) &#x2F; CBOW(周围的词--&gt;中心词) </span><br><span class="line">	1.3</span><br></pre></td></tr></table></figure>
      
      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag">深度学习</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-软件体系结构" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2022/10/11/%E8%BD%AF%E4%BB%B6%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/" class="article-date">
      <time datetime="2022-10-11T11:53:31.000Z" itemprop="datePublished">2022-10-11</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/10/11/%E8%BD%AF%E4%BB%B6%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/">软件体系结构</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h1 id="软件体系结构"><a href="#软件体系结构" class="headerlink" title="软件体系结构"></a>软件体系结构</h1><h2 id="参考论文"><a href="#参考论文" class="headerlink" title="参考论文"></a>参考论文</h2><p><a href="https://kns.cnki.net/kcms/detail/detail.aspx?dbcode=CJFD&dbname=CJFDAUTO&filename=SJSJ202209001&uniplatform=NZKPT&v=QSzkWHaEKr0sW6-OxHGc5xMEFRGPG1MA1RXR6bJx9UTyscuMa6P43lxv5Zq100uL" target="_blank" rel="noopener" title="面向软件在线升级过程的信任链机制">https://kns.cnki.net/kcms/detail/detail.aspx?dbcode=CJFD&amp;dbname=CJFDAUTO&amp;filename=SJSJ202209001&amp;uniplatform=NZKPT&amp;v=QSzkWHaEKr0sW6-OxHGc5xMEFRGPG1MA1RXR6bJx9UTyscuMa6P43lxv5Zq100uL</a></p>
<h2 id="ppt位置"><a href="#ppt位置" class="headerlink" title="ppt位置"></a>ppt位置</h2><p><a href="https://github.com/Larkkkkkkk/Larkkkkkkk.github.io/tree/master/2022/10/11/%E8%BD%AF%E4%BB%B6%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84" target="_blank" rel="noopener">https://github.com/Larkkkkkkk/Larkkkkkkk.github.io/tree/master/2022/10/11/%E8%BD%AF%E4%BB%B6%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84</a></p>

      
      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E8%BD%AF%E4%BB%B6%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/" rel="tag">软件体系结构</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-双碳大赛-垃圾分类" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2022/10/10/%E5%8F%8C%E7%A2%B3%E5%A4%A7%E8%B5%9B-%E5%9E%83%E5%9C%BE%E5%88%86%E7%B1%BB/" class="article-date">
      <time datetime="2022-10-10T13:18:37.000Z" itemprop="datePublished">2022-10-10</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/10/10/%E5%8F%8C%E7%A2%B3%E5%A4%A7%E8%B5%9B-%E5%9E%83%E5%9C%BE%E5%88%86%E7%B1%BB/">双碳大赛-垃圾分类</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h1 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1.题目:垃圾分类的处理与数据分析</span><br><span class="line">2.技术:机器学习+深度学习</span><br></pre></td></tr></table></figure>

<h1 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1.Kaggle:https:&#x2F;&#x2F;www.kaggle.com&#x2F;account&#x2F;login?phase&#x3D;startRegisterTab&amp;returnUrl&#x3D;%2F</span><br><span class="line">2.UCI：http:&#x2F;&#x2F;archive.ics.uci.edu&#x2F;ml&#x2F;index.php</span><br><span class="line">3.百度:https:&#x2F;&#x2F;github.com&#x2F;GokouRuri7&#x2F;TacoSSD</span><br><span class="line">4.阿里云:https:&#x2F;&#x2F;github.com&#x2F;Hmbb0606&#x2F;ResNet50_Garbage_sorting</span><br></pre></td></tr></table></figure>

<h1 id="torchvision简介"><a href="#torchvision简介" class="headerlink" title="torchvision简介"></a>torchvision简介</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">from torchvision import datasets</span><br><span class="line">from torchvision import models</span><br><span class="line">from torchvision import transforms</span><br><span class="line">from torchvision import utils</span><br><span class="line"># torchvision是pytorch的一个图形库  --&gt; 主要用来构建计算机视觉模型</span><br><span class="line"># torchvision.datasets : 用来进行数据加载(有很多图片数据集)</span><br><span class="line"># torchvision.models: 包含常用的模型结构(含有预训练模型) [AlexNet&#x2F;VGG&#x2F;ResNet&#x2F;SqueezeNet&#x2F;DenseNet]</span><br><span class="line"># torchvision.transforms: 常用的图片变换 [裁剪&#x2F;旋转]  -- 操作对象通常是PIL Image&#x2F;torch.tensor类型的图像数据</span><br><span class="line"># torchvision.utils: 其他一些有用的方法</span><br></pre></td></tr></table></figure>

<h1 id="models包"><a href="#models包" class="headerlink" title="models包"></a>models包</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">#1.使用models中的数据集</span><br><span class="line">##1.快速创建一个权重随机初始化的模型</span><br><span class="line">resnet18&#x3D;models.resnet18()</span><br><span class="line">alexnet&#x3D;models.alexnet()</span><br><span class="line">squeezenet&#x3D;models.squeezenet1_0()</span><br><span class="line">densenet&#x3D;models.densenet161()</span><br><span class="line">##2.通过pretrained&#x3D;True来加载一个别人预训练好的模型</span><br><span class="line">resnet18&#x3D;models.resnet18(pretrained&#x3D;True)  # pretrained设置为True,返回一个使用ImageNet数据集预训练过的模型,会下载权重并存储在缓存路径下</span><br><span class="line">alexnet&#x3D;models.alexnet(pretrained&#x3D;True,progress&#x3D;True)  # progress设置为True,显示下载进度条</span><br></pre></td></tr></table></figure>

<h1 id="transforms包"><a href="#transforms包" class="headerlink" title="transforms包"></a>transforms包</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">#2.使用transforms包(Compose类)</span><br><span class="line">transforms.Compose([</span><br><span class="line">    #1.以输入图像的中心为裁切中心,对图像进行裁切</span><br><span class="line">      #1.1size取值: 1.int型数字表示裁剪成size大小的正方形 2.(h,w)表示裁剪成h*w大小</span><br><span class="line">    transforms.CenterCrop(size&#x3D;10),</span><br><span class="line">    #2.以输入图像的任意点为裁切中心，对图像进行裁切</span><br><span class="line">      #2.1size取值: 1.int型数字表示裁剪成size大小的正方形 2.(h,w)表示裁剪成h*w大小</span><br><span class="line">      #2.2pad_if_needed取值: 当指定当图像小于裁切后的大小时是否进行pad填充</span><br><span class="line">      #2.3padding取值: 1.int型表示每个边缘都进行pad填充 2.Sequence为2表示对左右边界、上下边界进行不同宽度的pad填充&#x2F;Sequence为4表示对左右边界、上下边界进行不同宽度的pad填充</span><br><span class="line">      #2.4fill取值(当padding_mode参数为“constant”时有效): 1.数字类型(torch.Tensor)  2.str类型 3.元组类型(长度为3表示分别对R,G,B三个通道进行填充)</span><br><span class="line">      #2.5padding_mode取值: 1.constant使用一个常量进行填充，由fill参数进行指定 2.edge使用图片最外侧边缘的像素颜色填充 3.reflect使用图片的镜像图像对边缘进行填充，最边缘的像素不重复 4.symmetric使用图片的镜像图像对边缘进行填充,最边缘的像素重复一次</span><br><span class="line">    transforms.RandomCrop(size&#x3D;10,pad_if_needed&#x3D;False),</span><br><span class="line">    #3.图像边缘进行Pad填充</span><br><span class="line">      #3.1padding取值: 1.int型表示每个边缘都进行pad填充 2.Sequence为2表示对左右边界、上下边界进行不同宽度的pad填充&#x2F;Sequence为4表示对左右边界、上下边界进行不同宽度的pad填充</span><br><span class="line">      #3.2fill取值(当padding_mode参数为“constant”时有效): 1.数字类型(torch.Tensor)  2.str类型 3.元组类型(长度为3表示分别对R,G,B三个通道进行填充)</span><br><span class="line">      #3.3padding_mode取值: 1.constant使用一个常量进行填充，由fill参数进行指定 2.edge使用图片最外侧边缘的像素颜色填充 3.reflect使用图片的镜像图像对边缘进行填充，最边缘的像素不重复 4.symmetric使用图片的镜像图像对边缘进行填充,最边缘的像素重复一次</span><br><span class="line">    transforms.Pad(padding&#x3D;10,fill&#x3D;0,padding_mode&#x3D;&#39;constant&#39;)</span><br><span class="line">    transforms.ToTensor()  #图像转换成torch.Tensor格式</span><br><span class="line">    #4.输入只能是torch.Tensor</span><br><span class="line">    transforms.Normalize(mean&#x3D;[0.5,0.5,0.5],std&#x3D;[0.1,0.1,0.1]) #tensor图像进行标准化转换 mean是均值 std是标准差</span><br><span class="line">    transforms.ConvertImageDtype(torch.float),  #tensor图像转换成torch.float类型</span><br><span class="line">    #5.数据类型转换(tensor&#x2F;numpy.ndarray --&gt; PIL Image)</span><br><span class="line">      #5.1 mode取值: 表示输入数据的色彩空间或像素深度 1.None则实际的mode和输入图像的通道数有关 2.RGBA为输入有四个通道 3.RGB为输入有三个通道 4.LA为输入有两个通道</span><br><span class="line">    transforms.ToPILImage(mode&#x3D;None)</span><br><span class="line">    #6.数据类型转换(PIL Image --&gt; tensor)</span><br><span class="line">    image&#x3D;Image.open(r&quot;&#x2F;path&#x2F;to&#x2F;image.jpg&quot;)</span><br><span class="line">    img_tensor&#x3D;transform.ToTensor()(image)</span><br><span class="line">])</span><br></pre></td></tr></table></figure>

<h1 id="datasets包"><a href="#datasets包" class="headerlink" title="datasets包"></a>datasets包</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">#3.datasets包 -- 包中的类几乎都直接&#x2F;间接继承自torch.utils.data.DataSet类 -- 借由datasets包得到的数据集都可以再传递给torch.utils.data.DataLoader(多线程并行加载样本数据)</span><br><span class="line">data&#x3D;torchvision.datasets.ImageNet()</span><br><span class="line">data_loader&#x3D;torch.utils.data.DataLoader(data,batch_size&#x3D;4,shuffle&#x3D;True,num_workers&#x3D;args.nThreads) #并行加载一个ImageNet数据集</span><br><span class="line"></span><br><span class="line">#3.1 加载常用数据集</span><br><span class="line">#root: 表示存放mnist数据集的根目录(如果加载的是训练集这个参数就表示训练集的根目录，如果加载的是测试集这个参数就表示测试集的根目录)</span><br><span class="line">#train: True表示训练集,False表示测试集</span><br><span class="line">#transform: 可调用函数类型(输入图片必然是PIL Image格式的)</span><br><span class="line">#target_transform: 可调用函数类型(类对目标进行变换)</span><br><span class="line">#download:</span><br><span class="line">torchvision.datasets.MNIST(root,train&#x3D;True,transform&#x3D;None,target_transform&#x3D;None,download&#x3D;False)</span><br><span class="line">#3.2 加载用户自定义数据集(ImageFolder类)  --一种方式组织(不同类别的数据放在不同目录下，每个目录的名字就是数据的标签)</span><br><span class="line">torchvision.datasets.ImageFolder(root,transform&#x3D;None,target_transform&#x3D;None,loader&#x3D;default_loader,is_valid_file&#x3D;)</span><br><span class="line">dataset &#x3D; ImageFolder(&quot;train_data&#x2F;&quot;)</span><br><span class="line">print(dataset.classes)  #list类型的类名</span><br><span class="line">print(dataset.class_to_idx)  #list类型的标签</span><br><span class="line">print(dataset.imgs)  #list类型(图片名称和类型组成)</span><br><span class="line">print(dataset[0]) #对应图像的数据</span><br></pre></td></tr></table></figure>

<p><img src="/2022/10/10/%E5%8F%8C%E7%A2%B3%E5%A4%A7%E8%B5%9B-%E5%9E%83%E5%9C%BE%E5%88%86%E7%B1%BB/1.png" alt></p>
<h1 id="utils包"><a href="#utils包" class="headerlink" title="utils包"></a>utils包</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">#4.utils包(一些计算机视觉领域经常用到的操作)</span><br><span class="line">##4.1 make_grid函数  --&gt; 将若干张图像拼成一幅图像</span><br><span class="line">###4.1.1 tensor: 1.Tensor类型必须是四维B×C×H×W,用来表示一组mini-batch的Tensor 2.List类型必须是一组大小相同的图片</span><br><span class="line">###4.1.2 nrow: 表示组成的大图中每一行包括的小图的数量</span><br><span class="line">###4.1.3 padding: 表示每张小图四周的padding大小</span><br><span class="line">###4.1.4 normalize: 1.True表示图像会被标准化(控制在(0,1)范围内，最大值最小值通过batch中所有图像的最大值最小值决定)</span><br><span class="line">###4.1.5 value_range: 用元组(min,max)作为标准化图像时用到的最大值和最小值</span><br><span class="line">###4.1.6 scale_each: 1.True表示每个图片使用自己的最值</span><br><span class="line">###4.1.7 pad_value: 表示pad填充的像素的颜色</span><br><span class="line">torchvision.utils.make_grid(tensor, nrow&#x3D;8, padding&#x3D;2, normalize&#x3D;False,value_range&#x3D;None, scale_each&#x3D;False, pad_value&#x3D;0)</span><br><span class="line"></span><br><span class="line">##4.2 save_image函数  --&gt; 将给定的Tensor保存成图片</span><br><span class="line">###4.2.1 tensor: 1.如果给定的是一个mini-batch的Tensor,会自动调用make_grid函数将图片组合成网格形式再保存 2.List类型</span><br><span class="line">###4.2.2 fp: 将图片保存到该参数指定的文件路径&#x2F;文件对象 1.string类型&#x2F;文件对象(file object)类型</span><br><span class="line">###4.2.3 format: 1.fp为文件名，则忽略 2.fp为文本对象，则参数经常被使用</span><br><span class="line">torchvision.utils.save_image(tensor,fp,format&#x3D;None)</span><br><span class="line">##4.3 draw_bounding_boxes函数 --&gt; 将给定的图像中画出bounding box。输入的图像必须是uint8类型，且范围在0到255之间</span><br><span class="line">###4.3.1 image:Tensor类型 表示被操作的图片 Tensor大小为C×H×W，dtype类型为uint8</span><br><span class="line">###4.3.2 boxes:Tensor类型 如果一张图像上有N个bounding box (box的四个点以(xmin, ymin, xmax, ymax)的形式进行组织) --注意，这个坐标是图像上的绝对坐标。</span><br><span class="line">torchvision.utils.draw_bounding_boxes(image,boxes,labels&#x3D;None,colors,fill&#x3D;False,width&#x3D;1,font&#x3D;None,font_size&#x3D;10)</span><br><span class="line"></span><br><span class="line">##4.4 draw_segmentation_masks函数</span><br><span class="line">###4.4.1 image：Tensor类型，大小是(3, H, W)，类型是uint8</span><br><span class="line">###4.4.2 masks：Tensor类型，大小是(num_masks, H, W)或(H, W)，dtype是bool类型</span><br><span class="line">###4.4.3 alpha：float类型，大小在0到1之间，表示mask的透明度，0表示完全透明，1表示不透明</span><br><span class="line">###4.4.4 colors：list类型或None。list类型来指定每个mask的颜色，颜色可以用字符串&quot;red&quot;或&quot;#FF00FF&quot;来表示，也可以用RGB元组(0, 255, 255)表示</span><br><span class="line">torchvision.utils.draw_segmentation_masks(image, masks, alpha&#x3D;0.8, colors&#x3D;None)</span><br></pre></td></tr></table></figure>

      
      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag">深度学习</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-PyTorch深度学习实践" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2022/10/07/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5/" class="article-date">
      <time datetime="2022-10-07T10:50:29.000Z" itemprop="datePublished">2022-10-07</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/10/07/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5/">PyTorch深度学习实践</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h1 id="安装PyTorch"><a href="#安装PyTorch" class="headerlink" title="安装PyTorch"></a>安装PyTorch</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1.GPU版本</span><br><span class="line">2.CPU版本</span><br></pre></td></tr></table></figure>

      
      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag">深度学习</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-深度学习" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2022/10/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="article-date">
      <time datetime="2022-10-07T09:46:43.000Z" itemprop="datePublished">2022-10-07</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/10/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h1 id="深度学习入门路线"><a href="#深度学习入门路线" class="headerlink" title="深度学习入门路线"></a>深度学习入门路线</h1><p><img src="/2022/10/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/1.png" alt></p>
<h1 id="深度学习实战路线"><a href="#深度学习实战路线" class="headerlink" title="深度学习实战路线"></a>深度学习实战路线</h1><p><img src="/2022/10/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/2.1.png" alt></p>
<h1 id="深度学习必看书籍"><a href="#深度学习必看书籍" class="headerlink" title="深度学习必看书籍"></a>深度学习必看书籍</h1><p><img src="/2022/10/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/2.png" alt></p>
<h1 id="前馈神经网络"><a href="#前馈神经网络" class="headerlink" title="前馈神经网络"></a>前馈神经网络</h1><p><strong>总体框架</strong></p>
<p><img src="/2022/10/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/3.png" alt></p>
<h2 id="神经元"><a href="#神经元" class="headerlink" title="神经元"></a>神经元</h2><p><strong>人工神经元:</strong></p>
<p><img src="/2022/10/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/4.png" alt></p>
<p><strong>激活函数性质</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1.连续并可导的非线性函数</span><br><span class="line">2.激活函数及其导数要尽可能简单,有利于提高网络计算效率</span><br><span class="line">3.激活函数的导函数的值域要在一个合适的空间(不能太大也不能太小,否则会影响训练的效率和稳定性)</span><br></pre></td></tr></table></figure>

<h3 id="Sigmoid函数-S型曲线函数"><a href="#Sigmoid函数-S型曲线函数" class="headerlink" title="Sigmoid函数(S型曲线函数)"></a>Sigmoid函数(S型曲线函数)</h3><p><strong>sigmoid函数的公式</strong></p>
<p><img src="/2022/10/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/7.png" alt></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1.分为logistic函数和Tanh函数</span><br><span class="line">	1.1 logistic函数(值域&gt;0):</span><br><span class="line">	1.2 Tanh函数(值域(-1,1)):</span><br><span class="line">2.sigmoid函数的性质:</span><br><span class="line">  2.1 sigmoid函数是饱和函数[x&gt;-∞和x-&gt;+∞时,其f&#39;(x)-&gt;0]</span><br><span class="line">  2.2 Tanh函数是零中心化的,logistic函数输出恒大于0的</span><br></pre></td></tr></table></figure>

<p><strong>sigmoid两种函数的图像:</strong></p>
<p><img src="/2022/10/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/5.png" alt></p>
<h3 id="ReLU函数-斜坡函数-修正线性单元"><a href="#ReLU函数-斜坡函数-修正线性单元" class="headerlink" title="ReLU函数(斜坡函数/修正线性单元)"></a>ReLU函数(斜坡函数/修正线性单元)</h3><p><strong>ReLU函数公式</strong></p>
<p><img src="/2022/10/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/8.png" alt></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1.优点:</span><br><span class="line">  1.1 计算更加高效(采用ReLU的神经元只需要进行加、乘、比较操作) </span><br><span class="line">  1.2 具有生物学合理性(单侧抑制、宽兴奋边界) -- 能够保证大约50%的神经元会处于激活状态</span><br><span class="line">  1.3 ReLU函数为左饱和函数+x&gt;0时f&#39;(x)&#x3D;1,在一定程度上缓解了神经网络的梯度消失问题,加速梯度下降的收敛速度</span><br><span class="line">2.缺点:</span><br><span class="line">  2.1 输出是非零中心化的,给后一层的神经网络引入偏置偏移,会影响梯度下降的速度 </span><br><span class="line">	  2.2 死亡ReLU问题:ReLU神经元在训练时比较容易&quot;死亡&quot;(如果有一次不恰当的更新后,第一个隐藏层中的某个ReLU神经元在所有训练数据上都不能被激活,在以后的训练过程中永远不能被激活)</span><br></pre></td></tr></table></figure>

<h4 id="带泄露的ReLU"><a href="#带泄露的ReLU" class="headerlink" title="带泄露的ReLU"></a>带泄露的ReLU</h4><p><img src="/2022/10/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/10.png" alt></p>
<h4 id="带参数的ReLU"><a href="#带参数的ReLU" class="headerlink" title="带参数的ReLU"></a>带参数的ReLU</h4><p><img src="/2022/10/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/11.png" alt></p>
<h4 id="ELU函数"><a href="#ELU函数" class="headerlink" title="ELU函数"></a>ELU函数</h4><p><img src="/2022/10/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/12.png" alt></p>
<h4 id="Softplus函数"><a href="#Softplus函数" class="headerlink" title="Softplus函数"></a>Softplus函数</h4><p><img src="/2022/10/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/13.png" alt></p>
<p><strong>四种函数图对比:</strong></p>
<p><img src="/2022/10/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/9.png" alt></p>
<h3 id="Swish函数"><a href="#Swish函数" class="headerlink" title="Swish函数"></a>Swish函数</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1.自门控激活函数</span><br><span class="line">2.通过设置得到1&#x2F;0 --&gt; 门的状态为&quot;开&quot;&#x2F;&quot;关&quot;</span><br></pre></td></tr></table></figure>

<p><img src="/2022/10/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/14.png" alt></p>
<h3 id="GELU函数"><a href="#GELU函数" class="headerlink" title="GELU函数"></a>GELU函数</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1.高斯误差线性单元 --&gt; 通过门控机制来调整其输出值的激活函数</span><br><span class="line">2.特殊的Swish函数</span><br></pre></td></tr></table></figure>

<p><img src="/2022/10/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/15.png" alt></p>
<h3 id="Maxout单元"><a href="#Maxout单元" class="headerlink" title="Maxout单元"></a>Maxout单元</h3><p><img src="/2022/10/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/16.png" alt></p>
<h2 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h2><p><strong>三种网络结构:</strong></p>
<p><img src="/2022/10/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/17.png" alt></p>
<h3 id="前馈神经网络-1"><a href="#前馈神经网络-1" class="headerlink" title="前馈神经网络"></a>前馈神经网络</h3><h1 id="反向传播算法"><a href="#反向传播算法" class="headerlink" title="反向传播算法"></a>反向传播算法</h1><h2 id><a href="#" class="headerlink" title="##"></a>##</h2>
      
      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag">深度学习</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-机器学习实战之工业蒸汽" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/" class="article-date">
      <time datetime="2022-09-27T12:44:48.000Z" itemprop="datePublished">2022-09-27</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/">机器学习实战之工业蒸汽</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h1 id="题目基本情况"><a href="#题目基本情况" class="headerlink" title="题目基本情况"></a>题目基本情况</h1><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1.数据集:</span><br><span class="line">https:&#x2F;&#x2F;tianchi.aliyun.com&#x2F;dataset&#x2F;dataDetail?dataId&#x3D;130516</span><br></pre></td></tr></table></figure>

<h1 id="数据探索"><a href="#数据探索" class="headerlink" title="数据探索"></a>数据探索</h1><h2 id="理论知识"><a href="#理论知识" class="headerlink" title="理论知识"></a>理论知识</h2><p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/1.png" alt></p>
<h2 id="赛题数据探索"><a href="#赛题数据探索" class="headerlink" title="赛题数据探索"></a>赛题数据探索</h2><h3 id="导入工具包"><a href="#导入工具包" class="headerlink" title="导入工具包"></a>导入工具包</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import seaborn as sns</span><br><span class="line">import warnings</span><br><span class="line">from scipy import stats</span><br><span class="line">#1.读取数据</span><br><span class="line">train_data_file &#x3D; &quot;zhengqi_train.txt&quot;</span><br><span class="line">test_data_file &#x3D;  &quot;zhengqi_test.txt&quot;</span><br><span class="line">train_data &#x3D; pd.read_csv(train_data_file, sep&#x3D;&#39;\t&#39;, encoding&#x3D;&#39;utf-8&#39;) #训练集数据共有2888个样本(V0-V37共38个特征变量)  -- 有target字段</span><br><span class="line">test_data &#x3D; pd.read_csv(test_data_file, sep&#x3D;&#39;\t&#39;, encoding&#x3D;&#39;utf-8&#39;) #测试集数据共有1925个样本(V0-V37共有38个特征变量)  -- 无target字段</span><br></pre></td></tr></table></figure>

<h3 id="可视化数据分布"><a href="#可视化数据分布" class="headerlink" title="可视化数据分布"></a>可视化数据分布</h3><h4 id="箱型图-boxplot"><a href="#箱型图-boxplot" class="headerlink" title="箱型图(boxplot)"></a>箱型图(boxplot)</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">##2.1 箱型图boxplot(所有特征变量)</span><br><span class="line">columns&#x3D;train_data.columns.tolist()[:39]  #前39列</span><br><span class="line">fig&#x3D;plt.figure(figsize&#x3D;(20,40)) #指定绘图对象宽度和高度</span><br><span class="line">for i in range(38):</span><br><span class="line">    plt.subplot(8,5,i+1) #指定8行5列子图</span><br><span class="line">    sns.boxplot(train_data[columns[i]],orient&#x3D;&quot;h&quot;,width&#x3D;0.5)  #orient是v(垂直)&#x2F;h(水平)</span><br></pre></td></tr></table></figure>

<p><strong>整体的箱型图:</strong></p>
<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/2.1.1.png" alt></p>
<p><strong>V0一个的箱型图:</strong></p>
<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/2.1.2.png" alt></p>
<h4 id="直方图-distplot-和Q-Q图-probplot"><a href="#直方图-distplot-和Q-Q图-probplot" class="headerlink" title="直方图(distplot)和Q-Q图(probplot)"></a>直方图(distplot)和Q-Q图(probplot)</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">##2.3 直方图distplot和Q-Q图probplot(数据的分位数和正态分布的分位数对比参照) -- 如果数据符合正态分布 会在qq图内两条线重合</span><br><span class="line">train_cols&#x3D;6 #列</span><br><span class="line">train_rows&#x3D;len(train_data.columns)  #行</span><br><span class="line">plt.figure(figsize&#x3D;(train_cols,train_rows)) #指定绘图对象宽度和高度</span><br><span class="line">i&#x3D;0</span><br><span class="line">for col in train_data.columns:</span><br><span class="line">    i+&#x3D;1</span><br><span class="line">    ax&#x3D;plt.subplot(train_rows,train_cols,i) #指定r行c列子图第i个位置</span><br><span class="line">    sns.distplot(train_data[col],fit&#x3D;stats.norm)  #fit设置函数图像(与原图进行比较)</span><br><span class="line">    i+&#x3D;1</span><br><span class="line">    ax&#x3D;plt.subplot(train_rows,train_cols,i)  # 指定r行c列子图第i+1个位置</span><br><span class="line">    res&#x3D;stats.probplot(train_data[col],plot&#x3D;plt)  # fit设置函数图像(与原图进行比较)</span><br></pre></td></tr></table></figure>

<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/2.2.png" alt></p>
<h4 id="KDE分布图-核密度估计kdeplot"><a href="#KDE分布图-核密度估计kdeplot" class="headerlink" title="KDE分布图(核密度估计kdeplot)"></a>KDE分布图(核密度估计kdeplot)</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">##2.4 KDE分布图kdeplot(核密度估计) --对直方图的加窗平滑(可以查看对比训练集和测试集中特征变量的分布情况)</span><br><span class="line">dist_cols&#x3D;6 #列</span><br><span class="line">dist_rows&#x3D;len(test_data.columns)  #行</span><br><span class="line">plt.figure(figsize&#x3D;(train_cols,train_rows)) #指定绘图对象宽度和高度</span><br><span class="line">i&#x3D;1</span><br><span class="line">for col in test_data.columns:</span><br><span class="line">    ax&#x3D;plt.subplot(dist_rows,dist_cols,i) #指定r行c列子图第i个位置</span><br><span class="line">    ax&#x3D;sns.kdeplot(train_data[col],color&#x3D;&quot;Red&quot;,shade&#x3D;True)</span><br><span class="line">    ax&#x3D;sns.kdeplot(test_data[col], color&#x3D;&quot;Blue&quot;, shade&#x3D;True)</span><br><span class="line">    ax.set_xlabel(col)  #横坐标名称</span><br><span class="line">    ax.set_ylabel(&quot;Frequency&quot;)  #纵坐标名称</span><br><span class="line">    ax&#x3D;ax.legend([&quot;训练集&quot;,&quot;测试集&quot;])  #两条曲线的名称</span><br><span class="line">    i&#x3D;i+1</span><br></pre></td></tr></table></figure>

<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/2.3.png" alt></p>
<h4 id="线性回归关系图-regplot"><a href="#线性回归关系图-regplot" class="headerlink" title="线性回归关系图(regplot)"></a>线性回归关系图(regplot)</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">##2.5 线性回归关系图regplot(分析变量之间的线性回归关系)</span><br><span class="line">fcols&#x3D;6 #列</span><br><span class="line">frows&#x3D;len(test_data.columns)  #行</span><br><span class="line">plt.figure(figsize&#x3D;(fcols,frows)) #指定绘图对象宽度和高度</span><br><span class="line">i&#x3D;0</span><br><span class="line">for col in test_data.columns:</span><br><span class="line">    i&#x3D;i+1</span><br><span class="line">    ax&#x3D;plt.subplot(frows,fcols,i) #指定r行c列子图第i个位置</span><br><span class="line">    sns.regplot(x&#x3D;col,y&#x3D;&#39;target&#39;,data&#x3D;train_data,ax&#x3D;ax,scatter_kws&#x3D;&#123;&#39;marker&#39;:&#39;.&#39;,&#39;s&#39;:3,&#39;alpha&#39;:0.3&#125;,line_kws&#x3D;&#123;&#39;color&#39;:&#39;k&#39;&#125;)</span><br><span class="line">    plt.xlabel(col)</span><br><span class="line">    plt.ylabel(&#39;target&#39;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/2.4.png" alt></p>
<h3 id="查看特征变量的相关性"><a href="#查看特征变量的相关性" class="headerlink" title="查看特征变量的相关性"></a>查看特征变量的相关性</h3><h4 id="计算相关性系数-data-corr"><a href="#计算相关性系数-data-corr" class="headerlink" title="计算相关性系数(data.corr)"></a>计算相关性系数(data.corr)</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#3.查看特征变量的相关性</span><br><span class="line">##3.1 计算相关性系数corr --&gt; KDE图中拿训练集和测试集中分布不一致的特征变量进行删除(V5,V9,V11,V17,V22,V28) --&gt; 计算剩余特征变量和target变量的相关性系数</span><br><span class="line">pd.set_option(&#39;display.max_columns&#39;,10)  #显示10列 默认none就是最多</span><br><span class="line">pd.set_option(&#39;display.max_rows&#39;,10) #显示10行</span><br><span class="line">data_train1&#x3D;train_data.drop([&#39;V5&#39;,&#39;V9&#39;,&#39;V11&#39;,&#39;V17&#39;,&#39;V22&#39;,&#39;V28&#39;],axis&#x3D;1)  #删除那些测试集和训练集分布不一致的特征向量</span><br><span class="line">train_corr&#x3D;data_train1.corr() #corr给出任意两个变量之间的相关系数</span><br><span class="line">print(train_corr)</span><br></pre></td></tr></table></figure>

<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/2.5.png" alt></p>
<h4 id="相关热力图-sns-heatmap"><a href="#相关热力图-sns-heatmap" class="headerlink" title="相关热力图(sns.heatmap)"></a>相关热力图(sns.heatmap)</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">##3.2 热力图heatmap</span><br><span class="line">ax&#x3D;plt.subplots(figsize&#x3D;(20,16)) #调整画布大小</span><br><span class="line">ax&#x3D;sns.heatmap(train_corr,vmax&#x3D;.8,square&#x3D;True,annot&#x3D;True)  #vmax和vmin是图例中最大值和最小值的显示值 square为热力图矩阵小块形状(T以列名为标签名)  annot为T表示每个方格写入数据</span><br></pre></td></tr></table></figure>

<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/2.6.png" alt></p>
<h4 id="根据相关系数筛选特征变量-相关性选择-树模型"><a href="#根据相关系数筛选特征变量-相关性选择-树模型" class="headerlink" title="根据相关系数筛选特征变量(相关性选择/树模型)"></a>根据相关系数筛选特征变量(相关性选择/树模型)</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">###3.3.1 寻找k个与target变量最相关的特征变量(K&#x3D;10)</span><br><span class="line">columns&#x3D;train_corr.nlargest(10,&#39;target&#39;)  #利用相关系数.nlargest()获取</span><br><span class="line">columnsindex&#x3D;columns[&#39;target&#39;].index   # 获取符合的下标&#39;V0&#39;&#x2F;&#39;V1&#39;&#x2F;&#39;V8&#39;&#x2F;&#39;V27&#39;&#x2F;&#39;V31&#39;&#x2F;&#39;V2&#39;&#x2F;&#39;V4&#39;&#x2F;&#39;V12&#39;&#x2F;&#39;V16&#39;</span><br><span class="line">columnsvalue&#x3D;train_data[columnsindex].values  #找到k个特征变量在训练集中的值</span><br><span class="line">cm&#x3D;np.corrcoef(columnsvalue) #皮尔逊积矩相关系数--计算两个变量x和y之间的线性相关(-1到1)</span><br><span class="line">ax&#x3D;plt.subplots(figsize&#x3D;(10,10)) #调整画布大小</span><br><span class="line">ax&#x3D;sns.heatmap(train_data[columnsindex].corr(),annot&#x3D;True,square&#x3D;True) #k个相关值画热力图</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/2.7.png" alt></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">###3.3.2 找出与target变量的相关系数大于0.5的特征变量</span><br><span class="line">corrs&#x3D;train_data.corr() #获取训练数据集的相关系数</span><br><span class="line">corrres&#x3D;corrs.index[abs(corrs[&#39;target&#39;])&gt;0.5] # 获取符合的下标 V0&#39;&#x2F;&#39;V1&#39;&#x2F;&#39;V2&#39;&#x2F;&#39;V3&#39;&#x2F;&#39;V4&#39;&#x2F;&#39;V8&#39;&#x2F;&#39;V12&#39;&#x2F;&#39;V16&#39;&#x2F;&#39;V27&#39;&#x2F;&#39;V31&#39;&#x2F;&#39;V37&#39;</span><br><span class="line">ax&#x3D;plt.figure(figsize&#x3D;(10,10))</span><br><span class="line">ax&#x3D;sns.heatmap(train_data[corrres].corr(),annot&#x3D;True,cmap&#x3D;&quot;RdYlGn&quot;) #cmap设置颜色</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/2.8.png" alt></p>
<h4 id="Box-Cox变换"><a href="#Box-Cox变换" class="headerlink" title="Box-Cox变换"></a>Box-Cox变换</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">###3.3.3 Box-Cox变换(线性回归基于正态分布 --&gt; 统计分析将数据转换为符合正态分布)</span><br><span class="line">####1. 合并数据</span><br><span class="line">drop_columns &#x3D; [&#39;V5&#39;,&#39;V9&#39;,&#39;V11&#39;,&#39;V17&#39;,&#39;V22&#39;,&#39;V28&#39;] #KDE图发现训练集和测试集中这几个特征变量不一致 需要删除</span><br><span class="line">train_droptarget&#x3D;train_data.drop([&#39;target&#39;],axis&#x3D;1)  #按照axis&#x3D;1列删除了target的行和列(因为train里面比test多了target列)</span><br><span class="line">data_all&#x3D;pd.concat([train_droptarget,test_data])  #默认纵向拼接train和test两个训练集(列不变 行数会变多)</span><br><span class="line">data_all.drop(drop_columns,axis&#x3D;1,inplace&#x3D;True)  #按照axis&#x3D;1列删除那些列</span><br><span class="line">####2. 归一化(1.MinMaxScaler函数&#x2F;2.min-max离差标准化)</span><br><span class="line">colunms_list&#x3D;list(data_all.columns)  #对合并后的每列数据合成一个list列表</span><br><span class="line">def scale_minmax(col):  #定义一个标准化的函数用于apply方法的第一个参数</span><br><span class="line">    return (col-col.min())&#x2F;(col.max()-col.min())</span><br><span class="line">data_all[colunms_list]&#x3D;data_all[colunms_list].apply(scale_minmax,axis&#x3D;0) # axis&#x3D;0对每一列数据应用函数</span><br><span class="line"></span><br><span class="line">####3. Box-Cox变换</span><br><span class="line">data_all, lambda0 &#x3D; boxcox1p(data_all)</span><br><span class="line"></span><br><span class="line">####4. 重新画Q-Q图</span><br><span class="line">data_all_cols&#x3D;6 #列</span><br><span class="line">data_all_rows&#x3D;len(data_all.columns)  #行</span><br><span class="line">plt.figure(figsize&#x3D;(data_all_cols,data_all_rows)) #指定绘图对象宽度和高度</span><br><span class="line">i&#x3D;0</span><br><span class="line">for col in data_all.columns:</span><br><span class="line">    i+&#x3D;1</span><br><span class="line">    ax&#x3D;plt.subplot(data_all_rows,data_all_cols,i) #指定r行c列子图第i个位置</span><br><span class="line">    sns.distplot(data_all[col],fit&#x3D;stats.norm)  #fit设置函数图像(与原图进行比较)</span><br><span class="line">    i+&#x3D;1</span><br><span class="line">    ax&#x3D;plt.subplot(data_all_rows,data_all_cols,i)  # 指定r行c列子图第i+1个位置</span><br><span class="line">    res&#x3D;stats.probplot(data_all[col],plot&#x3D;plt)  # fit设置函数图像(与原图进行比较)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h1 id="特征工程"><a href="#特征工程" class="headerlink" title="特征工程"></a>特征工程</h1><h2 id="特征工程的重要性和处理"><a href="#特征工程的重要性和处理" class="headerlink" title="特征工程的重要性和处理"></a>特征工程的重要性和处理</h2><p><strong>特征工程的重要性:</strong></p>
<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.1.png" alt></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"> 1.特征工程处理流程:</span><br><span class="line">1.1 去掉无用特征</span><br><span class="line">1.2 去掉冗余特征(如共线特征)</span><br><span class="line">   1.3 生成新特征(利用存在的特征、转换特征、内容中的特征、其他数据源)</span><br><span class="line">1.4 特征转换(数值化、类别转换、归一化等)</span><br><span class="line">1.5 特征处理(异常值、最大值、最小值、缺失值)</span><br></pre></td></tr></table></figure>

<h2 id="数据预处理和特征处理"><a href="#数据预处理和特征处理" class="headerlink" title="数据预处理和特征处理"></a>数据预处理和特征处理</h2><h3 id="数据预处理-数据采集-数据清洗-数据采样"><a href="#数据预处理-数据采集-数据清洗-数据采样" class="headerlink" title="数据预处理(数据采集+数据清洗+数据采样)"></a>数据预处理(数据采集+数据清洗+数据采样)</h3><h4 id="数据采集"><a href="#数据采集" class="headerlink" title="数据采集"></a>数据采集</h4><h4 id="数据清洗"><a href="#数据清洗" class="headerlink" title="数据清洗"></a>数据清洗</h4><h4 id="数据采样"><a href="#数据采样" class="headerlink" title="数据采样"></a>数据采样</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1.数据采样的原因:经过采集和清洗之后正负样本是不均衡的 --&gt; 数据采样</span><br><span class="line">2.数据采样的方法:</span><br><span class="line">  2.1 随机采样: 可能随机采样得到的数据很不均匀</span><br><span class="line">  2.2 分层采样: </span><br><span class="line">3.正负样本不均衡的处理办法:</span><br><span class="line">  3.1 正样本&gt;负样本 + 量特别大 : 下采样(downsampling)的方法</span><br><span class="line">  3.2 正样本&gt;负样本 + 量不大 : 上采样(oversampling)的方法(图像识别的镜像和旋转&#x2F;修改损失函数设置样本权重)</span><br></pre></td></tr></table></figure>

<h3 id="特征处理"><a href="#特征处理" class="headerlink" title="特征处理"></a>特征处理</h3><p><strong>特征处理小结:</strong></p>
<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.5.png" alt></p>
<h4 id="标准化-StandardScaler类"><a href="#标准化-StandardScaler类" class="headerlink" title="标准化(StandardScaler类)"></a>标准化(StandardScaler类)</h4><p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.1.png" alt></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1.标准化: 依照特征矩阵的列去处理数据[通过求标准分数的方法将特征--&gt;标准正态分布]</span><br><span class="line">2.使用场景:</span><br><span class="line">	2.1 数据存在异常值和较多噪声</span><br></pre></td></tr></table></figure>

<h4 id="区间缩放法-MinMaxScaler类"><a href="#区间缩放法-MinMaxScaler类" class="headerlink" title="区间缩放法(MinMaxScaler类)"></a>区间缩放法(MinMaxScaler类)</h4><p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.4.png" alt></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1.区间缩放法: 利用两个最值(最大值和最小值)进行缩放 [归一化的一种]</span><br></pre></td></tr></table></figure>

<h4 id="归一化-Normalizer类"><a href="#归一化-Normalizer类" class="headerlink" title="归一化(Normalizer类)"></a>归一化(Normalizer类)</h4><p><strong>公式:</strong></p>
<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.3.png" alt></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1.归一化: 样本的特征值--&gt;同一量纲，数据--&gt;[0,1]&#x2F;[a,b]区间内</span><br><span class="line">2.使用场景:</span><br><span class="line">	2.1 输出结果范围有要求</span><br><span class="line">    2.2 数据较为稳定，不存在极端的最大值&#x2F;最小值</span><br></pre></td></tr></table></figure>

<h4 id="定量特征二值化-Binarizer类"><a href="#定量特征二值化-Binarizer类" class="headerlink" title="定量特征二值化(Binarizer类)"></a>定量特征二值化(Binarizer类)</h4><p><strong>公式:</strong></p>
<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.2.png" alt></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1. 定量特征二值化: 核心在于设定一个阈值(&gt;阈值的赋值为1,≤阈值的赋值为0)</span><br></pre></td></tr></table></figure>

<h4 id="定性特征哑编码-OneHotEncoder类"><a href="#定性特征哑编码-OneHotEncoder类" class="headerlink" title="定性特征哑编码(OneHotEncoder类)"></a>定性特征哑编码(OneHotEncoder类)</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1.哑变量&#x2F;虚拟变量(Dummy Variable):通常是认为虚设的变量(0&#x2F;1),用来反映某个变量的不同属性。</span><br><span class="line">2.哑变量目的: 原本不能定量处理的变量进行量化，从而评估定性因素对因变量的影响</span><br><span class="line">	2.1 例如: 变量&quot;职业&quot;取值分别为工人、农民、学生、企业职员、其他(5种选项) --&gt; 工人定义为(0,0,0,1) 那么农民就是(0,0,1,0) 学生就是(0,1,0,0) 企业职工就是(1,0,0,0)</span><br><span class="line"></span><br><span class="line">2.哑编码: 类别变量 --&gt; 哑变量</span><br><span class="line">3.哑编码规则:对于有n个类别属性的变量,通常以1个类别特征为参照，产生n-1个哑变量</span><br></pre></td></tr></table></figure>

<h4 id="缺失值处理-impute库的SimpleImputer类"><a href="#缺失值处理-impute库的SimpleImputer类" class="headerlink" title="缺失值处理(impute库的SimpleImputer类)"></a>缺失值处理(impute库的SimpleImputer类)</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1.用Pandas读取后特征均为NaN(数据缺失)</span><br><span class="line">2.使用impute库的SimpleImputer类</span><br></pre></td></tr></table></figure>

<h4 id="数据转换"><a href="#数据转换" class="headerlink" title="数据转换"></a>数据转换</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1.基于多项式的多项式转换(PolynomialFeatures类):参数degree为度(默认值为2)</span><br><span class="line">2.基于对数函数的对数变换:基于单变元函数的数据转换可以使用统一的方法完成(FunctionTransformer类)</span><br><span class="line">3.基于指数函数:</span><br></pre></td></tr></table></figure>

<h2 id="特征降维"><a href="#特征降维" class="headerlink" title="特征降维"></a>特征降维</h2><h3 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h3><p><strong>特征选择三类方法:</strong></p>
<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.6.png" alt></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1.特征选择概念:比较简单粗暴，就是映射函数直接将不重要的特征(×)，不过会造成特征信息的丢失，不利用模型精度</span><br><span class="line">2.特征选择方法:</span><br><span class="line">  2.1 过滤法(Filter):按照发散性&#x2F;相关性对各个特征进行评分,通过设定阈值&#x2F;待选择阈值的个数来选择特征</span><br><span class="line">  2.2 包装法(Wrapper):按照目标函数(AUC&#x2F;MSE)每次选择&#x2F;排除若干特征</span><br><span class="line">	  2.3 嵌入法(Embedded):使用某些算法和模型进行训练,得到各个特征的权值系数，根据系数从大到小选择特征</span><br></pre></td></tr></table></figure>

<h3 id="线性降维"><a href="#线性降维" class="headerlink" title="线性降维"></a>线性降维</h3><p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.8.png" alt></p>
<h2 id="赛题特征工程"><a href="#赛题特征工程" class="headerlink" title="赛题特征工程"></a>赛题特征工程</h2><h3 id="异常值分析-箱线图找出异常删除异常"><a href="#异常值分析-箱线图找出异常删除异常" class="headerlink" title="异常值分析(箱线图找出异常删除异常)"></a>异常值分析(箱线图找出异常删除异常)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">##箱型图</span><br><span class="line">plt.figure(figsize&#x3D;(18,10))</span><br><span class="line">plt.boxplot(x&#x3D;train_data.values,labels&#x3D;train_data.columns) #标签就是训练集的各个列</span><br><span class="line">plt.hlines([-7.5,7.5],0,40,colors&#x3D;&#39;r&#39;)  #从-7.5到7.5绘制水平线 0和40就是这条线从第几个Vx开始画到第Vx个特征</span><br><span class="line">plt.show()</span><br><span class="line">##删除异常值(通过箱型图可以查看到明显的异常值【比如V9变量】)</span><br><span class="line">train_data&#x3D;train_data[train_data[&#39;V9&#39;]&gt;-7.5]</span><br><span class="line">test_data&#x3D;test_data[test_data[&#39;V9&#39;]&gt;-7.5]</span><br><span class="line">print(train_data.describe())</span><br><span class="line">print(test_data.describe())</span><br></pre></td></tr></table></figure>

<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.9.png" alt></p>
<h3 id="归一化-最大值和最小值"><a href="#归一化-最大值和最小值" class="headerlink" title="归一化(最大值和最小值)"></a>归一化(最大值和最小值)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">##归一化(最大值和最小值)  --放缩到(0,1区间)</span><br><span class="line">features_columns&#x3D;[col for col in train_data.columns if col not in [&#39;target&#39;]]   #从V0到V37</span><br><span class="line">min_max_scaler&#x3D;preprocessing.MinMaxScaler().fit(train_data[features_columns])</span><br><span class="line"></span><br><span class="line">train_data_scaler&#x3D;min_max_scaler.transform(train_data[features_columns])</span><br><span class="line">test_data_scaler&#x3D;min_max_scaler.transform(test_data[features_columns])</span><br><span class="line"></span><br><span class="line">train_data_scaler&#x3D;pd.DataFrame(train_data_scaler) #将训练集数据弄成DF格式</span><br><span class="line">train_data_scaler.columns&#x3D;features_columns</span><br><span class="line"></span><br><span class="line">test_data_scaler&#x3D;pd.DataFrame(test_data_scaler) #将测试集数据弄成DF格式</span><br><span class="line">test_data_scaler.columns&#x3D;features_columns</span><br><span class="line"></span><br><span class="line">train_data_scaler[&#39;target&#39;] &#x3D; train_data[&#39;target&#39;]</span><br><span class="line"></span><br><span class="line">print(train_data_scaler.describe())</span><br><span class="line">print(test_data_scaler.describe())</span><br></pre></td></tr></table></figure>

<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.10.png" alt></p>
<h3 id="查看数据分布-KDE差异较大删除特征"><a href="#查看数据分布-KDE差异较大删除特征" class="headerlink" title="查看数据分布(KDE差异较大删除特征)"></a>查看数据分布(KDE差异较大删除特征)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">##查看数据分布  --通过KDE分布对比了特征变量在两个数据集中的分布情况(V5&#x2F;V9&#x2F;V11&#x2F;V17&#x2F;V22&#x2F;V28在训练集和测试集分布差异较大，会影响模型的泛化能力，故删除这些特征)</span><br><span class="line">drop_col&#x3D;6 #6列</span><br><span class="line">drop_row&#x3D;1 #1行</span><br><span class="line">plt.figure(figsize&#x3D;(5*drop_col,5*drop_row))</span><br><span class="line">for i,col in enumerate([&quot;V5&quot;,&quot;V9&quot;,&quot;V11&quot;,&quot;V17&quot;,&quot;V22&quot;,&quot;V28&quot;]): #enumerate函数用于将一个可遍历的数据对象</span><br><span class="line">    ax&#x3D;plt.subplot(1,6,i+1)</span><br><span class="line">    ax&#x3D;sns.kdeplot(train_data_scaler[col],color&#x3D;&quot;Red&quot;,shade&#x3D;True) #画KDE图</span><br><span class="line">    ax&#x3D;sns.kdeplot(test_data_scaler[col],color&#x3D;&quot;Blue&quot;,shade&#x3D;True) #画KDE图</span><br><span class="line">    ax.set_xlabel(col) #设置x标签为col</span><br><span class="line">    ax.set_ylabel(&quot;Frequency&quot;) #设置y标签为Frequency</span><br><span class="line">    ax&#x3D;ax.legend([&quot;train&quot;, &quot;test&quot;])  #设置两条曲线分别叫train和test</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.11.png" alt></p>
<h3 id="特征相关性-用热力图可视化"><a href="#特征相关性-用热力图可视化" class="headerlink" title="特征相关性(用热力图可视化)"></a>特征相关性(用热力图可视化)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">##特征相关性(热力图可视化显示)</span><br><span class="line">plt.figure(figsize&#x3D;(20,16))</span><br><span class="line">column&#x3D;train_data_scaler.columns.tolist() # 整出来一个列表list表示从V0-V39-target</span><br><span class="line">mcorr&#x3D;train_data_scaler[column].corr(method&#x3D;&quot;spearman&quot;)  # spearman表示非线性的 pearson表示相关系数 kendall反映分类变量相关性的指标(无序序列的相关系数)</span><br><span class="line"># zeros_like()函数: 创建一个和mcorr同维度的数组(初始化全为False)</span><br><span class="line">mask&#x3D;np.zeros_like(mcorr,dtype&#x3D;np.bool)</span><br><span class="line"># triu_indices_from()函数: 返回矩阵的上三角(上三角全为True)</span><br><span class="line">mask[np.triu_indices_from(mask)]&#x3D;True</span><br><span class="line">g&#x3D;sns.heatmap(mcorr,mask&#x3D;mask,square&#x3D;True,annot&#x3D;True,fmt&#x3D;&#39;0.2f&#39;) # square为热力图矩阵小块形状(T以列名为标签名)  annot为True表示每个方格写入数据 fmt表示小数点后两位</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.12.png" alt></p>
<h3 id="特征降维-1"><a href="#特征降维-1" class="headerlink" title="特征降维"></a>特征降维</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">##特征降维(特征相关性的初筛--计算相关性系数并筛选&gt;0.1的特征变量)</span><br><span class="line">mcorr&#x3D;mcorr.abs() #将所有取绝对值</span><br><span class="line">numberical_corr&#x3D;mcorr[mcorr[&#39;target&#39;]&gt;0.1][&#39;target&#39;]</span><br><span class="line">print(numberical_corr.sort_values(ascending&#x3D;False))  # VX和系数值 (按照系数值进行排序)</span><br></pre></td></tr></table></figure>

<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.13.png" alt></p>
<h3 id="多重共线性分析-statsmodels-stats-outliers-influence-variance-inflation-factor"><a href="#多重共线性分析-statsmodels-stats-outliers-influence-variance-inflation-factor" class="headerlink" title="多重共线性分析(statsmodels.stats.outliers_influence.variance_inflation_factor)"></a>多重共线性分析(statsmodels.stats.outliers_influence.variance_inflation_factor)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">##多重共线性分析(特征组之间的相关性系数较大) -- 每个特征变量与其他特征变量之间的相关性系数较大所以存在较大的共线性影响 --&gt; 使用PCA进行处理(去除多重共线性)</span><br><span class="line">###statsmodels.stats.outliers_influence.variance_inflation_factor  多重共线性方差膨胀因子</span><br><span class="line">new_numberical&#x3D;[&#39;V0&#39;, &#39;V2&#39;, &#39;V3&#39;, &#39;V4&#39;, &#39;V5&#39;, &#39;V6&#39;, &#39;V10&#39;,&#39;V11&#39;, &#39;V13&#39;, &#39;V15&#39;, &#39;V16&#39;, &#39;V18&#39;, &#39;V19&#39;, &#39;V20&#39;, &#39;V22&#39;,&#39;V24&#39;,&#39;V30&#39;, &#39;V31&#39;, &#39;V37&#39;]</span><br><span class="line">X&#x3D;np.matrix(train_data_scaler[new_numberical]) #根据new_numberical来构成一个二维数组</span><br><span class="line">VIF_list&#x3D;[variance_inflation_factor(X,i) for i in range(X.shape[1])] # 获得多重共线性方差膨胀因子</span><br><span class="line">print(VIF_list)</span><br></pre></td></tr></table></figure>

<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.14.png" alt></p>
<h3 id="PCA处理-去除数据的多重共线性-并进行降维"><a href="#PCA处理-去除数据的多重共线性-并进行降维" class="headerlink" title="PCA处理(去除数据的多重共线性,并进行降维)"></a>PCA处理(去除数据的多重共线性,并进行降维)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">##PCA处理</span><br><span class="line">### sklearn.decomposition.PCA PCA处理之后可保持90%的信息数据</span><br><span class="line">pca&#x3D;PCA(n_components&#x3D;0.9) # 整数表示保留几个特征 小数表示百分之多少的信息</span><br><span class="line">#获得转换器</span><br><span class="line">new_train_pca_90&#x3D;pca.fit_transform(train_data_scaler.iloc[:,0:-1])</span><br><span class="line">new_test_pca_90&#x3D;pca.transform(test_data_scaler)</span><br><span class="line">#转移为DF格式</span><br><span class="line">new_train_pca_90&#x3D;pd.DataFrame(new_train_pca_90)</span><br><span class="line">new_test_pca_90&#x3D;pd.DataFrame(new_test_pca_90)</span><br><span class="line">new_train_pca_90[&#39;target&#39;]&#x3D;train_data_scaler[&#39;target&#39;]  # PCA处理之后保留了16个主成分</span><br><span class="line">print(new_train_pca_90.describe())</span><br><span class="line">print(&quot;----------------------------------------------&quot;)</span><br><span class="line">print(train_data_scaler.describe())</span><br></pre></td></tr></table></figure>

<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.15.png" alt></p>
<h1 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h1><h2 id="回归和相关模型"><a href="#回归和相关模型" class="headerlink" title="回归和相关模型"></a>回归和相关模型</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import seaborn as sns</span><br><span class="line">from sklearn import preprocessing</span><br><span class="line">from sklearn.preprocessing import MinMaxScaler</span><br><span class="line">from scipy import stats</span><br><span class="line">from sklearn.decomposition import PCA</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.linear_model import LinearRegression  #线性回归</span><br><span class="line">from sklearn.neighbors import KNeighborsRegressor  #K近邻回归</span><br><span class="line">from sklearn.tree import DecisionTreeRegressor     #决策树回归</span><br><span class="line">from sklearn.ensemble import RandomForestRegressor #随机森林回归</span><br><span class="line">from sklearn.svm import SVR  # 支持向量回归</span><br><span class="line">from sklearn.model_selection import train_test_split # 切分数据</span><br><span class="line">from sklearn.metrics import mean_squared_error #评价指标</span><br><span class="line">from sklearn.model_selection import learning_curve</span><br><span class="line">from sklearn.model_selection import ShuffleSplit</span><br><span class="line">#1.读取数据</span><br><span class="line">train_data_file &#x3D; &quot;zhengqi_train.txt&quot;</span><br><span class="line">test_data_file &#x3D;  &quot;zhengqi_test.txt&quot;</span><br><span class="line">train_data &#x3D; pd.read_csv(train_data_file, sep&#x3D;&#39;\t&#39;, encoding&#x3D;&#39;utf-8&#39;) #训练集数据共有2888个样本(V0-V37共38个特征变量)  -- 有target字段</span><br><span class="line">test_data &#x3D; pd.read_csv(test_data_file, sep&#x3D;&#39;\t&#39;, encoding&#x3D;&#39;utf-8&#39;) #测试集数据共有1925个样本(V0-V37共有38个特征变量)  -- 无target字段</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#3.归一化(最大值和最小值)  --放缩到(0,1区间)</span><br><span class="line">features_columns&#x3D;[col for col in train_data.columns if col not in [&#39;target&#39;]]   #从V0到V37</span><br><span class="line">min_max_scaler&#x3D;preprocessing.MinMaxScaler().fit(train_data[features_columns])</span><br><span class="line"></span><br><span class="line">train_data_scaler&#x3D;min_max_scaler.transform(train_data[features_columns])</span><br><span class="line">test_data_scaler&#x3D;min_max_scaler.transform(test_data[features_columns])</span><br><span class="line"></span><br><span class="line">train_data_scaler&#x3D;pd.DataFrame(train_data_scaler) #将训练集数据弄成DF格式</span><br><span class="line">train_data_scaler.columns&#x3D;features_columns</span><br><span class="line"></span><br><span class="line">test_data_scaler&#x3D;pd.DataFrame(test_data_scaler) #将测试集数据弄成DF格式</span><br><span class="line">test_data_scaler.columns&#x3D;features_columns</span><br><span class="line"></span><br><span class="line">train_data_scaler[&#39;target&#39;] &#x3D; train_data[&#39;target&#39;]</span><br><span class="line"></span><br><span class="line">#3.PCA处理</span><br><span class="line">### 1.sklearn.decomposition.PCA PCA处理之后可保持90%的信息数据</span><br><span class="line">pca&#x3D;PCA(n_components&#x3D;0.9) # 整数表示保留几个特征 小数表示百分之多少的信息</span><br><span class="line">#获得转换器</span><br><span class="line">new_train_pca_90&#x3D;pca.fit_transform(train_data_scaler.iloc[:,0:-1])</span><br><span class="line">new_test_pca_90&#x3D;pca.transform(test_data_scaler)</span><br><span class="line">#转移为DF格式</span><br><span class="line">new_train_pca_90&#x3D;pd.DataFrame(new_train_pca_90)</span><br><span class="line">new_test_pca_90&#x3D;pd.DataFrame(new_test_pca_90)</span><br><span class="line">new_train_pca_90[&#39;target&#39;]&#x3D;train_data_scaler[&#39;target&#39;]  # PCA处理之后保留了16个主成分</span><br><span class="line">### 2.sklearn.decomposition.PCA PCA处理之后可保持95%的信息数据</span><br><span class="line">pca &#x3D; PCA(n_components&#x3D;0.95)</span><br><span class="line">#获得转换器</span><br><span class="line">new_train_pca_16 &#x3D; pca.fit_transform(train_data_scaler.iloc[:,0:-1])</span><br><span class="line">new_test_pca_16 &#x3D; pca.transform(test_data_scaler)</span><br><span class="line">#转移为DF格式</span><br><span class="line">new_train_pca_16 &#x3D; pd.DataFrame(new_train_pca_16)</span><br><span class="line">new_test_pca_16 &#x3D; pd.DataFrame(new_test_pca_16)</span><br><span class="line">new_train_pca_16[&#39;target&#39;] &#x3D; train_data_scaler[&#39;target&#39;] # PCA处理之后保留了16个主成分</span><br><span class="line"></span><br><span class="line">#2.切分数据(训练集--&gt; 80%训练集和20%验证数据)</span><br><span class="line">new_train_pca_16&#x3D;new_train_pca_16.fillna(0) #采用PCA保留16维特征的数据</span><br><span class="line">train&#x3D;new_train_pca_16[new_test_pca_16.columns]</span><br><span class="line">target&#x3D;new_train_pca_16[&#39;target&#39;]</span><br><span class="line">##切分数据 训练数据80% 验证数据20%</span><br><span class="line">train_data,test_data,train_target,test_target&#x3D;train_test_split(train,target,test_size&#x3D;0.2,random_state&#x3D;0)</span><br><span class="line"></span><br><span class="line">#4.线性回归</span><br><span class="line">clf&#x3D;LinearRegression()  #实例化</span><br><span class="line">clf.fit(train_data,train_target) #创建训练集的转换器</span><br><span class="line">test_pred&#x3D;clf.predict(test_data) #获得测试集的预测</span><br><span class="line">score&#x3D;mean_squared_error(test_target,test_pred) #判断测试集的目标值和测试集的预测值</span><br><span class="line">print(&quot;线性回归预测结果:&quot;,score)  # 结果为0.13468236081062834</span><br><span class="line"></span><br><span class="line">#5.K近邻</span><br><span class="line">clf&#x3D;KNeighborsRegressor(n_neighbors&#x3D;3) # k取3</span><br><span class="line">clf.fit(train_data,train_target)</span><br><span class="line">test_pred&#x3D;clf.predict(test_data)</span><br><span class="line">score&#x3D;mean_squared_error(test_target,test_pred)</span><br><span class="line">print(&quot;K近邻回归预测结果:&quot;,score) # 结果为0.22391053287197232</span><br><span class="line"></span><br><span class="line">#6.决策树回归</span><br><span class="line">clf&#x3D;DecisionTreeRegressor()</span><br><span class="line">clf.fit(train_data,train_target)</span><br><span class="line">test_pred&#x3D;clf.predict(test_data)</span><br><span class="line">score&#x3D;mean_squared_error(test_target,test_pred)</span><br><span class="line">print(&quot;决策树回归预测结果:&quot;,score) # 结果为0.33070805190311414</span><br><span class="line"></span><br><span class="line">#7.随机森林回归</span><br><span class="line">clf&#x3D;RandomForestRegressor(n_estimators&#x3D;200)  #创建200课树的模型</span><br><span class="line">clf.fit(train_data,train_target)</span><br><span class="line">test_pred&#x3D;clf.predict(test_data)</span><br><span class="line">score&#x3D;mean_squared_error(test_target,test_pred)</span><br><span class="line">print(&quot;随机森林回归预测结果:&quot;,score) # 结果为</span><br><span class="line"></span><br><span class="line">#8.LightGBM回归(微软开发的一个GBDT算法框架--更快的训练速度，更低的内存消耗，更好的准确率，处理海量数据)</span><br><span class="line">##(1)连续的浮点特征值 --&gt; k个整数 + (2)构造一个宽度为k的直方图   [遍历时，将离散化后的值作为索引在直方图中积累统计量]</span><br></pre></td></tr></table></figure>

<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.16.png" alt></p>
<h2 id="赛题模型训练"><a href="#赛题模型训练" class="headerlink" title="赛题模型训练"></a>赛题模型训练</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import seaborn as sns</span><br><span class="line">from sklearn import preprocessing</span><br><span class="line">from sklearn.preprocessing import MinMaxScaler</span><br><span class="line">from scipy import stats</span><br><span class="line">from sklearn.decomposition import PCA</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.linear_model import LinearRegression  #线性回归</span><br><span class="line">from sklearn.neighbors import KNeighborsRegressor  #K近邻回归</span><br><span class="line">from sklearn.tree import DecisionTreeRegressor     #决策树回归</span><br><span class="line">from sklearn.ensemble import RandomForestRegressor #随机森林回归</span><br><span class="line">from sklearn.svm import SVR  # 支持向量回归</span><br><span class="line">import lightgbm as lgb # LightGBM模型</span><br><span class="line">from sklearn.model_selection import train_test_split # 切分数据</span><br><span class="line">from sklearn.metrics import mean_squared_error #评价指标</span><br><span class="line">from sklearn.model_selection import learning_curve</span><br><span class="line">from sklearn.model_selection import ShuffleSplit</span><br><span class="line">#1.读取数据</span><br><span class="line">train_data_file &#x3D; &quot;zhengqi_train.txt&quot;</span><br><span class="line">test_data_file &#x3D;  &quot;zhengqi_test.txt&quot;</span><br><span class="line">train_data &#x3D; pd.read_csv(train_data_file, sep&#x3D;&#39;\t&#39;, encoding&#x3D;&#39;utf-8&#39;) #训练集数据共有2888个样本(V0-V37共38个特征变量)  -- 有target字段</span><br><span class="line">test_data &#x3D; pd.read_csv(test_data_file, sep&#x3D;&#39;\t&#39;, encoding&#x3D;&#39;utf-8&#39;) #测试集数据共有1925个样本(V0-V37共有38个特征变量)  -- 无target字段</span><br><span class="line"></span><br><span class="line">#3归一化(最大值和最小值)  --放缩到(0,1区间)</span><br><span class="line">features_columns&#x3D;[col for col in train_data.columns if col not in [&#39;target&#39;]]   #从V0到V37</span><br><span class="line">min_max_scaler&#x3D;preprocessing.MinMaxScaler().fit(train_data[features_columns])</span><br><span class="line"></span><br><span class="line">train_data_scaler&#x3D;min_max_scaler.transform(train_data[features_columns])</span><br><span class="line">test_data_scaler&#x3D;min_max_scaler.transform(test_data[features_columns])</span><br><span class="line"></span><br><span class="line">train_data_scaler&#x3D;pd.DataFrame(train_data_scaler) #将训练集数据弄成DF格式</span><br><span class="line">train_data_scaler.columns&#x3D;features_columns</span><br><span class="line"></span><br><span class="line">test_data_scaler&#x3D;pd.DataFrame(test_data_scaler) #将测试集数据弄成DF格式</span><br><span class="line">test_data_scaler.columns&#x3D;features_columns</span><br><span class="line"></span><br><span class="line">train_data_scaler[&#39;target&#39;] &#x3D; train_data[&#39;target&#39;]</span><br><span class="line"></span><br><span class="line">#3.PCA处理</span><br><span class="line">### 1.sklearn.decomposition.PCA PCA处理之后可保持90%的信息数据</span><br><span class="line">pca&#x3D;PCA(n_components&#x3D;0.9) # 整数表示保留几个特征 小数表示百分之多少的信息</span><br><span class="line">#获得转换器</span><br><span class="line">new_train_pca_90&#x3D;pca.fit_transform(train_data_scaler.iloc[:,0:-1])</span><br><span class="line">new_test_pca_90&#x3D;pca.transform(test_data_scaler)</span><br><span class="line">#转移为DF格式</span><br><span class="line">new_train_pca_90&#x3D;pd.DataFrame(new_train_pca_90)</span><br><span class="line">new_test_pca_90&#x3D;pd.DataFrame(new_test_pca_90)</span><br><span class="line">new_train_pca_90[&#39;target&#39;]&#x3D;train_data_scaler[&#39;target&#39;]  # PCA处理之后保留了16个主成分</span><br><span class="line">### 2.sklearn.decomposition.PCA PCA处理之后可保持95%的信息数据</span><br><span class="line">pca &#x3D; PCA(n_components&#x3D;0.95)</span><br><span class="line">#获得转换器</span><br><span class="line">new_train_pca_16 &#x3D; pca.fit_transform(train_data_scaler.iloc[:,0:-1])</span><br><span class="line">new_test_pca_16 &#x3D; pca.transform(test_data_scaler)</span><br><span class="line">#转移为DF格式</span><br><span class="line">new_train_pca_16 &#x3D; pd.DataFrame(new_train_pca_16)</span><br><span class="line">new_test_pca_16 &#x3D; pd.DataFrame(new_test_pca_16)</span><br><span class="line">new_train_pca_16[&#39;target&#39;] &#x3D; train_data_scaler[&#39;target&#39;] # PCA处理之后保留了16个主成分</span><br><span class="line"></span><br><span class="line">#2.切分数据(训练集--&gt; 80%训练集和20%验证数据)</span><br><span class="line">new_train_pca_16&#x3D;new_train_pca_16.fillna(0) #采用PCA保留16维特征的数据</span><br><span class="line">train&#x3D;new_train_pca_16[new_test_pca_16.columns]</span><br><span class="line">target&#x3D;new_train_pca_16[&#39;target&#39;]</span><br><span class="line">##切分数据 训练数据80% 验证数据20%</span><br><span class="line">train_data,test_data,train_target,test_target&#x3D;train_test_split(train,target,test_size&#x3D;0.2,random_state&#x3D;0)</span><br><span class="line"></span><br><span class="line">#4.线性回归(效果一般，适合分析使用)</span><br><span class="line">clf&#x3D;LinearRegression()  #实例化</span><br><span class="line">clf.fit(train_data,train_target) #创建训练集的转换器</span><br><span class="line">test_pred&#x3D;clf.predict(test_data) #获得测试集的预测</span><br><span class="line">score&#x3D;mean_squared_error(test_target,test_pred) #判断测试集的目标值和测试集的预测值</span><br><span class="line">print(&quot;线性回归预测结果:&quot;,score)  # 结果为0.13468236081062834</span><br><span class="line"></span><br><span class="line">#5.K近邻(效果一般)</span><br><span class="line">clf&#x3D;KNeighborsRegressor(n_neighbors&#x3D;8) # k取8 最近8个</span><br><span class="line">clf.fit(train_data,train_target)</span><br><span class="line">test_pred&#x3D;clf.predict(test_data)</span><br><span class="line">score&#x3D;mean_squared_error(test_target,test_pred)</span><br><span class="line">print(&quot;K近邻回归预测结果:&quot;,score) # 结果为0.22391053287197232</span><br><span class="line"></span><br><span class="line">#6.决策树回归</span><br><span class="line">clf&#x3D;DecisionTreeRegressor()</span><br><span class="line">clf.fit(train_data,train_target)</span><br><span class="line">test_pred&#x3D;clf.predict(test_data)</span><br><span class="line">score&#x3D;mean_squared_error(test_target,test_pred)</span><br><span class="line">print(&quot;决策树回归预测结果:&quot;,score) # 结果为0.33070805190311414</span><br><span class="line"></span><br><span class="line">#7.随机森林回归(比较合适)</span><br><span class="line">clf&#x3D;RandomForestRegressor(n_estimators&#x3D;200)  #创建200课树的模型</span><br><span class="line">clf.fit(train_data,train_target)</span><br><span class="line">test_pred&#x3D;clf.predict(test_data)</span><br><span class="line">score&#x3D;mean_squared_error(test_target,test_pred)</span><br><span class="line">print(&quot;随机森林回归预测结果:&quot;,score) # 结果为</span><br><span class="line"></span><br><span class="line">#8.LightGBM回归(微软开发的一个GBDT算法框架--更快的训练速度，更低的内存消耗，更好的准确率，处理海量数据)</span><br><span class="line">##(1)连续的浮点特征值 --&gt; k个整数 + (2)构造一个宽度为k的直方图   [遍历时，将离散化后的值作为索引在直方图中积累统计量]</span><br><span class="line">clf&#x3D;lgb.LGBMRegressor(</span><br><span class="line">    learning_rate&#x3D;0.01, # 学习率 推荐的候选值为：[0.01, 0.015, 0.025, 0.05, 0.1]</span><br><span class="line">    max_depth&#x3D;-1, # 指定树的最大深度(防止过拟合)</span><br><span class="line">    n_estimators&#x3D;5000, # 树的数量</span><br><span class="line">    boosting_type&#x3D;&#39;gbdt&#39;, # 指定弱学习器的类型 -- gbdt表示使用基于树的模型进行计算(默认)&#x2F;gblinear表示使用线性模型&#x2F;rf使用随机森林</span><br><span class="line">    random_state&#x3D;2019,</span><br><span class="line">    objective&#x3D;&#39;regression&#39; # regression是使用L2正则项的回归模型(默认) &#x2F;regression_l1是使用L1正则项的回归模型 &#x2F;mape平均绝对百分比误差 &#x2F;binary二分类 &#x2F;multiclass多分类</span><br><span class="line">)</span><br><span class="line">##训练模型</span><br><span class="line">clf.fit(X&#x3D;train_data,y&#x3D;train_target,eval_metric&#x3D;&#39;MSE&#39;) #eval_metric表示评价指标(默认是logloss) MSE是均方误差</span><br><span class="line">test_pred&#x3D;clf.predict(test_data)</span><br><span class="line">score&#x3D;mean_squared_error(test_target,test_pred)</span><br><span class="line">print(&quot;lightGbm回归预测结果:&quot;,score)</span><br></pre></td></tr></table></figure>

<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.17.png" alt></p>
<h1 id="模型验证"><a href="#模型验证" class="headerlink" title="模型验证"></a>模型验证</h1><h2 id="模型评估的概念和方法"><a href="#模型评估的概念和方法" class="headerlink" title="模型评估的概念和方法"></a>模型评估的概念和方法</h2><h3 id="欠拟合和过拟合"><a href="#欠拟合和过拟合" class="headerlink" title="欠拟合和过拟合"></a>欠拟合和过拟合</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import seaborn as sns</span><br><span class="line">from sklearn import preprocessing</span><br><span class="line">from sklearn.preprocessing import MinMaxScaler</span><br><span class="line">from scipy import stats</span><br><span class="line">from sklearn.decomposition import PCA</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.linear_model import LinearRegression  #线性回归</span><br><span class="line">from sklearn.neighbors import KNeighborsRegressor  #K近邻回归</span><br><span class="line">from sklearn.tree import DecisionTreeRegressor     #决策树回归</span><br><span class="line">from sklearn.ensemble import RandomForestRegressor #随机森林回归</span><br><span class="line">from sklearn.svm import SVR  # 支持向量回归</span><br><span class="line">import lightgbm as lgb # LightGBM模型</span><br><span class="line">from sklearn.model_selection import train_test_split # 切分数据</span><br><span class="line">from sklearn.metrics import mean_squared_error #评价指标</span><br><span class="line">from sklearn.model_selection import learning_curve</span><br><span class="line">from sklearn.model_selection import ShuffleSplit</span><br><span class="line">from sklearn.pipeline import Pipeline</span><br><span class="line">from sklearn.preprocessing import PolynomialFeatures</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line">#1.读取数据</span><br><span class="line">train_data_file &#x3D; &quot;zhengqi_train.txt&quot;</span><br><span class="line">test_data_file &#x3D;  &quot;zhengqi_test.txt&quot;</span><br><span class="line">train_data &#x3D; pd.read_csv(train_data_file, sep&#x3D;&#39;\t&#39;, encoding&#x3D;&#39;utf-8&#39;) #训练集数据共有2888个样本(V0-V37共38个特征变量)  -- 有target字段</span><br><span class="line">test_data &#x3D; pd.read_csv(test_data_file, sep&#x3D;&#39;\t&#39;, encoding&#x3D;&#39;utf-8&#39;) #测试集数据共有1925个样本(V0-V37共有38个特征变量)  -- 无target字段</span><br><span class="line"></span><br><span class="line">#生成数据集并可视化显示</span><br><span class="line">np.random.seed(666)  #随机生成666个种子</span><br><span class="line">x&#x3D;np.random.uniform(-3.0,3.0,size&#x3D;100) #随机数的最小值是-3.0 最大值是3.0</span><br><span class="line">X&#x3D;x.reshape(-1,1) #reshape更改数据的行列数目</span><br><span class="line">y&#x3D;0.5*x**2+x+2+np.random.normal(0,1,size&#x3D;100)</span><br><span class="line">plt.scatter(x,y) #生成散点图</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">#1.使用线性回归模型对数据进行拟合</span><br><span class="line">lin_reg&#x3D;LinearRegression()</span><br><span class="line">lin_reg.fit(X,y)</span><br><span class="line">print(&quot;准确率为:&quot;,lin_reg.score(X,y)) #准确率约为0.495(比较低) --可见直线拟合数据的程度较低</span><br><span class="line">##使用均方误差来评价拟合程度</span><br><span class="line">y_predict&#x3D;lin_reg.predict(X)</span><br><span class="line">print(&quot;均方误差为:&quot;,mean_squared_error(y,y_predict)) # 均方误差为3.0750025765636577</span><br><span class="line">##绘制拟合结果</span><br><span class="line">plt.scatter(x,y)</span><br><span class="line">plt.plot(np.sort(x),y_predict[np.argsort(x)],color&#x3D;&#39;r&#39;)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">#2.使用多项式回归拟合(2.1封装Pipeline管道 2.2使用Pipeline拟合数据，多项式参数设置为degree&#x3D;x)</span><br><span class="line">##2.1 封装Pipeline管道(以便于下一步灵活调整多项式回归模型参数)</span><br><span class="line">def PolynomialRegression(degree):</span><br><span class="line">    return Pipeline(</span><br><span class="line">        [(&#39;poly&#39;,PolynomialFeatures(degree&#x3D;degree)),</span><br><span class="line">        (&#39;std_scaler&#39;,StandardScaler()),</span><br><span class="line">        (&#39;lin_reg&#39;,LinearRegression())])</span><br><span class="line"></span><br><span class="line">##2.2使用Pipeline拟合数据(多项式参数设置为degree&#x3D;2)</span><br><span class="line">poly2_reg&#x3D;PolynomialRegression(degree&#x3D;2) #使用degree&#x3D;2</span><br><span class="line">poly2_reg.fit(X,y)</span><br><span class="line">y2_predict&#x3D;poly2_reg.predict(X)</span><br><span class="line">print(&quot;degree为2时候的均方误差为:&quot;,mean_squared_error(y,y2_predict)) # 均方误差为1.0987392142417858</span><br><span class="line">##绘制拟合结果</span><br><span class="line">plt.scatter(x,y)</span><br><span class="line">plt.plot(np.sort(x),y2_predict[np.argsort(x)],color&#x3D;&#39;r&#39;)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">##2.2使用Pipeline拟合数据(多项式参数设置为degree&#x3D;10)</span><br><span class="line">poly10_reg&#x3D;PolynomialRegression(degree&#x3D;10) #使用degree&#x3D;10</span><br><span class="line">poly10_reg.fit(X,y)</span><br><span class="line">y10_predict&#x3D;poly10_reg.predict(X)</span><br><span class="line">print(&quot;degree为10时候的均方误差为:&quot;,mean_squared_error(y,y10_predict)) # 均方误差为1.050846676376416</span><br><span class="line">##绘制拟合结果</span><br><span class="line">plt.scatter(x,y)</span><br><span class="line">plt.plot(np.sort(x),y10_predict[np.argsort(x)],color&#x3D;&#39;r&#39;)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">##2.3使用Pipeline拟合数据(多项式参数设置为degree&#x3D;100)</span><br><span class="line">poly100_reg&#x3D;PolynomialRegression(degree&#x3D;100) #使用degree&#x3D;100</span><br><span class="line">poly100_reg.fit(X,y)</span><br><span class="line">y100_predict&#x3D;poly100_reg.predict(X)</span><br><span class="line">print(&quot;degree为100时候的均方误差为:&quot;,mean_squared_error(y,y100_predict)) # 均方误差为0.6831833931625624</span><br><span class="line">##绘制拟合结果</span><br><span class="line">plt.scatter(x,y)</span><br><span class="line">plt.plot(np.sort(x),y100_predict[np.argsort(x)],color&#x3D;&#39;r&#39;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.18.png" alt></p>
<h3 id="模型的泛化与正则化"><a href="#模型的泛化与正则化" class="headerlink" title="模型的泛化与正则化"></a>模型的泛化与正则化</h3><p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.19.png" alt></p>
<h3 id="回归模型的评估指标和调用方法"><a href="#回归模型的评估指标和调用方法" class="headerlink" title="回归模型的评估指标和调用方法"></a>回归模型的评估指标和调用方法</h3><p><strong>四种回归模型评估方法:</strong></p>
<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.20.png" alt></p>
<p><strong>四种回归模型评估的公式:</strong></p>
<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.21.png" alt></p>
<h3 id="交叉验证"><a href="#交叉验证" class="headerlink" title="交叉验证"></a>交叉验证</h3><p><strong>1.简单交叉验证</strong></p>
<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.22.png" alt></p>
<p><strong>2.K折交叉验证</strong></p>
<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.23.png" alt></p>
<p><strong>3.留一法交叉验证</strong></p>
<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.24.png" alt></p>
<p><strong>4.留P法交叉验证</strong></p>
<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.25.png" alt></p>
<p><strong>5.其他交叉验证</strong></p>
<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.26.png" alt></p>
<h2 id="模型调参"><a href="#模型调参" class="headerlink" title="模型调参"></a>模型调参</h2><h3 id="调参的概念"><a href="#调参的概念" class="headerlink" title="调参的概念"></a>调参的概念</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"> 1.参数分类:</span><br><span class="line">   1.1 过程影响类参数: 子模型不变的前提下，调整&quot;子模型数(n_estimators)和学习率(learning_rate)&quot; --&gt; 改变训练过程，提高整体模型的性能</span><br><span class="line">   1.2 子模型影响类参数: 调整&quot;最大树深度(max_depth)和分裂条件(criterion)&quot; --&gt; 改变子模型的性能，提高整体模型的性能</span><br><span class="line">1.3 bagging: 降低方差</span><br><span class="line">1.4 boosting: 降低偏差</span><br></pre></td></tr></table></figure>

<h3 id="参数的影响"><a href="#参数的影响" class="headerlink" title="参数的影响"></a>参数的影响</h3><p><strong>参数对Random Forest的影响</strong></p>
<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.27.png" alt></p>
<p><strong>参数对Gradient Tree Boosting的影响</strong></p>
<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.28.png" alt></p>
<h3 id="网格搜索-Grid-Search"><a href="#网格搜索-Grid-Search" class="headerlink" title="网格搜索(Grid Search)"></a>网格搜索(Grid Search)</h3><p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.29.png" alt></p>
<h3 id="学习曲线"><a href="#学习曲线" class="headerlink" title="学习曲线"></a>学习曲线</h3><p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.30.png" alt></p>
<h3 id="验证曲线"><a href="#验证曲线" class="headerlink" title="验证曲线"></a>验证曲线</h3><p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.31.png" alt></p>
<h2 id="赛题模型验证和调参"><a href="#赛题模型验证和调参" class="headerlink" title="赛题模型验证和调参"></a>赛题模型验证和调参</h2><h3 id="模型过拟合与欠拟合"><a href="#模型过拟合与欠拟合" class="headerlink" title="模型过拟合与欠拟合"></a>模型过拟合与欠拟合</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import seaborn as sns</span><br><span class="line">from sklearn import preprocessing</span><br><span class="line">from sklearn.preprocessing import MinMaxScaler</span><br><span class="line">from scipy import stats</span><br><span class="line">from sklearn.decomposition import PCA</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.linear_model import LinearRegression  #线性回归</span><br><span class="line">from sklearn.neighbors import KNeighborsRegressor  #K近邻回归</span><br><span class="line">from sklearn.tree import DecisionTreeRegressor     #决策树回归</span><br><span class="line">from sklearn.ensemble import RandomForestRegressor #随机森林回归</span><br><span class="line">from sklearn.svm import SVR  # 支持向量回归</span><br><span class="line">import lightgbm as lgb # LightGBM模型</span><br><span class="line">from sklearn.model_selection import train_test_split # 切分数据</span><br><span class="line">from sklearn.metrics import mean_squared_error #均方误差</span><br><span class="line">from sklearn.metrics import mean_absolute_error #平均绝对值误差</span><br><span class="line">from math import sqrt #平方根</span><br><span class="line">from sklearn.metrics import r2_score #R平方值</span><br><span class="line">from sklearn.model_selection import learning_curve</span><br><span class="line">from sklearn.model_selection import ShuffleSplit</span><br><span class="line">from sklearn.pipeline import Pipeline</span><br><span class="line">from sklearn.preprocessing import PolynomialFeatures</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line">from sklearn.linear_model import SGDRegressor</span><br><span class="line">#1.读取数据</span><br><span class="line">train_data_file &#x3D; &quot;zhengqi_train.txt&quot;</span><br><span class="line">test_data_file &#x3D;  &quot;zhengqi_test.txt&quot;</span><br><span class="line">train_data &#x3D; pd.read_csv(train_data_file, sep&#x3D;&#39;\t&#39;, encoding&#x3D;&#39;utf-8&#39;) #训练集数据共有2888个样本(V0-V37共38个特征变量)  -- 有target字段</span><br><span class="line">test_data &#x3D; pd.read_csv(test_data_file, sep&#x3D;&#39;\t&#39;, encoding&#x3D;&#39;utf-8&#39;) #测试集数据共有1925个样本(V0-V37共有38个特征变量)  -- 无target字段</span><br><span class="line"></span><br><span class="line">#2.归一化(最大值和最小值)  --放缩到(0,1区间)</span><br><span class="line">features_columns&#x3D;[col for col in train_data.columns if col not in [&#39;target&#39;]]   #从V0到V37</span><br><span class="line">min_max_scaler&#x3D;preprocessing.MinMaxScaler().fit(train_data[features_columns])</span><br><span class="line"></span><br><span class="line">train_data_scaler&#x3D;min_max_scaler.transform(train_data[features_columns])</span><br><span class="line">test_data_scaler&#x3D;min_max_scaler.transform(test_data[features_columns])</span><br><span class="line"></span><br><span class="line">train_data_scaler&#x3D;pd.DataFrame(train_data_scaler) #将训练集数据弄成DF格式</span><br><span class="line">train_data_scaler.columns&#x3D;features_columns</span><br><span class="line"></span><br><span class="line">test_data_scaler&#x3D;pd.DataFrame(test_data_scaler) #将测试集数据弄成DF格式</span><br><span class="line">test_data_scaler.columns&#x3D;features_columns</span><br><span class="line"></span><br><span class="line">train_data_scaler[&#39;target&#39;] &#x3D; train_data[&#39;target&#39;]</span><br><span class="line"></span><br><span class="line">#3.PCA处理</span><br><span class="line">### 1.sklearn.decomposition.PCA PCA处理之后可保持90%的信息数据</span><br><span class="line">pca&#x3D;PCA(n_components&#x3D;16) # 整数表示保留几个特征 小数表示百分之多少的信息</span><br><span class="line">#获得转换器</span><br><span class="line">new_train_pca_16&#x3D;pca.fit_transform(train_data_scaler.iloc[:,0:-1])</span><br><span class="line">new_test_pca_16&#x3D;pca.transform(test_data_scaler)</span><br><span class="line">#转移为DF格式</span><br><span class="line">new_train_pca_16&#x3D;pd.DataFrame(new_train_pca_16)</span><br><span class="line">new_test_pca_16&#x3D;pd.DataFrame(new_test_pca_16)</span><br><span class="line">new_train_pca_16[&#39;target&#39;]&#x3D;train_data_scaler[&#39;target&#39;]  # PCA处理之后保留了16个主成分</span><br><span class="line"></span><br><span class="line">#4.切分数据(训练集--&gt; 80%训练集和20%验证数据)</span><br><span class="line">new_train_pca_16&#x3D;new_train_pca_16.fillna(0) #采用PCA保留16维特征的数据</span><br><span class="line">train&#x3D;new_train_pca_16[new_test_pca_16.columns]</span><br><span class="line">target&#x3D;new_train_pca_16[&#39;target&#39;]</span><br><span class="line">##切分数据 训练数据80% 验证数据20%</span><br><span class="line">train_data,test_data,train_target,test_target&#x3D;train_test_split(train,target,test_size&#x3D;0.2,random_state&#x3D;0)</span><br><span class="line"></span><br><span class="line">#5.欠拟合(没有多项式转换)</span><br><span class="line">clf&#x3D;SGDRegressor(max_iter&#x3D;500,tol&#x3D;1e-2) # max_iter表示是训练数据的最大传递次数  tol是停止标准</span><br><span class="line">clf.fit(train_data,train_target)</span><br><span class="line">score_train&#x3D;mean_squared_error(train_target,clf.predict(train_data)) # 训练集的均方误差</span><br><span class="line">score_test&#x3D;mean_squared_error(test_target,clf.predict(test_data)) # 测试集的均方误差</span><br><span class="line">print(&quot;SGDRegressor train MSE:&quot;,score_train) # SGDRegressor train MSE:0.14152723650374396</span><br><span class="line">print(&quot;SGDRegressor test MSE:&quot;,score_test) # SGDRegressor test MSE:0.1470304756084494</span><br><span class="line"></span><br><span class="line">#6.过拟合(多项式转换系数过大)</span><br><span class="line">poly&#x3D;PolynomialFeatures(5)  #多项式转换 写5</span><br><span class="line">train_data_poly&#x3D;poly.fit_transform(train_data)</span><br><span class="line">test_data_poly&#x3D;poly.transform(test_data)</span><br><span class="line">clf&#x3D;SGDRegressor(max_iter&#x3D;1000,tol&#x3D;1e-3) # max_iter表示是训练数据的最大传递次数  tol是停止标准</span><br><span class="line">clf.fit(train_data_poly, train_target)  #装在转换器</span><br><span class="line">score_train &#x3D; mean_squared_error(train_target, clf.predict(train_data_poly))</span><br><span class="line">score_test &#x3D; mean_squared_error(test_target, clf.predict(test_data_poly))</span><br><span class="line">print(&quot;SGDRegressor train MSE:&quot;,score_train) # SGDRegressor train MSE: 0.1332651075687169</span><br><span class="line">print(&quot;SGDRegressor test MSE:&quot;,score_test) # SGDRegressor test MSE:  0.14544120121194679</span><br><span class="line"></span><br><span class="line">#7.正常拟合</span><br><span class="line">poly&#x3D;PolynomialFeatures(3)  #多项式转换 写3</span><br><span class="line">train_data_poly&#x3D;poly.fit_transform(train_data)</span><br><span class="line">test_data_poly&#x3D;poly.transform(test_data)</span><br><span class="line">clf&#x3D;SGDRegressor(max_iter&#x3D;1000,tol&#x3D;1e-3) # max_iter表示是训练数据的最大传递次数  tol是停止标准</span><br><span class="line">clf.fit(train_data_poly, train_target)  #装在转换器</span><br><span class="line">score_train &#x3D; mean_squared_error(train_target, clf.predict(train_data_poly))</span><br><span class="line">score_test &#x3D; mean_squared_error(test_target, clf.predict(test_data_poly))</span><br><span class="line">print(&quot;SGDRegressor train MSE:&quot;,score_train) # SGDRegressor train MSE: 0.13343001175858962</span><br><span class="line">print(&quot;SGDRegressor test MSE:&quot;,score_test) # SGDRegressor test MSE: 0.14179907981584394</span><br></pre></td></tr></table></figure>

<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.32.png" alt></p>
<h3 id="模型正则化"><a href="#模型正则化" class="headerlink" title="模型正则化"></a>模型正则化</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import seaborn as sns</span><br><span class="line">from sklearn import preprocessing</span><br><span class="line">from sklearn.preprocessing import MinMaxScaler</span><br><span class="line">from scipy import stats</span><br><span class="line">from sklearn.decomposition import PCA</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.linear_model import LinearRegression  #线性回归</span><br><span class="line">from sklearn.neighbors import KNeighborsRegressor  #K近邻回归</span><br><span class="line">from sklearn.tree import DecisionTreeRegressor     #决策树回归</span><br><span class="line">from sklearn.ensemble import RandomForestRegressor #随机森林回归</span><br><span class="line">from sklearn.svm import SVR  # 支持向量回归</span><br><span class="line">import lightgbm as lgb # LightGBM模型</span><br><span class="line">from sklearn.model_selection import train_test_split # 切分数据</span><br><span class="line">from sklearn.metrics import mean_squared_error #均方误差</span><br><span class="line">from sklearn.metrics import mean_absolute_error #平均绝对值误差</span><br><span class="line">from math import sqrt #平方根</span><br><span class="line">from sklearn.metrics import r2_score #R平方值</span><br><span class="line">from sklearn.model_selection import learning_curve</span><br><span class="line">from sklearn.model_selection import ShuffleSplit</span><br><span class="line">from sklearn.pipeline import Pipeline</span><br><span class="line">from sklearn.preprocessing import PolynomialFeatures</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line">from sklearn.linear_model import SGDRegressor</span><br><span class="line">#1.读取数据</span><br><span class="line">train_data_file &#x3D; &quot;zhengqi_train.txt&quot;</span><br><span class="line">test_data_file &#x3D;  &quot;zhengqi_test.txt&quot;</span><br><span class="line">train_data &#x3D; pd.read_csv(train_data_file, sep&#x3D;&#39;\t&#39;, encoding&#x3D;&#39;utf-8&#39;) #训练集数据共有2888个样本(V0-V37共38个特征变量)  -- 有target字段</span><br><span class="line">test_data &#x3D; pd.read_csv(test_data_file, sep&#x3D;&#39;\t&#39;, encoding&#x3D;&#39;utf-8&#39;) #测试集数据共有1925个样本(V0-V37共有38个特征变量)  -- 无target字段</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#2.归一化(最大值和最小值)  --放缩到(0,1区间)</span><br><span class="line">features_columns&#x3D;[col for col in train_data.columns if col not in [&#39;target&#39;]]   #从V0到V37</span><br><span class="line">min_max_scaler&#x3D;preprocessing.MinMaxScaler().fit(train_data[features_columns])</span><br><span class="line"></span><br><span class="line">train_data_scaler&#x3D;min_max_scaler.transform(train_data[features_columns])</span><br><span class="line">test_data_scaler&#x3D;min_max_scaler.transform(test_data[features_columns])</span><br><span class="line"></span><br><span class="line">train_data_scaler&#x3D;pd.DataFrame(train_data_scaler) #将训练集数据弄成DF格式</span><br><span class="line">train_data_scaler.columns&#x3D;features_columns</span><br><span class="line"></span><br><span class="line">test_data_scaler&#x3D;pd.DataFrame(test_data_scaler) #将测试集数据弄成DF格式</span><br><span class="line">test_data_scaler.columns&#x3D;features_columns</span><br><span class="line"></span><br><span class="line">train_data_scaler[&#39;target&#39;] &#x3D; train_data[&#39;target&#39;]</span><br><span class="line"></span><br><span class="line">#3.PCA处理</span><br><span class="line">### 1.sklearn.decomposition.PCA PCA处理之后可保持90%的信息数据</span><br><span class="line">pca&#x3D;PCA(n_components&#x3D;16) # 整数表示保留几个特征 小数表示百分之多少的信息</span><br><span class="line">#获得转换器</span><br><span class="line">new_train_pca_16&#x3D;pca.fit_transform(train_data_scaler.iloc[:,0:-1])</span><br><span class="line">new_test_pca_16&#x3D;pca.transform(test_data_scaler)</span><br><span class="line">#转移为DF格式</span><br><span class="line">new_train_pca_16&#x3D;pd.DataFrame(new_train_pca_16)</span><br><span class="line">new_test_pca_16&#x3D;pd.DataFrame(new_test_pca_16)</span><br><span class="line">new_train_pca_16[&#39;target&#39;]&#x3D;train_data_scaler[&#39;target&#39;]  # PCA处理之后保留了16个主成分</span><br><span class="line"></span><br><span class="line">#4.切分数据(训练集--&gt; 80%训练集和20%验证数据)</span><br><span class="line">new_train_pca_16&#x3D;new_train_pca_16.fillna(0) #采用PCA保留16维特征的数据</span><br><span class="line">train&#x3D;new_train_pca_16[new_test_pca_16.columns]</span><br><span class="line">target&#x3D;new_train_pca_16[&#39;target&#39;]</span><br><span class="line">##切分数据 训练数据80% 验证数据20%</span><br><span class="line">train_data,test_data,train_target,test_target&#x3D;train_test_split(train,target,test_size&#x3D;0.2,random_state&#x3D;0)</span><br><span class="line"></span><br><span class="line">#8.模型正则化</span><br><span class="line">##8.1 L2范数正则化</span><br><span class="line">poly&#x3D;PolynomialFeatures(3)  #多项式转换 写3</span><br><span class="line">train_data_poly&#x3D;poly.fit_transform(train_data)</span><br><span class="line">test_data_poly&#x3D;poly.transform(test_data)</span><br><span class="line">clf&#x3D;SGDRegressor(max_iter&#x3D;1000,tol&#x3D;1e-3,penalty&#x3D;&#39;L2&#39;,alpha&#x3D;0.0001) # max_iter表示是训练数据的最大传递次数  tol是停止标准</span><br><span class="line">clf.fit(train_data_poly, train_target)  #装在转换器</span><br><span class="line">score_train &#x3D; mean_squared_error(train_target, clf.predict(train_data_poly))</span><br><span class="line">score_test &#x3D; mean_squared_error(test_target, clf.predict(test_data_poly))</span><br><span class="line">print(&quot;SGDRegressor train MSE:&quot;,score_train) # SGDRegressor train MSE: 0.13343001175858962</span><br><span class="line">print(&quot;SGDRegressor test MSE:&quot;,score_test) # SGDRegressor test MSE: 0.14179907981584394</span><br><span class="line"></span><br><span class="line">##8.2 L1范数正则化</span><br><span class="line">poly&#x3D;PolynomialFeatures(3)  #多项式转换 写3</span><br><span class="line">train_data_poly&#x3D;poly.fit_transform(train_data)</span><br><span class="line">test_data_poly&#x3D;poly.transform(test_data)</span><br><span class="line">clf&#x3D;SGDRegressor(max_iter&#x3D;1000,tol&#x3D;1e-3,penalty&#x3D;&#39;L1&#39;,alpha&#x3D;0.0001) # max_iter表示是训练数据的最大传递次数  tol是停止标准</span><br><span class="line">clf.fit(train_data_poly, train_target)  #装在转换器</span><br><span class="line">score_train &#x3D; mean_squared_error(train_target, clf.predict(train_data_poly))</span><br><span class="line">score_test &#x3D; mean_squared_error(test_target, clf.predict(test_data_poly))</span><br><span class="line">print(&quot;SGDRegressor train MSE:&quot;,score_train) # SGDRegressor train MSE: 0.1347595438689653</span><br><span class="line">print(&quot;SGDRegressor test MSE:&quot;,score_test) # SGDRegressor test MSE: 0.14295179346699013</span><br><span class="line"></span><br><span class="line">##8.3 ElasticNet联合L1和L2范数加权正则化</span><br><span class="line">poly&#x3D;PolynomialFeatures(3)  #多项式转换 写3</span><br><span class="line">train_data_poly&#x3D;poly.fit_transform(train_data)</span><br><span class="line">test_data_poly&#x3D;poly.transform(test_data)</span><br><span class="line">clf&#x3D;SGDRegressor(max_iter&#x3D;1000,tol&#x3D;1e-3,penalty&#x3D;&#39;elasticnet&#39;,l1_ratio&#x3D;0.9,alpha&#x3D;0.0001) # max_iter表示是训练数据的最大传递次数  tol是停止标准</span><br><span class="line">clf.fit(train_data_poly, train_target)  #装在转换器</span><br><span class="line">score_train &#x3D; mean_squared_error(train_target, clf.predict(train_data_poly))</span><br><span class="line">score_test &#x3D; mean_squared_error(test_target, clf.predict(test_data_poly))</span><br><span class="line">print(&quot;SGDRegressor train MSE:&quot;,score_train) # SGDRegressor train MSE: 0.13501686392085374</span><br><span class="line">print(&quot;SGDRegressor test MSE:&quot;,score_test) # SGDRegressor test MSE: 0.14315710816572816</span><br></pre></td></tr></table></figure>

<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.33.png" alt></p>
<h3 id="模型交叉验证-四种"><a href="#模型交叉验证-四种" class="headerlink" title="模型交叉验证(四种)"></a>模型交叉验证(四种)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import seaborn as sns</span><br><span class="line">from sklearn import preprocessing</span><br><span class="line">from sklearn.preprocessing import MinMaxScaler  #归一化</span><br><span class="line">from scipy import stats</span><br><span class="line">from sklearn.decomposition import PCA  #PCA主成分降维</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.linear_model import LinearRegression  #线性回归</span><br><span class="line">from sklearn.neighbors import KNeighborsRegressor  #K近邻回归</span><br><span class="line">from sklearn.tree import DecisionTreeRegressor     #决策树回归</span><br><span class="line">from sklearn.ensemble import RandomForestRegressor #随机森林回归</span><br><span class="line">from sklearn.svm import SVR  # 支持向量回归</span><br><span class="line">import lightgbm as lgb # LightGBM模型</span><br><span class="line">from sklearn.model_selection import train_test_split # 切分数据</span><br><span class="line">from sklearn.metrics import mean_squared_error #均方误差</span><br><span class="line">from sklearn.metrics import mean_absolute_error #平均绝对值误差</span><br><span class="line">from math import sqrt #平方根</span><br><span class="line">from sklearn.metrics import r2_score #R平方值</span><br><span class="line">from sklearn.model_selection import learning_curve</span><br><span class="line">from sklearn.model_selection import ShuffleSplit</span><br><span class="line">from sklearn.pipeline import Pipeline  #管道</span><br><span class="line">from sklearn.preprocessing import PolynomialFeatures  #多项式转变</span><br><span class="line">from sklearn.preprocessing import StandardScaler #标准化</span><br><span class="line">from sklearn.linear_model import SGDRegressor  #随机递推下降</span><br><span class="line">from sklearn.model_selection import KFold #KFold是K折交叉验证</span><br><span class="line">from sklearn.model_selection import LeaveOneOut #留一法</span><br><span class="line">from sklearn.model_selection import LeavePOut #留P法</span><br><span class="line">#1.读取数据</span><br><span class="line">train_data_file &#x3D; &quot;zhengqi_train.txt&quot;</span><br><span class="line">test_data_file &#x3D;  &quot;zhengqi_test.txt&quot;</span><br><span class="line">train_data &#x3D; pd.read_csv(train_data_file, sep&#x3D;&#39;\t&#39;, encoding&#x3D;&#39;utf-8&#39;) #训练集数据共有2888个样本(V0-V37共38个特征变量)  -- 有target字段</span><br><span class="line">test_data &#x3D; pd.read_csv(test_data_file, sep&#x3D;&#39;\t&#39;, encoding&#x3D;&#39;utf-8&#39;) #测试集数据共有1925个样本(V0-V37共有38个特征变量)  -- 无target字段</span><br><span class="line"></span><br><span class="line">#2.归一化(最大值和最小值)  --放缩到(0,1区间)</span><br><span class="line">features_columns&#x3D;[col for col in train_data.columns if col not in [&#39;target&#39;]]   #从V0到V37</span><br><span class="line">min_max_scaler&#x3D;preprocessing.MinMaxScaler().fit(train_data[features_columns])</span><br><span class="line"></span><br><span class="line">train_data_scaler&#x3D;min_max_scaler.transform(train_data[features_columns])</span><br><span class="line">test_data_scaler&#x3D;min_max_scaler.transform(test_data[features_columns])</span><br><span class="line"></span><br><span class="line">train_data_scaler&#x3D;pd.DataFrame(train_data_scaler) #将训练集数据弄成DF格式</span><br><span class="line">train_data_scaler.columns&#x3D;features_columns</span><br><span class="line"></span><br><span class="line">test_data_scaler&#x3D;pd.DataFrame(test_data_scaler) #将测试集数据弄成DF格式</span><br><span class="line">test_data_scaler.columns&#x3D;features_columns</span><br><span class="line"></span><br><span class="line">train_data_scaler[&#39;target&#39;] &#x3D; train_data[&#39;target&#39;]</span><br><span class="line"></span><br><span class="line">#3.PCA处理</span><br><span class="line">### 1.sklearn.decomposition.PCA PCA处理之后可保持90%的信息数据</span><br><span class="line">pca&#x3D;PCA(n_components&#x3D;16) # 整数表示保留几个特征 小数表示百分之多少的信息</span><br><span class="line">#获得转换器</span><br><span class="line">new_train_pca_16&#x3D;pca.fit_transform(train_data_scaler.iloc[:,0:-1])</span><br><span class="line">new_test_pca_16&#x3D;pca.transform(test_data_scaler)</span><br><span class="line">#转移为DF格式</span><br><span class="line">new_train_pca_16&#x3D;pd.DataFrame(new_train_pca_16)</span><br><span class="line">new_test_pca_16&#x3D;pd.DataFrame(new_test_pca_16)</span><br><span class="line">new_train_pca_16[&#39;target&#39;]&#x3D;train_data_scaler[&#39;target&#39;]  # PCA处理之后保留了16个主成分</span><br><span class="line"></span><br><span class="line">#4.切分数据(训练集--&gt; 80%训练集和20%验证数据)</span><br><span class="line">new_train_pca_16&#x3D;new_train_pca_16.fillna(0) #采用PCA保留16维特征的数据</span><br><span class="line">train&#x3D;new_train_pca_16[new_test_pca_16.columns]</span><br><span class="line">target&#x3D;new_train_pca_16[&#39;target&#39;]</span><br><span class="line">##切分数据 训练数据80% 验证数据20%</span><br><span class="line">train_data,test_data,train_target,test_target&#x3D;train_test_split(train,target,test_size&#x3D;0.2,random_state&#x3D;0)</span><br><span class="line"></span><br><span class="line">#5.模型交叉验证</span><br><span class="line">##5.1 简单交叉验证</span><br><span class="line">clf&#x3D;SGDRegressor(max_iter&#x3D;1000,tol&#x3D;1e-3) # max_iter表示是训练数据的最大传递次数  tol是停止标准</span><br><span class="line">clf.fit(train_data,train_target)  #装在转换器</span><br><span class="line">score_train &#x3D; mean_squared_error(train_target, clf.predict(train_data))</span><br><span class="line">score_test &#x3D; mean_squared_error(test_target, clf.predict(test_data))</span><br><span class="line">#print(&quot;SGDRegressor train MSE:&quot;,score_train) # SGDRegressor train MSE: 0.1415415271798254</span><br><span class="line">#print(&quot;SGDRegressor test MSE:&quot;,score_test) # SGDRegressor test MSE: 0.147046507243961</span><br><span class="line"></span><br><span class="line">##5.2 k折交叉验证</span><br><span class="line">kf&#x3D;KFold(n_splits&#x3D;5)</span><br><span class="line">for k,(train_index,test_index) in enumerate(kf.split(train)):</span><br><span class="line">    train_data,test_data,train_target,test_target&#x3D;train.values[train_index],train.values[test_index],target[train_index],target[test_index]</span><br><span class="line">    clf &#x3D; SGDRegressor(max_iter&#x3D;1000,tol&#x3D;1e-3)  # max_iter表示是训练数据的最大传递次数  tol是停止标准</span><br><span class="line">    clf.fit(train_data,train_target)</span><br><span class="line">    score_train &#x3D; mean_squared_error(train_target, clf.predict(train_data))</span><br><span class="line">    score_test &#x3D; mean_squared_error(test_target, clf.predict(test_data))</span><br><span class="line">    print(k,&quot;折&quot;,&quot;SGDRegressor train MSE:&quot;,score_train) # x 折 SGDRegressor train MSE: 0.1415415271798254</span><br><span class="line">    print(k,&quot;折&quot;,&quot;SGDRegressor test MSE:&quot;,score_test) # x 折 SGDRegressor train MSE: 0.1415415271798254</span><br><span class="line"></span><br><span class="line">##5.3 留一法 LOO CV</span><br><span class="line">loo&#x3D;LeaveOneOut()</span><br><span class="line">num&#x3D;100</span><br><span class="line">for k,(train_index,test_index) in enumerate(loo.split(train)):</span><br><span class="line">    train_data,test_data,train_target,test_target &#x3D; train.values[train_index],train.values[test_index],target[train_index],target[test_index]</span><br><span class="line">    clf &#x3D; SGDRegressor(max_iter&#x3D;1000,tol&#x3D;1e-3)  # max_iter表示是训练数据的最大传递次数  tol是停止标准</span><br><span class="line">    clf.fit(train_data,train_target)</span><br><span class="line">    score_train &#x3D; mean_squared_error(train_target, clf.predict(train_data))</span><br><span class="line">    score_test &#x3D; mean_squared_error(test_target, clf.predict(test_data))</span><br><span class="line">    print(k,&quot;个&quot;,&quot;SGDRegressor train MSE:&quot;,score_train)</span><br><span class="line">    print(k,&quot;个&quot;,&quot;SGDRegressor test MSE:&quot;,score_test)</span><br><span class="line">    if k &gt;&#x3D; 9:</span><br><span class="line">        break</span><br><span class="line"></span><br><span class="line">##5.4 留P法 LPO CV</span><br><span class="line">lpo&#x3D;LeavePOut(p&#x3D;10)</span><br><span class="line">num&#x3D;100</span><br><span class="line">for k,(train_index, test_index) in enumerate(lpo.split(train)):</span><br><span class="line">    train_data,test_data,train_target,test_target &#x3D; train.values[train_index],train.values[test_index],target[train_index],target[test_index]</span><br><span class="line">    clf &#x3D; SGDRegressor(max_iter&#x3D;1000,tol&#x3D;1e-3)  # max_iter表示是训练数据的最大传递次数  tol是停止标准</span><br><span class="line">    clf.fit(train_data, train_target)</span><br><span class="line">    score_train &#x3D; mean_squared_error(train_target, clf.predict(train_data))</span><br><span class="line">    score_test &#x3D; mean_squared_error(test_target, clf.predict(test_data))</span><br><span class="line">    print(k,&quot;10个&quot;,&quot;SGDRegressor train MSE:&quot;,score_train)</span><br><span class="line">    print(k,&quot;10个&quot;,&quot;SGDRegressor test MSE:&quot;,score_test)</span><br><span class="line">    if k &gt;&#x3D; 9:</span><br><span class="line">        break</span><br></pre></td></tr></table></figure>

<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.34.png" alt></p>
<h3 id="模型超参空间及调参"><a href="#模型超参空间及调参" class="headerlink" title="模型超参空间及调参"></a>模型超参空间及调参</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import seaborn as sns</span><br><span class="line">from sklearn import preprocessing</span><br><span class="line">from sklearn.preprocessing import MinMaxScaler  #归一化</span><br><span class="line">from scipy import stats</span><br><span class="line">from sklearn.decomposition import PCA  #PCA主成分降维</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.linear_model import LinearRegression  #线性回归</span><br><span class="line">from sklearn.neighbors import KNeighborsRegressor  #K近邻回归</span><br><span class="line">from sklearn.tree import DecisionTreeRegressor     #决策树回归</span><br><span class="line">from sklearn.ensemble import RandomForestRegressor #随机森林回归</span><br><span class="line">from sklearn.svm import SVR  # 支持向量回归</span><br><span class="line">import lightgbm as lgb # LightGBM模型</span><br><span class="line">from sklearn.model_selection import train_test_split # 切分数据</span><br><span class="line">from sklearn.metrics import mean_squared_error #均方误差</span><br><span class="line">from sklearn.metrics import mean_absolute_error #平均绝对值误差</span><br><span class="line">from math import sqrt #平方根</span><br><span class="line">from sklearn.metrics import r2_score #R平方值</span><br><span class="line">from sklearn.model_selection import learning_curve</span><br><span class="line">from sklearn.model_selection import ShuffleSplit</span><br><span class="line">from sklearn.pipeline import Pipeline  #管道</span><br><span class="line">from sklearn.preprocessing import PolynomialFeatures  #多项式转变</span><br><span class="line">from sklearn.preprocessing import StandardScaler #标准化</span><br><span class="line">from sklearn.linear_model import SGDRegressor  #随机递推下降</span><br><span class="line">from sklearn.model_selection import KFold #KFold是K折交叉验证</span><br><span class="line">from sklearn.model_selection import LeaveOneOut #留一法</span><br><span class="line">from sklearn.model_selection import LeavePOut #留P法</span><br><span class="line">from sklearn.model_selection import GridSearchCV #网格搜索</span><br><span class="line">from sklearn.model_selection import RandomizedSearchCV</span><br><span class="line">#1.读取数据</span><br><span class="line">train_data_file &#x3D; &quot;zhengqi_train.txt&quot;</span><br><span class="line">test_data_file &#x3D;  &quot;zhengqi_test.txt&quot;</span><br><span class="line">train_data &#x3D; pd.read_csv(train_data_file, sep&#x3D;&#39;\t&#39;, encoding&#x3D;&#39;utf-8&#39;) #训练集数据共有2888个样本(V0-V37共38个特征变量)  -- 有target字段</span><br><span class="line">test_data &#x3D; pd.read_csv(test_data_file, sep&#x3D;&#39;\t&#39;, encoding&#x3D;&#39;utf-8&#39;) #测试集数据共有1925个样本(V0-V37共有38个特征变量)  -- 无target字段</span><br><span class="line"></span><br><span class="line">#2.归一化(最大值和最小值)  --放缩到(0,1区间)</span><br><span class="line">features_columns&#x3D;[col for col in train_data.columns if col not in [&#39;target&#39;]]   #从V0到V37</span><br><span class="line">min_max_scaler&#x3D;preprocessing.MinMaxScaler().fit(train_data[features_columns])</span><br><span class="line"></span><br><span class="line">train_data_scaler&#x3D;min_max_scaler.transform(train_data[features_columns])</span><br><span class="line">test_data_scaler&#x3D;min_max_scaler.transform(test_data[features_columns])</span><br><span class="line"></span><br><span class="line">train_data_scaler&#x3D;pd.DataFrame(train_data_scaler) #将训练集数据弄成DF格式</span><br><span class="line">train_data_scaler.columns&#x3D;features_columns</span><br><span class="line"></span><br><span class="line">test_data_scaler&#x3D;pd.DataFrame(test_data_scaler) #将测试集数据弄成DF格式</span><br><span class="line">test_data_scaler.columns&#x3D;features_columns</span><br><span class="line"></span><br><span class="line">train_data_scaler[&#39;target&#39;] &#x3D; train_data[&#39;target&#39;]</span><br><span class="line"></span><br><span class="line">#3.PCA处理</span><br><span class="line">### 1.sklearn.decomposition.PCA PCA处理之后可保持90%的信息数据</span><br><span class="line">pca&#x3D;PCA(n_components&#x3D;16) # 整数表示保留几个特征 小数表示百分之多少的信息</span><br><span class="line">#获得转换器</span><br><span class="line">new_train_pca_16&#x3D;pca.fit_transform(train_data_scaler.iloc[:,0:-1])</span><br><span class="line">new_test_pca_16&#x3D;pca.transform(test_data_scaler)</span><br><span class="line">#转移为DF格式</span><br><span class="line">new_train_pca_16&#x3D;pd.DataFrame(new_train_pca_16)</span><br><span class="line">new_test_pca_16&#x3D;pd.DataFrame(new_test_pca_16)</span><br><span class="line">new_train_pca_16[&#39;target&#39;]&#x3D;train_data_scaler[&#39;target&#39;]  # PCA处理之后保留了16个主成分</span><br><span class="line"></span><br><span class="line">#4.切分数据(训练集--&gt; 80%训练集和20%验证数据)</span><br><span class="line">new_train_pca_16&#x3D;new_train_pca_16.fillna(0) #采用PCA保留16维特征的数据</span><br><span class="line">train&#x3D;new_train_pca_16[new_test_pca_16.columns]</span><br><span class="line">target&#x3D;new_train_pca_16[&#39;target&#39;]</span><br><span class="line">##切分数据 训练数据80% 验证数据20%</span><br><span class="line">train_data,test_data,train_target,test_target&#x3D;train_test_split(train,target,test_size&#x3D;0.2,random_state&#x3D;0)</span><br><span class="line"></span><br><span class="line">#5.模型超参空间及调参</span><br><span class="line">##5.1 穷举网格搜索</span><br><span class="line">randomForestRegressor&#x3D;RandomForestRegressor()</span><br><span class="line">parameters&#x3D;&#123;</span><br><span class="line">    &#39;n_estimators&#39;:[50,100,200], #预测器数量</span><br><span class="line">    &#39;max_depth&#39;:[1,2,3] #最大深度</span><br><span class="line">&#125;</span><br><span class="line">clf&#x3D;GridSearchCV(randomForestRegressor,parameters,cv&#x3D;5) # cv指定几折交叉验证(训练集中训练集和验证集的划分有几次，然后得出平均值)</span><br><span class="line">clf.fit(train_data,train_target)</span><br><span class="line">score_test &#x3D; mean_squared_error(test_target, clf.predict(test_data)) #均方误差</span><br><span class="line">print(&quot;RandomForestRegressor GridSearchCV test MSE:&quot;,score_test) # 0.25522816178256824</span><br><span class="line">##5.2 随机参数优化</span><br><span class="line">randomForestRegressor &#x3D; RandomForestRegressor()</span><br><span class="line">parameters &#x3D; &#123;</span><br><span class="line">              &#39;n_estimators&#39;:[50, 100, 200, 300], #预测器数量</span><br><span class="line">              &#39;max_depth&#39;:[1, 2, 3, 4, 5] #最大深度</span><br><span class="line">&#125;</span><br><span class="line">clf&#x3D;RandomizedSearchCV(randomForestRegressor,parameters,cv&#x3D;5)</span><br><span class="line">clf.fit(train_data,train_target)</span><br><span class="line">score_test &#x3D; mean_squared_error(test_target, clf.predict(test_data)) #均方误差</span><br><span class="line">print(&quot;RandomForestRegressor RandomizedSearchCV test MSE:&quot;,score_test) #</span><br><span class="line">print(sorted(clf.cv_results_))</span><br><span class="line">##5.3 LGB调参(使用数据训练LGB模型，采用网格搜索方法调参)</span><br><span class="line">clf&#x3D;lgb.LGBMRegressor(num_leaves&#x3D;31)</span><br><span class="line">parameters &#x3D; &#123;</span><br><span class="line">    &#39;learning_rate&#39;: [0.01, 0.1, 1], #学习率</span><br><span class="line">    &#39;n_estimators&#39;: [20, 40] #预测器数量</span><br><span class="line">&#125;</span><br><span class="line">clf&#x3D;GridSearchCV(clf,parameters,cv&#x3D;5)</span><br><span class="line">clf.fit(train_data,train_target)</span><br><span class="line">print(&#39;Best parameters found by grid search are:&#39;,clf.best_params_)   #最好的学习率和预测器个数</span><br><span class="line">score_test&#x3D;mean_squared_error(test_target,clf.predict(test_data))</span><br><span class="line">print(&quot;LGBMRegressor RandomizedSearchCV test MSE:&quot;,score_test)  # LGBMRegressor RandomizedSearchCV test MSE: 0.15175110081465454</span><br></pre></td></tr></table></figure>

<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.35.png" alt></p>
<h1 id="特征优化"><a href="#特征优化" class="headerlink" title="特征优化"></a>特征优化</h1><h2 id="特征优化的方法"><a href="#特征优化的方法" class="headerlink" title="特征优化的方法"></a>特征优化的方法</h2><p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.36.png" alt></p>
<h2 id="赛题特征优化"><a href="#赛题特征优化" class="headerlink" title="赛题特征优化"></a>赛题特征优化</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import seaborn as sns</span><br><span class="line">from sklearn import preprocessing</span><br><span class="line">from sklearn.preprocessing import MinMaxScaler  #归一化</span><br><span class="line">from scipy import stats</span><br><span class="line">from sklearn.decomposition import PCA  #PCA主成分降维</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.linear_model import LinearRegression  #线性回归</span><br><span class="line">from sklearn.neighbors import KNeighborsRegressor  #K近邻回归</span><br><span class="line">from sklearn.tree import DecisionTreeRegressor     #决策树回归</span><br><span class="line">from sklearn.ensemble import RandomForestRegressor #随机森林回归</span><br><span class="line">from sklearn.svm import SVR  # 支持向量回归</span><br><span class="line">import lightgbm as lgb # LightGBM模型</span><br><span class="line">from sklearn.model_selection import train_test_split # 切分数据</span><br><span class="line">from sklearn.metrics import mean_squared_error #均方误差</span><br><span class="line">from sklearn.metrics import mean_absolute_error #平均绝对值误差</span><br><span class="line">from math import sqrt #平方根</span><br><span class="line">from sklearn.metrics import r2_score #R平方值</span><br><span class="line">from sklearn.model_selection import learning_curve</span><br><span class="line">from sklearn.model_selection import ShuffleSplit</span><br><span class="line">from sklearn.pipeline import Pipeline  #管道</span><br><span class="line">from sklearn.preprocessing import PolynomialFeatures  #多项式转变</span><br><span class="line">from sklearn.preprocessing import StandardScaler #标准化</span><br><span class="line">from sklearn.linear_model import SGDRegressor  #随机递推下降</span><br><span class="line">from sklearn.model_selection import KFold #KFold是K折交叉验证</span><br><span class="line">from sklearn.model_selection import LeaveOneOut #留一法</span><br><span class="line">from sklearn.model_selection import LeavePOut #留P法</span><br><span class="line">from sklearn.model_selection import GridSearchCV #网格搜索</span><br><span class="line">from sklearn.model_selection import RandomizedSearchCV</span><br><span class="line">#1.读取数据</span><br><span class="line">train_data_file &#x3D; &quot;zhengqi_train.txt&quot;</span><br><span class="line">test_data_file &#x3D;  &quot;zhengqi_test.txt&quot;</span><br><span class="line">train_data &#x3D; pd.read_csv(train_data_file, sep&#x3D;&#39;\t&#39;, encoding&#x3D;&#39;utf-8&#39;) #训练集数据共有2888个样本(V0-V37共38个特征变量)  -- 有target字段</span><br><span class="line">test_data &#x3D; pd.read_csv(test_data_file, sep&#x3D;&#39;\t&#39;, encoding&#x3D;&#39;utf-8&#39;) #测试集数据共有1925个样本(V0-V37共有38个特征变量)  -- 无target字段</span><br><span class="line"></span><br><span class="line">#2.特征构造方法</span><br><span class="line">epsilon&#x3D;1e-5</span><br><span class="line">#组合交叉特征(自行定义) --增加x*x&#x2F;y log(x)&#x2F;y等</span><br><span class="line">function_dict &#x3D; &#123;</span><br><span class="line">            &#39;add&#39;: lambda x,y: x+y,    #加法</span><br><span class="line">            &#39;mins&#39;: lambda x,y: x-y,   #减法</span><br><span class="line">            &#39;div&#39;: lambda x,y: x&#x2F;(y+epsilon),  #除法</span><br><span class="line">            &#39;multi&#39;: lambda x,y: x*y  #乘法</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">#3.特征构造函数</span><br><span class="line">def auto_features_make(train_data,test_data,function_dict,col_list):  #传入训练集、测试集、特征构造方法、list集合</span><br><span class="line">    train_data,test_data&#x3D;train_data.copy(),test_data.copy()  #获取训练集和测试集</span><br><span class="line">    for i in col_list:</span><br><span class="line">        for j in col_list:</span><br><span class="line">            for function_name,function in function_dict.items(): #获取四个函数的函数名和函数</span><br><span class="line">                for data in [train_data,test_data]:  #从训练集和测试集获取数据</span><br><span class="line">                    function_features&#x3D;function(data[i],data[j])  # data[i]就是x data[j]就是y</span><br><span class="line">                    col_function_features&#x3D;&#39;-&#39;.join([i,function_name,j])</span><br><span class="line">                    data[col_function_features]&#x3D;function_features</span><br><span class="line">    return train_data,test_data</span><br><span class="line"></span><br><span class="line">#4.特征降维处理 --- 先构造新特征，然后使用PCA方法对特征进行降维处理</span><br><span class="line">train_data2,test_data2&#x3D;auto_features_make(train_data,test_data,function_dict,col_list&#x3D;test_data.columns)</span><br><span class="line">pca&#x3D;PCA(n_components&#x3D;500) # 整数表示保留几个特征 小数表示百分之多少的信息</span><br><span class="line">#获得转换器</span><br><span class="line">train_data2_pca&#x3D;pca.fit_transform(train_data2.iloc[:,0:-1])</span><br><span class="line">test_data2_pca&#x3D;pca.transform(test_data2)</span><br><span class="line">#转移为DF格式</span><br><span class="line">train_data2_pca&#x3D;pd.DataFrame(train_data2_pca)</span><br><span class="line">test_data2_pca&#x3D;pd.DataFrame(test_data2_pca)</span><br><span class="line">train_data2_pca[&#39;target&#39;]&#x3D;train_data2[&#39;target&#39;]  # PCA处理之后保留了16个主成分</span><br><span class="line">X_train2&#x3D;train_data2[test_data2.columns].values</span><br><span class="line">y_train&#x3D;train_data2[&#39;target&#39;]</span><br><span class="line"></span><br><span class="line">#5.使用LightGBM模型对新构造的特征进行模型训练和评估</span><br></pre></td></tr></table></figure>

<h1 id="模型融合"><a href="#模型融合" class="headerlink" title="模型融合"></a>模型融合</h1><h2 id="模型优化"><a href="#模型优化" class="headerlink" title="模型优化"></a>模型优化</h2><h3 id="模型学习曲线"><a href="#模型学习曲线" class="headerlink" title="模型学习曲线"></a>模型学习曲线</h3><p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.37.png" alt></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1.欠拟合(高偏差): 模型太简单(没能力学习到样本的底层规律) -- 训练集和测试集的准确率很低</span><br><span class="line">2.过拟合(高方差): 模型太复杂(学习太过) -- 训练集准确率较好 测试集的准确率很低(相差较大)</span><br><span class="line">3.正常拟合</span><br></pre></td></tr></table></figure>

<h3 id="模型融合提升技术"><a href="#模型融合提升技术" class="headerlink" title="模型融合提升技术"></a>模型融合提升技术</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1.概念:产生一组个体学习器 --根据某种策略 --&gt; 结合个体学习器，加强模型效果</span><br><span class="line">2.分类:</span><br><span class="line">  2.1 个体学习器之间不存在(×)强依赖关系 可以同时生成的并行化方法 --&gt; Bagging方法和随机森林</span><br><span class="line">  2.2 个体学习器之间存在(√)强依赖关系 必须串行的序列化方法 --&gt; Boosting方法</span><br></pre></td></tr></table></figure>

<h4 id="Bagging方法"><a href="#Bagging方法" class="headerlink" title="Bagging方法"></a>Bagging方法</h4><p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.38.png" alt></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1.概念:从训练集中抽样得到每个基模型所需要的子训练集 --&gt; 对所有基模型预测的结果进行综合，产生最终的预测结果</span><br><span class="line">2.Bagging方法采用 --&gt; 自助采样法(Bootstrap sampling)</span><br><span class="line">  2.1 m个样本的原始训练集,每次先随机采集一个样本放入采样集，然后将该样本放回</span><br><span class="line">  2.2 m个样本(随机采样),所以会得到m个样本的采样集(可以得到多个不同的弱学习器)</span><br></pre></td></tr></table></figure>

<h4 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1.概念:(对Bagging方法改进)</span><br><span class="line">2.改进之处:</span><br><span class="line">  2.1 基本学习器限定为决策树</span><br><span class="line">  2.2 决策树学习过程中引入了随机属性选择</span><br><span class="line">  2.3 对基决策树的每个结点，先从该结点的属性集合中随机选择一个包含k个属性的子集，然后从这个子集中选择一个最优属性进行划分(就是划分很多小块然后小块里面选个最优属性划分，然后慢慢更新)</span><br></pre></td></tr></table></figure>

<h4 id="Boosting方法"><a href="#Boosting方法" class="headerlink" title="Boosting方法"></a>Boosting方法</h4><p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.39.png" alt></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">1.概念:(阶梯状)基模型按照次序一一进行训练</span><br><span class="line">2.基模型的训练集按照某种策略进行一定的转换 --&gt; 所有基模型预测的结果进行线性综合,产生最终预测结果</span><br><span class="line">3.Boosting方法中著名的算法</span><br><span class="line">  3.1 AdaBoost算法 :加法模型、损失函数为指数函数、学习算法为前向分布算法</span><br><span class="line">  3.2 提升树(Boosting Tree) : 加法模型、基本学习器为决策树、学习算法为前向分布算法 的二分类算法</span><br><span class="line">	3.2.1 对于二分类问题: 损失函数为指数函数 </span><br><span class="line">    3.2.2 对于回归问题:  损失函数为平方误差</span><br><span class="line">  3.3 梯度提升树 : (对提升树算法的改进) 可以将损失函数的负梯度在当前模型的值 &lt;--&gt; 残差的近似值</span><br></pre></td></tr></table></figure>

<h3 id="预测结果融合策略"><a href="#预测结果融合策略" class="headerlink" title="预测结果融合策略"></a>预测结果融合策略</h3><p><strong>Stacking示意:</strong></p>
<p><img src="/2022/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B9%8B%E5%B7%A5%E4%B8%9A%E8%92%B8%E6%B1%BD/3.2.40.png" alt></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">1.Voting(投票机制): 采用少数服从多数的原则</span><br><span class="line"> 1.1 硬投票:对多个模型直接进行投票，投票数最多的类 --&gt; 最终被预测的类</span><br><span class="line">	 1.2 软投票:不同模型设置不同权重，对多个模型直接进行投票，投票数最多的类 --&gt; 最终被预测的类</span><br><span class="line">2.Averaging:将模型结果的平均值 --&gt; 最终的预测值(不同回归方法预测结果波动幅度相差比较大)</span><br><span class="line">3.Ranking:排名平均的方法(如果有权重，就求出n个模型权重比排名之和)</span><br><span class="line">4.Blending:</span><br><span class="line"> 4.1 先将原始的训练集分为两个部分(训练集 -&gt; 训练集+测试集)</span><br><span class="line"> 4.2 在第一层中,用70%的数据训练多个模型，然后去预测剩余30%数据的label</span><br><span class="line"> 4.3 在第二层中,用30%的数据在第一层预测的结果作为新特征继续训练即可</span><br><span class="line">5.Stacking: 用训练好的所有基模型对训练集进行预测</span><br><span class="line">    5.1 第j个基模型对第i个训练样本的预测值作为新的训练集中第i个样本的第j个特征值(最后基于新的训练集进行训练)</span><br><span class="line">    5.2 同理，预测的过程也要先经过所有基模型的预测形成新的测试集，最后对测试集进行测试	</span><br><span class="line"> 5.3 Stacking是一种分层模型集成框架 -- 第一层由多个基学习器组成(输入为原始训练集) 第二层由第一层基学习器的输出作为训练集进行训练</span><br></pre></td></tr></table></figure>

<h1 id="最终导包汇总"><a href="#最终导包汇总" class="headerlink" title="最终导包汇总"></a>最终导包汇总</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import seaborn as sns</span><br><span class="line">from sklearn import preprocessing</span><br><span class="line">from sklearn.preprocessing import MinMaxScaler  #归一化</span><br><span class="line">from scipy import stats</span><br><span class="line">from sklearn.decomposition import PCA  #PCA主成分降维</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.linear_model import LinearRegression  #线性回归</span><br><span class="line">from sklearn.neighbors import KNeighborsRegressor  #K近邻回归</span><br><span class="line">from sklearn.tree import DecisionTreeRegressor     #决策树回归</span><br><span class="line">from sklearn.ensemble import RandomForestRegressor #随机森林回归</span><br><span class="line">from sklearn.svm import SVR  # 支持向量回归</span><br><span class="line">import lightgbm as lgb # LightGBM模型</span><br><span class="line">from sklearn.model_selection import train_test_split # 切分数据</span><br><span class="line">from sklearn.metrics import mean_squared_error #均方误差</span><br><span class="line">from sklearn.metrics import mean_absolute_error #平均绝对值误差</span><br><span class="line">from math import sqrt #平方根</span><br><span class="line">from sklearn.metrics import r2_score #R平方值</span><br><span class="line">from sklearn.model_selection import learning_curve</span><br><span class="line">from sklearn.model_selection import ShuffleSplit</span><br><span class="line">from sklearn.pipeline import Pipeline  #管道</span><br><span class="line">from sklearn.preprocessing import PolynomialFeatures  #多项式转变</span><br><span class="line">from sklearn.preprocessing import StandardScaler #标准化</span><br><span class="line">from sklearn.linear_model import SGDRegressor  #随机递推下降</span><br><span class="line">from sklearn.model_selection import KFold #KFold是K折交叉验证</span><br><span class="line">from sklearn.model_selection import LeaveOneOut #留一法</span><br><span class="line">from sklearn.model_selection import LeavePOut #留P法</span><br><span class="line">from sklearn.model_selection import GridSearchCV #网格搜索</span><br><span class="line">from sklearn.model_selection import RandomizedSearchCV</span><br></pre></td></tr></table></figure>
      
      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-统计学习方法" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2022/09/17/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/" class="article-date">
      <time datetime="2022-09-17T11:20:55.000Z" itemprop="datePublished">2022-09-17</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/09/17/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/">统计学习方法</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h1 id="机器学习入门策略"><a href="#机器学习入门策略" class="headerlink" title="机器学习入门策略"></a>机器学习入门策略</h1><p><strong>参考的路线:</strong></p>
<p><img src="/2022/09/17/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/1.png" alt></p>
<h1 id="统计学习方法"><a href="#统计学习方法" class="headerlink" title="统计学习方法"></a>统计学习方法</h1><h2 id="统计学习"><a href="#统计学习" class="headerlink" title="统计学习"></a>统计学习</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">1.统计学习:关于计算机基于数据构建概率统计模型并运用模型对数据进行预测与分析的一门学科</span><br><span class="line">2.统计学习分类:	</span><br><span class="line">  2.1 监督学习</span><br><span class="line">  2.2 非监督学习</span><br><span class="line">     2.3 半监督学习</span><br><span class="line">  2.4 强化学习</span><br><span class="line">3.统计学习方法步骤:</span><br><span class="line">  3.1 得到一个有限的训练数据集合</span><br><span class="line">  3.2 确定包含所有可能的所有模型(学习模型的集合)</span><br><span class="line">     3.3 确定选择模型的标准(学习的策略)</span><br><span class="line">  3.4 实现求解最优模型的算法(学习的算法)</span><br><span class="line">  3.5 通过学习方法选择最优模型</span><br><span class="line">     3.6 利用最优模型对新数据进行预测或分析</span><br></pre></td></tr></table></figure>

<h2 id="监督学习"><a href="#监督学习" class="headerlink" title="监督学习"></a>监督学习</h2><h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">1.输入&#x2F;输出空间: 输入与输出所有可能取值的集合</span><br><span class="line">  1.1 可以是有限元素的集合</span><br><span class="line">  1.2 可以是整个欧式空间</span><br><span class="line">     1.3 可以是同一个空间，也可以是不同空间(输出空间&lt;&lt;输入空间)</span><br><span class="line">2.每个具体的输入是一个实例(instance),是用特征向量表示。[所有特征向量存在的空间被称为特征空间]</span><br><span class="line">   3.监督学习类型:</span><br><span class="line">  3.1 回归问题:输入变量和输出变量均为连续变量的预测问题</span><br><span class="line">     3.2 分类问题:输出变量为有限个离散变量的预测问题</span><br><span class="line">     3.3 标注问题:输入变量与输出变量均为变量序列的预测问题</span><br><span class="line">   4.联合概率分布(P(X,Y)):</span><br><span class="line">  监督学习假设输入与输出的随机变量X和Y遵循联合概率分布P(X,Y)</span><br><span class="line">5.假设空间:</span><br><span class="line">  模型输入由输入空间-&gt;输出空间的映射的集合</span><br></pre></td></tr></table></figure>

<h3 id="问题的形式化"><a href="#问题的形式化" class="headerlink" title="问题的形式化"></a>问题的形式化</h3><p><img src="/2022/09/17/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/1.png" alt></p>
<h2 id="统计学习三要素-方法-模型-策略-算法"><a href="#统计学习三要素-方法-模型-策略-算法" class="headerlink" title="统计学习三要素(方法=模型+策略+算法)"></a>统计学习三要素(方法=模型+策略+算法)</h2><h3 id="模型-条件概率分布-决策函数"><a href="#模型-条件概率分布-决策函数" class="headerlink" title="模型(条件概率分布/决策函数)"></a>模型(条件概率分布/决策函数)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="策略"><a href="#策略" class="headerlink" title="策略"></a>策略</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="模型评估与模型选择"><a href="#模型评估与模型选择" class="headerlink" title="模型评估与模型选择"></a>模型评估与模型选择</h2><h3 id="训练误差与测试误差"><a href="#训练误差与测试误差" class="headerlink" title="训练误差与测试误差"></a>训练误差与测试误差</h3><h3 id="过拟合与模型选择"><a href="#过拟合与模型选择" class="headerlink" title="过拟合与模型选择"></a>过拟合与模型选择</h3><h2 id="正则化与交叉验证"><a href="#正则化与交叉验证" class="headerlink" title="正则化与交叉验证"></a>正则化与交叉验证</h2><h3 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h3><h3 id="交叉验证"><a href="#交叉验证" class="headerlink" title="交叉验证"></a>交叉验证</h3><h2 id="泛化能力"><a href="#泛化能力" class="headerlink" title="泛化能力"></a>泛化能力</h2><h3 id="泛化误差"><a href="#泛化误差" class="headerlink" title="泛化误差"></a>泛化误差</h3><h3 id="泛化误差上界"><a href="#泛化误差上界" class="headerlink" title="泛化误差上界"></a>泛化误差上界</h3><h2 id="生成模型与判别模型"><a href="#生成模型与判别模型" class="headerlink" title="生成模型与判别模型"></a>生成模型与判别模型</h2><h2 id="分类问题"><a href="#分类问题" class="headerlink" title="分类问题"></a>分类问题</h2><h2 id="标注问题"><a href="#标注问题" class="headerlink" title="标注问题"></a>标注问题</h2><h2 id="回归问题"><a href="#回归问题" class="headerlink" title="回归问题"></a>回归问题</h2>
      
      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/page/5/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><a class="page-number" href="/page/5/">5</a><span class="page-number current">6</span><a class="page-number" href="/page/7/">7</a><a class="page-number" href="/page/8/">8</a><span class="space">&hellip;</span><a class="page-number" href="/page/25/">25</a><a class="extend next" rel="next" href="/page/7/">Next &amp;raquo;</a>
    </nav>
  
</div>
      <footer id="footer">
    <div class="outer">
        <div id="footer-info">
            <div class="footer-left">
                &copy; 2024 Larkkkkkkk
            </div>
            <div class="footer-right">
                <a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="http://bestwing.me" target="_blank">Sw'blog</a> by Swing
            </div>
        </div>
        
            <div class="visit">
                
                    <span id="busuanzi_container_site_pv" style='display:none'>
                        <span id="site-visit" >海贼到访数: 
                            <span id="busuanzi_value_site_uv"></span>
                        </span>
                    </span>
                
                
                    <span>, </span>
                
                
                    <span id="busuanzi_container_page_pv" style='display:none'>
                        <span id="page-visit">本页阅读量: 
                            <span id="busuanzi_value_page_pv"></span>
                        </span>
                    </span>
                
            </div>
        
    </div>
</footer>

    </div>
    
<script src="https://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js"></script>


<script src="/js/main.js"></script>


    <script>
        $(document).ready(function() {
            var backgroundnum = 24;
            var backgroundimg = "url(/background/bg-x.jpg)".replace(/x/gi, Math.ceil(Math.random() * backgroundnum));
            $("#mobile-nav").css({"background-image": backgroundimg,"background-size": "cover","background-position": "center"});
            $(".left-col").css({"background-image": backgroundimg,"background-size": "cover","background-position": "center"});
        })
    </script>





<div class="scroll" id="scroll">
    <a href="#"><i class="fa fa-arrow-up"></i></a>
    <a href="#comments"><i class="fa fa-comments-o"></i></a>
    <a href="#footer"><i class="fa fa-arrow-down"></i></a>
</div>
<script>
    $(document).ready(function() {
        if ($("#comments").length < 1) {
            $("#scroll > a:nth-child(2)").hide();
        };
    })
</script>

<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>

  <script language="javascript">
    $(function() {
        $("a[title]").each(function() {
            var a = $(this);
            var title = a.attr('title');
            if (title == undefined || title == "") return;
            a.data('title', title).removeAttr('title').hover(

            function() {
                var offset = a.offset();
                $("<div id=\"anchortitlecontainer\"></div>").appendTo($("body")).html(title).css({
                    top: offset.top - a.outerHeight() - 15,
                    left: offset.left + a.outerWidth()/2 + 1
                }).fadeIn(function() {
                    var pop = $(this);
                    setTimeout(function() {
                        pop.remove();
                    }, pop.text().length * 800);
                });
            }, function() {
                $("#anchortitlecontainer").remove();
            });
        });
    });
</script>


    <script type="text/javascript">
      window.onload = function(){
        document.getElementById("search").onclick = function(){
            console.log("search")
            search();
        }
      }
      function search(){
        (function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){
        (w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);
        e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);
        })(window,document,'script','//s.swiftypecdn.com/install/v2/st.js','_st');

        _st('install','A1Pz-LKMXbrzcFg2FWi6','2.0.0');
      }
    </script>

  </div>
</body>
</html>